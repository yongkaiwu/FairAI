# Conference Papers

## 2022

### [AAAI 2022](https://dblp.uni-trier.de/db/conf/aaai/aaai2022.html)

- [A Random CNN Sees Objects: One Inductive Bias of CNN and Its Applications.](https://ojs.aaai.org/index.php/AAAI/article/view/19894)
- [Resistance Training Using Prior Bias: Toward Unbiased Scene Graph Generation.](https://ojs.aaai.org/index.php/AAAI/article/view/19896)
- [Unbiased IoU for Spherical Image Object Detection.](https://ojs.aaai.org/index.php/AAAI/article/view/19929)
- [LAGConv: Local-Context Adaptive Convolution Kernels with Global Harmonic Bias for Pansharpening.](https://ojs.aaai.org/index.php/AAAI/article/view/19996)
- [A Causal Debiasing Framework for Unsupervised Salient Object Detection.](https://ojs.aaai.org/index.php/AAAI/article/view/20052)
- [Debiased Batch Normalization via Gaussian Process for Generalizable Person Re-identification.](https://ojs.aaai.org/index.php/AAAI/article/view/20065)
- [Information-Theoretic Bias Reduction via Causal View of Spurious Correlation.](https://ojs.aaai.org/index.php/AAAI/article/view/20115)
- [Cross-Domain Empirical Risk Minimization for Unbiased Long-Tailed Classification.](https://ojs.aaai.org/index.php/AAAI/article/view/20271)
- [Unifying Knowledge Base Completion with PU Learning to Mitigate the Observation Bias.](https://ojs.aaai.org/index.php/AAAI/article/view/20332)
- [Locally Fair Partitioning.](https://ojs.aaai.org/index.php/AAAI/article/view/20401)
- [Fair and Truthful Giveaway Lotteries.](https://ojs.aaai.org/index.php/AAAI/article/view/20405)
- [Truthful and Fair Mechanisms for Matroid-Rank Valuations.](https://ojs.aaai.org/index.php/AAAI/article/view/20407)
- [A Little Charity Guarantees Fair Connected Graph Partitioning.](https://ojs.aaai.org/index.php/AAAI/article/view/20420)
- [Weighted Fairness Notions for Indivisible Items Revisited.](https://ojs.aaai.org/index.php/AAAI/article/view/20425)
- [Fair and Efficient Allocations of Chores under Bivalued Preferences.](https://ojs.aaai.org/index.php/AAAI/article/view/20436)
- [Improved Maximin Guarantees for Subadditive and Fractionally Subadditive Fair Allocation Problem.](https://ojs.aaai.org/index.php/AAAI/article/view/20453)
- [On Testing for Discrimination Using Causal Models.](https://ojs.aaai.org/index.php/AAAI/article/view/20494)
- [Online Certification of Preference-Based Fairness for Personalized Recommender Systems.](https://ojs.aaai.org/index.php/AAAI/article/view/20606)
- [Modification-Fair Cluster Editing.](https://ojs.aaai.org/index.php/AAAI/article/view/20617)
- [Recovering the Propensity Score from Biased Positive Unlabeled Data.](https://ojs.aaai.org/index.php/AAAI/article/view/20624)
- [Achieving Counterfactual Fairness for Causal Bandit.](https://ojs.aaai.org/index.php/AAAI/article/view/20653)
- [Group-Aware Threshold Adaptation for Fair Classification.](https://ojs.aaai.org/index.php/AAAI/article/view/20657)
- [Spatial Frequency Bias in Convolutional Generative Adversarial Networks.](https://ojs.aaai.org/index.php/AAAI/article/view/20675)
- [A Computable Definition of the Spectral Bias.](https://ojs.aaai.org/index.php/AAAI/article/view/20677)
- [Gradient Based Activations for Accurate Bias-Free Learning.](https://ojs.aaai.org/index.php/AAAI/article/view/20687)
- [Fast and Efficient MMD-Based Fair PCA via Optimization over Stiefel Manifold.](https://ojs.aaai.org/index.php/AAAI/article/view/20699)
- [Covered Information Disentanglement: Model Transparency via Unbiased Permutation Importance.](https://ojs.aaai.org/index.php/AAAI/article/view/20769)
- [On the Impossibility of Non-trivial Accuracy in Presence of Fairness Constraints.](https://ojs.aaai.org/index.php/AAAI/article/view/20770)
- [Powering Finetuning in Few-Shot Learning: Domain-Agnostic Bias Reduction with Selected Sampling.](https://ojs.aaai.org/index.php/AAAI/article/view/20823)
- [Controlling Underestimation Bias in Reinforcement Learning via Quasi-median Operation.](https://ojs.aaai.org/index.php/AAAI/article/view/20840)
- [Cooperative Multi-Agent Fairness and Equivariant Policies.](https://ojs.aaai.org/index.php/AAAI/article/view/21166)
- [Why Fair Labels Can Yield Unfair Predictions: Graphical Conditions for Introduced Unfairness.](https://ojs.aaai.org/index.php/AAAI/article/view/21182)
- [Towards Debiasing DNN Models from Spurious Feature Influence.](https://ojs.aaai.org/index.php/AAAI/article/view/21185)
- [Algorithmic Fairness Verification with Graphical Models.](https://ojs.aaai.org/index.php/AAAI/article/view/21187)
- [Achieving Long-Term Fairness in Sequential Decision Making.](https://ojs.aaai.org/index.php/AAAI/article/view/21188)
- [Fairness without Imputation: A Decision Tree Approach for Fair Prediction with Missing Values.](https://ojs.aaai.org/index.php/AAAI/article/view/21189)
- [On the Fairness of Causal Algorithmic Recourse.](https://ojs.aaai.org/index.php/AAAI/article/view/21192)
- [Mitigating Reporting Bias in Semi-supervised Temporal Commonsense Inference with Probabilistic Soft Logic.](https://ojs.aaai.org/index.php/AAAI/article/view/21288)
- [Attention Biasing and Context Augmentation for Zero-Shot Control of Encoder-Decoder Transformers for Natural Language Generation.](https://ojs.aaai.org/index.php/AAAI/article/view/21319)
- [KATG: Keyword-Bias-Aware Adversarial Text Generation for Text Classification.](https://ojs.aaai.org/index.php/AAAI/article/view/21380)
- [Debiasing NLU Models via Causal Intervention and Counterfactual Reasoning.](https://ojs.aaai.org/index.php/AAAI/article/view/21389)
- [Socially Fair Mitigation of Misinformation on Social Networks via Constraint Stochastic Optimization.](https://ojs.aaai.org/index.php/AAAI/article/view/21436)
- [Interpreting Gender Bias in Neural Machine Translation: Multilingual Architecture Matters.](https://ojs.aaai.org/index.php/AAAI/article/view/21442)
- [Word Embeddings via Causal Inference: Gender Bias Reducing and Semantic Information Preserving.](https://ojs.aaai.org/index.php/AAAI/article/view/21443)
- [Has CEO Gender Bias Really Been Fixed? Adversarial Attacking and Improving Gender Fairness in Image Search.](https://ojs.aaai.org/index.php/AAAI/article/view/21445)
- [FairFoody: Bringing In Fairness in Food Delivery.](https://ojs.aaai.org/index.php/AAAI/article/view/21447)
- [Gradual (In)Compatibility of Fairness Criteria.](https://ojs.aaai.org/index.php/AAAI/article/view/21450)
- [Unmasking the Mask - Evaluating Social Biases in Masked Language Models.](https://ojs.aaai.org/index.php/AAAI/article/view/21453)
- [CrossWalk: Fairness-Enhanced Node Representation Learning.](https://ojs.aaai.org/index.php/AAAI/article/view/21454)
- [Fair Conformal Predictors for Applications in Medical Imaging.](https://ojs.aaai.org/index.php/AAAI/article/view/21459)
- [Investigations of Performance and Bias in Human-AI Teamwork in Hiring.](https://ojs.aaai.org/index.php/AAAI/article/view/21468)
- [Fairness by "Where": A Statistically-Robust and Model-Agnostic Bi-level Learning Framework.](https://ojs.aaai.org/index.php/AAAI/article/view/21481)
- [Longitudinal Fairness with Censorship.](https://ojs.aaai.org/index.php/AAAI/article/view/21484)
- [Target Languages (vs. Inductive Biases) for Learning to Act and Plan.](https://ojs.aaai.org/index.php/AAAI/article/view/21497)
- [Anatomizing Bias in Facial Analysis.](https://ojs.aaai.org/index.php/AAAI/article/view/21500)
- [Combating Sampling Bias: A Self-Training Method in Credit Risk Models.](https://ojs.aaai.org/index.php/AAAI/article/view/21528)
- [Reproducibility as a Mechanism for Teaching Fairness, Accountability, Confidentiality, and Transparency in Artificial Intelligence.](https://ojs.aaai.org/index.php/AAAI/article/view/21558)
- [Deep Representation Debiasing via Mutual Information Minimization and Maximization (Student Abstract).](https://ojs.aaai.org/index.php/AAAI/article/view/21619)
- [LITMUS Predictor: An AI Assistant for Building Reliable, High-Performing and Fair Multilingual NLP Systems.](https://ojs.aaai.org/index.php/AAAI/article/view/21736)

### [AIES 2022](https://www.aies-conference.com/2022/)

- [The Limits of Fairness.](https://doi.org/10.1145/3514094.3539568)
- [Beyond Fairness and Explanation: Foundations of Trustworthiness of Artificial Agents.](https://doi.org/10.1145/3514094.3539570)
- [Long-term Dynamics of Fairness Intervention in Connection Recommender Systems.](https://doi.org/10.1145/3514094.3534173)
- [SCALES: From Fairness Principles to Constrained Decision-Making.](https://doi.org/10.1145/3514094.3534190)
- [Fairness in Agreement With European Values: An Interdisciplinary Perspective on AI Regulation.](https://doi.org/10.1145/3514094.3534158)
- [FINS Auditing Framework: Group Fairness for Subset Selections.](https://doi.org/10.1145/3514094.3534160)
- [Gender Bias in Word Embeddings: A Comprehensive Analysis of Frequency, Syntax, and Semantics.](https://doi.org/10.1145/3514094.3534162)
- [Fairness via Explanation Quality: Evaluating Disparities in the Quality of Post hoc Explanations.](https://doi.org/10.1145/3514094.3534159)
- [Does AI De-Bias Recruitment?: Race, Gender, and AI's 'Eradication of Differences Between Groups'.](https://doi.org/10.1145/3514094.3534151)
- [An Ontology for Fairness Metrics.](https://doi.org/10.1145/3514094.3534137)
- [Understanding Decision Subjects' Fairness Perceptions and Retention in Repeated Interactions with AI-Based Decision Systems.](https://doi.org/10.1145/3514094.3534201)
- [FairCanary: Rapid Continuous Explainable Fairness.](https://doi.org/10.1145/3514094.3534157)
- [Learning Fairer Interventions.](https://doi.org/10.1145/3514094.3534172)
- [Algorithmic Fairness and Structural Injustice: Insights from Feminist Political Philosophy.](https://doi.org/10.1145/3514094.3534188)
- [Equalizing Credit Opportunity in Algorithms: Aligning Algorithmic Fairness Research with U.S. Fair Lending Regulation.](https://doi.org/10.1145/3514094.3534154)
- [Data-Centric Factors in Algorithmic Fairness.](https://doi.org/10.1145/3514094.3534147)
- [Towards Better Detection of Biased Language with Scarce, Noisy, and Biased Annotations.](https://doi.org/10.1145/3514094.3534142)
- [Investigating Debiasing Effects on Classification and Explainability.](https://doi.org/10.1145/3514094.3534170)
- [Contrastive Counterfactual Fairness in Algorithmic Decision-Making.](https://doi.org/10.1145/3514094.3534143)
- [Measuring Gender Bias in Word Embeddings of Gendered Languages Requires Disentangling Grammatical Gender Signals.](https://doi.org/10.1145/3514094.3534176)
- [A Dynamic Decision-Making Framework Promoting Long-Term Fairness.](https://doi.org/10.1145/3514094.3534127)
- [A Bio-Inspired Framework for Machine Bias Interpretation.](https://doi.org/10.1145/3514094.3534126)
- [Algorithms that "Don't See Color": Measuring Biases in Lookalike and Special Ad Audiences.](https://doi.org/10.1145/3514094.3534135)
- [From Coded Bias to Existential Threat: Expert Frames and the Epistemic Politics of AI Governance.](https://doi.org/10.1145/3514094.3534161)
- [Strategic Best Response Fairness in Fair Machine Learning.](https://doi.org/10.1145/3514094.3534194)
- [Explainability's Gain is Optimality's Loss?: How Explanations Bias Decision-making.](https://doi.org/10.1145/3514094.3534156)
- [Enhancing Fairness in Face Detection in Computer Vision Systems by Demographic Bias Mitigation.](https://doi.org/10.1145/3514094.3534153)
- [Identifying Bias in Data Using Two-Distribution Hypothesis Tests.](https://doi.org/10.1145/3514094.3534169)
- [Why is my System Biased?: Rating of AI Systems through a Causal Lens.](https://doi.org/10.1145/3514094.3539556)
- [Socially-Aware Artificial Intelligence for Fair Mobility.](https://doi.org/10.1145/3514094.3539545)
- [Bias in Artificial Intelligence Models in Financial Services.](https://doi.org/10.1145/3514094.3539561)
- [Bias in Hate Speech and Toxicity Detection.](https://doi.org/10.1145/3514094.3539519)
- [What's (Not) Ideal about Fair Machine Learning?](https://doi.org/10.1145/3514094.3539543)
- [Fair, Robust, and Data-Efficient Machine Learning in Healthcare.](https://doi.org/10.1145/3514094.3539552)

### [CIKM 2022](https://dblp.uni-trier.de/db/conf/cikm/cikm2022.html)

- [RAGUEL: Recourse-Aware Group Unfairness Elimination.](https://doi.org/10.1145/3511808.3557424)
- [Quantifying and Mitigating Popularity Bias in Conversational Recommender Systems.](https://doi.org/10.1145/3511808.3557423)
- [Debiased Balanced Interleaving at Amazon Search.](https://doi.org/10.1145/3511808.3557123)
- [Mitigating Biases in Student Performance Prediction via Attention-Based Personalized Federated Learning.](https://doi.org/10.1145/3511808.3557108)
- [Cascaded Debiasing: Studying the Cumulative Effect of Multiple Fairness-Enhancing Interventions.](https://doi.org/10.1145/3511808.3557155)
- [Towards Fairer Classifier via True Fairness Score Path.](https://doi.org/10.1145/3511808.3557109)
- [Incorporating Fairness in Large-scale Evacuation Planning.](https://doi.org/10.1145/3511808.3557075)
- [Causal Intervention for Sentiment De-biasing in Recommendation.](https://doi.org/10.1145/3511808.3557558)
- [Debiasing Neighbor Aggregation for Graph Neural Network in Recommender Systems.](https://doi.org/10.1145/3511808.3557576)
- [Do Graph Neural Networks Build Fair User Models? Assessing Disparate Impact and Mistreatment in Behavioural User Profiling.](https://doi.org/10.1145/3511808.3557584)
- [Balancing Utility and Exposure Fairness for Integrated Ranking with Reinforcement Learning.](https://doi.org/10.1145/3511808.3557551)
- [Visual Encoding and Debiasing for CTR Prediction.](https://doi.org/10.1145/3511808.3557721)
- [How Does the Crowd Impact the Model? A Tool for Raising Awareness of Social Bias in Crowdsourced Training Data.](https://doi.org/10.1145/3511808.3557178)

### [FAT\* 2022](https://dblp.uni-trier.de/db/conf/fat/fat2022.html)


### [ICLR 2022](https://dblp.uni-trier.de/db/conf/iclr/iclr2022.html)

- [Is Fairness Only Metric Deep? Evaluating and Addressing Subgroup Gaps in Deep Metric Learning.](https://openreview.net/forum?id=js62_xuLDDv)
- [Fair Normalizing Flows.](https://openreview.net/forum?id=BrFIKuxrZE)
- [Distributionally Robust Fair Principal Components via Geodesic Descents.](https://openreview.net/forum?id=9NVd-DMtThY)
- [FairCal: Fairness Calibration for Face Verification.](https://openreview.net/forum?id=nRj0NcmSuxb)
- [Fairness Guarantees under Demographic Shift.](https://openreview.net/forum?id=wbPObLm6ueA)
- [Generalized Demographic Parity for Group Fairness.](https://openreview.net/forum?id=YigKlMJwjye)
- [Fairness in Representation for Multilingual NLP: Insights from Controlled Experiments on Conditional Language Modeling.](https://openreview.net/forum?id=-llS6TiOew)

## [ICDM 2022](https://dblp.uni-trier.de/db/conf/icdm/icdm2022.html)

### [ICML 2022](https://dblp.uni-trier.de/db/conf/icml/icml2022.html)

- [Active Sampling for Min-Max Fairness.](https://proceedings.mlr.press/v162/abernethy22a.html)
- [Fair and Fast k-Center Clustering for Data Summarization.](https://proceedings.mlr.press/v162/angelidakis22a.html)
- [On the Hidden Biases of Policy Mirror Ascent in Continuous Action Spaces.](https://proceedings.mlr.press/v162/bedi22a.html)
- [Skin Deep Unlearning: Artefact and Instrument Debiasing in the Context of Melanoma Classification.](https://proceedings.mlr.press/v162/bevan22a.html)
- [Fairness with Adaptive Weights.](https://proceedings.mlr.press/v162/chai22a.html)
- [The Poisson Binomial Mechanism for Unbiased Federated Learning with Secure Aggregation.](https://proceedings.mlr.press/v162/chen22s.html)
- [RieszNet and ForestRiesz: Automatic Debiased Machine Learning with Neural Nets and Random Forests.](https://proceedings.mlr.press/v162/chernozhukov22a.html)
- [Mitigating Gender Bias in Face Recognition using the von Mises-Fisher Mixture Model.](https://proceedings.mlr.press/v162/conti22a.html)
- [Fair Generalized Linear Models with a Convex Penalty.](https://proceedings.mlr.press/v162/do22a.html)
- [Fast rates for noisy interpolation require rethinking the effect of inductive bias.](https://proceedings.mlr.press/v162/donhauser22a.html)
- [Inductive Biases and Variable Creation in Self-Attention Mechanisms.](https://proceedings.mlr.press/v162/edelman22a.html)
- [Contrastive Mixture of Posteriors for Counterfactual Inference, Data Integration and Fairness.](https://proceedings.mlr.press/v162/foster22a.html)
- [Unsupervised Detection of Contextualized Embedding Bias with Application to Ideology.](https://proceedings.mlr.press/v162/hofmann22a.html)
- [Input-agnostic Certified Group Fairness via Gaussian Parameter Smoothing.](https://proceedings.mlr.press/v162/jin22g.html)
- [Learning fair representation with a parametric integral probability metric.](https://proceedings.mlr.press/v162/kim22b.html)
- [Implicit Bias of Linear Equivariant Networks.](https://proceedings.mlr.press/v162/lawrence22a.html)
- [Achieving Fairness at No Utility Cost via Data Reweighing with Influence.](https://proceedings.mlr.press/v162/li22p.html)
- [Fluctuations, Bias, Variance & Ensemble of Learners: Exact Asymptotics for Convex Losses in High-Dimension.](https://proceedings.mlr.press/v162/loureiro22a.html)
- [ModLaNets: Learning Generalisable Dynamics via Modularity and Physical Inductive Bias.](https://proceedings.mlr.press/v162/lu22c.html)
- [Rethinking Fano's Inequality in Ensemble Learning.](https://proceedings.mlr.press/v162/morishita22a.html)
- [Implicit Bias of the Step Size in Linear Diagonal Neural Networks.](https://proceedings.mlr.press/v162/nacson22a.html)
- [The Primacy Bias in Deep Reinforcement Learning.](https://proceedings.mlr.press/v162/nikishin22a.html)
- [Causal Conceptions of Fairness and their Consequences.](https://proceedings.mlr.press/v162/nilforoshan22a.html)
- [Debiaser Beware: Pitfalls of Centering Regularized Transport Maps.](https://proceedings.mlr.press/v162/pooladian22a.html)
- [A Convergence Theory for SVGD in the Population Limit under Talagrand's Inequality T1.](https://proceedings.mlr.press/v162/salim22a.html)
- [Understanding Contrastive Learning Requires Incorporating Inductive Biases.](https://proceedings.mlr.press/v162/saunshi22a.html)
- [Selective Regression under Fairness Criteria.](https://proceedings.mlr.press/v162/shah22a.html)
- [Metric-Fair Active Learning.](https://proceedings.mlr.press/v162/shen22b.html)
- [Fair Representation Learning through Implicit Path Alignment.](https://proceedings.mlr.press/v162/shui22a.html)

### [IJCAI 2022](https://dblp.uni-trier.de/db/conf/ijcai/ijcai2022.html)

- [Individual Fairness Guarantees for Neural Networks.](https://doi.org/10.24963/ijcai.2022/92)
- [How Does Frequency Bias Affect the Robustness of Neural Image Classifiers against Common Corruption and Adversarial Perturbations?](https://doi.org/10.24963/ijcai.2022/93)
- [SoFaiR: Single Shot Fair Representation Learning.](https://doi.org/10.24963/ijcai.2022/97)
- [Fairness without the Sensitive Attribute via Causal Variational Autoencoder.](https://doi.org/10.24963/ijcai.2022/98)
- [Counterfactual Interpolation Augmentation (CIA): A Unified Approach to Enhance Fairness and Explainability of DNN.](https://doi.org/10.24963/ijcai.2022/103)
- [Post-processing of Differentially Private Data: A Fairness Perspective.](https://doi.org/10.24963/ijcai.2022/559)
- [Differential Privacy and Fairness in Decisions and Learning Tasks: A Survey.](https://doi.org/10.24963/ijcai.2022/766)
- [Extending Decision Tree to Handle Multiple Fairness Criteria.](https://doi.org/10.24963/ijcai.2022/822)

### [KDD 2022](https://dblp.uni-trier.de/db/conf/kdd/kdd2022.html)

- [Avoiding Biases due to Similarity Assumptions in Node Embeddings.](https://doi.org/10.1145/3534678.3539287)
- [Scalar is Not Enough: Vectorization-based Unbiased Learning to Rank.](https://doi.org/10.1145/3534678.3539468)
- [A Generalized Doubly Robust Learning Framework for Debiasing Post-Click Conversion Rate Prediction.](https://doi.org/10.1145/3534678.3539270)
- [Debiasing the Cloze Task in Sequential Recommendation with Bidirectional Transformers.](https://doi.org/10.1145/3534678.3539430)
- [On Structural Explanation of Bias in Graph Neural Networks.](https://doi.org/10.1145/3534678.3539319)
- [Fair Labeled Clustering.](https://doi.org/10.1145/3534678.3539451)
- [Fair Representation Learning: An Alternative to Mutual Information.](https://doi.org/10.1145/3534678.3539302)
- [UD-GNN: Uncertainty-aware Debiased Training on Semi-Homophilous Graphs.](https://doi.org/10.1145/3534678.3539483)
- [Learning Fair Representation via Distributional Contrastive Disentanglement.](https://doi.org/10.1145/3534678.3539232)
- [Fair and Interpretable Models for Survival Analysis.](https://doi.org/10.1145/3534678.3539259)
- [Fair Ranking as Fair Division: Impact-Based Individual Fairness in Ranking.](https://doi.org/10.1145/3534678.3539353)
- [Balancing Bias and Variance for Active Weakly Supervised Learning.](https://doi.org/10.1145/3534678.3539264)
- [GUIDE: Group Equality Informed Individual Fairness in Graph Neural Networks.](https://doi.org/10.1145/3534678.3539346)
- [Clustering with Fair-Center Representation: Parameterized Approximation Algorithms and Heuristics.](https://doi.org/10.1145/3534678.3539487)
- [Make Fairness More Fair: Fair Item Utility Estimation and Exposure Re-Distribution.](https://doi.org/10.1145/3534678.3539354)
- [Partial Label Learning with Discrimination Augmentation.](https://doi.org/10.1145/3534678.3539363)
- [Improving Fairness in Graph Neural Networks via Mitigating Sensitive Attribute Leakage.](https://doi.org/10.1145/3534678.3539404)
- [Debiasing Learning for Membership Inference Attacks Against Recommender Systems.](https://doi.org/10.1145/3534678.3539392)
- [Invariant Preference Learning for General Debiasing in Recommendation.](https://doi.org/10.1145/3534678.3539439)
- [Comprehensive Fair Meta-learned Recommender System.](https://doi.org/10.1145/3534678.3539269)
- [Counteracting User Attention Bias in Music Streaming Recommendation via Reward Modification.](https://doi.org/10.1145/3534678.3539393)
- [Adaptive Fairness-Aware Online Meta-Learning for Changing Environments.](https://doi.org/10.1145/3534678.3539420)
- [Optimizing Long-Term Efficiency and Fairness in Ride-Hailing via Joint Order Dispatching and Driver Repositioning.](https://doi.org/10.1145/3534678.3539060)
- [CausalMTA: Eliminating the User Confounding Bias for Causal Multi-touch Attribution.](https://doi.org/10.1145/3534678.3539108)
- [Deconfounding Duration Bias in Watch-time Prediction for Video Recommendation.](https://doi.org/10.1145/3534678.3539092)
- [Why Data Scientists Prefer Glassbox Machine Learning: Algorithms, Differential Privacy, Editing and Bias Mitigation.](https://doi.org/10.1145/3534678.3542627)
- [The Battlefront of Combating Misinformation and Coping with Media Bias.](https://doi.org/10.1145/3534678.3542615)
- [Algorithmic Fairness on Graphs: Methods and Trends.](https://doi.org/10.1145/3534678.3542599)
- [Temporal Graph Learning for Financial World: Algorithms, Scalability, Explainability & Fairness.](https://doi.org/10.1145/3534678.3542619)

### [NIPS 2022](https://dblp.uni-trier.de/db/conf/nips/neurips2022.html)

- [A Large Scale Search Dataset for Unbiased Learning to Rank.](http://papers.nips.cc/paper_files/paper/2022/hash/07f560092a0edceabf55af32a40eaee3-Abstract-Datasets_and_Benchmarks.html)
- [Counterfactual Fairness with Partially Known Causal Graph.](http://papers.nips.cc/paper_files/paper/2022/hash/08887999616116910fccec17a63584b5-Abstract-Conference.html)
- [Adaptive Data Debiasing through Bounded Exploration.](http://papers.nips.cc/paper_files/paper/2022/hash/0a166a3d98720697d9028bbe592fa177-Abstract-Conference.html)
- [A Reduction to Binary Approach for Debiasing Multiclass Datasets.](http://papers.nips.cc/paper_files/paper/2022/hash/10eaa0aae94b34308e9b3fa7b677cbe1-Abstract-Conference.html)
- [Combinatorial Bandits with Linear Constraints: Beyond Knapsacks and Fairness.](http://papers.nips.cc/paper_files/paper/2022/hash/13f17f74ec061f1e3e231aca9a43ff23-Abstract-Conference.html)
- [Debiased Machine Learning without Sample-Splitting for Stable Estimators.](http://papers.nips.cc/paper_files/paper/2022/hash/1498a03a04f9bcd3a7d44058fc5dc639-Abstract-Conference.html)
- [Is Sortition Both Representative and Fair?](http://papers.nips.cc/paper_files/paper/2022/hash/165bbd0a0a1b9470ec34d5afec582d2e-Abstract-Conference.html)
- [Fairness in Federated Learning via Core-Stability.](http://papers.nips.cc/paper_files/paper/2022/hash/25e92e33ac8c35fd49f394c37f21b6da-Abstract-Conference.html)
- [Spectral Bias in Practice: The Role of Function Frequency in Generalization.](http://papers.nips.cc/paper_files/paper/2022/hash/306264db5698839230be3642aafc849c-Abstract-Conference.html)
- [FairVFL: A Fair Vertical Federated Learning Framework with Contrastive Adversarial Learning.](http://papers.nips.cc/paper_files/paper/2022/hash/333a7697dbb67f09249337f81c27d749-Abstract-Conference.html)
- [Policy Optimization with Advantage Regularization for Long-Term Fairness in Decision Systems.](http://papers.nips.cc/paper_files/paper/2022/hash/36b76e1f69bbba80d3463f7d6c02bc3d-Abstract-Conference.html)
- [Fairness Transferability Subject to Bounded Distribution Shift.](http://papers.nips.cc/paper_files/paper/2022/hash/4937610670be26d651ecdb4f2206d95f-Abstract-Conference.html)
- [Conformalized Fairness via Quantile Regression.](http://papers.nips.cc/paper_files/paper/2022/hash/4b52b3c50110fc10f6a1a86055682ea2-Abstract-Conference.html)
- [SelecMix: Debiased Learning by Contradicting-pair Sampling.](http://papers.nips.cc/paper_files/paper/2022/hash/5c6f928e3fc5f32ee29a1d916b68e6f5-Abstract-Conference.html)
- [Are Two Heads the Same as One? Identifying Disparate Treatment in Fair Neural Networks.](http://papers.nips.cc/paper_files/paper/2022/hash/698c05933e5f7fde98e567a669d2c752-Abstract-Conference.html)
- [Bounding and Approximating Intersectional Fairness through Marginal Fairness.](http://papers.nips.cc/paper_files/paper/2022/hash/6ae7df1f40f5faeda474b36b61197822-Abstract-Conference.html)
- [All Politics is Local: Redistricting via Local Fairness.](http://papers.nips.cc/paper_files/paper/2022/hash/6f7fa4df2c8a79c164d3697898a32bd9-Abstract-Conference.html)
- [The price of unfairness in linear bandits with biased feedback.](http://papers.nips.cc/paper_files/paper/2022/hash/74bb24dca8334adce292883b4b651eda-Abstract-Conference.html)
- [Learning Debiased Classifier with Biased Committee.](http://papers.nips.cc/paper_files/paper/2022/hash/750046157471c56235a781f2eff6e226-Abstract-Conference.html)
- [Fairness without Demographics through Knowledge Distillation.](http://papers.nips.cc/paper_files/paper/2022/hash/79dc391a2c1067e9ac2b764e31a60377-Abstract-Conference.html)
- [Diagnosing failures of fairness transfer across distribution shift in real-world medical settings.](http://papers.nips.cc/paper_files/paper/2022/hash/7a969c30dc7e74d4e891c8ffb217cf79-Abstract-Conference.html)
- [Fair Wrapping for Black-box Predictions.](http://papers.nips.cc/paper_files/paper/2022/hash/876b45367d9069f0e91e359c57155ab1-Abstract-Conference.html)
- [Fair Rank Aggregation.](http://papers.nips.cc/paper_files/paper/2022/hash/974309ef51ebd89034adc64a57e304f2-Abstract-Conference.html)
- [Group Meritocratic Fairness in Linear Contextual Bandits.](http://papers.nips.cc/paper_files/paper/2022/hash/9a1dab894ce96cb8339c2fadd85a100b-Abstract-Conference.html)
- [Debiasing Graph Neural Networks via Learning Disentangled Causal Substructure.](http://papers.nips.cc/paper_files/paper/2022/hash/9e47a0bc530cc88b09b7670d2c130a29-Abstract-Conference.html)
- [On the Tradeoff Between Robustness and Fairness.](http://papers.nips.cc/paper_files/paper/2022/hash/a80ebbb4ec9e9b39789318a0a61e2e43-Abstract-Conference.html)
- [Self-Supervised Fair Representation Learning without Demographics.](http://papers.nips.cc/paper_files/paper/2022/hash/ad991bbc381626a8e44dc5414aa136a8-Abstract-Conference.html)
- [Fair Bayes-Optimal Classifiers Under Predictive Parity.](http://papers.nips.cc/paper_files/paper/2022/hash/b1d9c7e7bd265d81aae8d74a7a6bd7f1-Abstract-Conference.html)
- [Debiased, Longitudinal and Coordinated Drug Recommendation through Multi-Visit Clinic Records.](http://papers.nips.cc/paper_files/paper/2022/hash/b295b3a940706f431076c86b78907757-Abstract-Conference.html)
- [DeepMed: Semiparametric Causal Mediation Analysis with Debiased Deep Learning.](http://papers.nips.cc/paper_files/paper/2022/hash/b57939005a3cbe40f49b66a0efd6fc8c-Abstract-Conference.html)
- [Domain Adaptation meets Individual Fairness. And they get along.](http://papers.nips.cc/paper_files/paper/2022/hash/b9e0ceee9751ae8b5c6603c029e4ca42-Abstract-Conference.html)
- [Personalized Federated Learning towards Communication Efficiency, Robustness and Fairness.](http://papers.nips.cc/paper_files/paper/2022/hash/c47e6286162ec5442e06fe2b7cb7145f-Abstract-Conference.html)
- [Certifying Some Distributional Fairness with Subpopulation Decomposition.](http://papers.nips.cc/paper_files/paper/2022/hash/c8e9a2beb84ab1a616edb89581c4b32a-Abstract-Conference.html)
- [Fair Ranking with Noisy Protected Attributes.](http://papers.nips.cc/paper_files/paper/2022/hash/cdd0640218a27e9e2c0e52e324e25db0-Abstract-Conference.html)
- [Debiased Self-Training for Semi-Supervised Learning.](http://papers.nips.cc/paper_files/paper/2022/hash/d10d6b28d74c4f0fcab588feeb6fe7d6-Abstract-Conference.html)
- [Uncovering the Structural Fairness in Graph Contrastive Learning.](http://papers.nips.cc/paper_files/paper/2022/hash/d13565c82d1e44eda2da3bd00b35ca11-Abstract-Conference.html)
- [Transferring Fairness under Distribution Shifts via Fair Consistency Regularization.](http://papers.nips.cc/paper_files/paper/2022/hash/d1dbaabf454a479ca86309e66592c7f6-Abstract-Conference.html)
- [Pushing the limits of fairness impossibility: Who's the fairest of them all?](http://papers.nips.cc/paper_files/paper/2022/hash/d3222559698f41247261b7a6c2bbaedc-Abstract-Conference.html)
- [Turning the Tables: Biased, Imbalanced, Dynamic Tabular Datasets for ML Evaluation.](http://papers.nips.cc/paper_files/paper/2022/hash/d9696563856bd350e4e7ac5e5812f23c-Abstract-Datasets_and_Benchmarks.html)
- [Optimal Transport of Classifiers to Fairness.](http://papers.nips.cc/paper_files/paper/2022/hash/da75d2bbf862b86f10241d0887613b41-Abstract-Conference.html)
- [On Learning Fairness and Accuracy on Multiple Subgroups.](http://papers.nips.cc/paper_files/paper/2022/hash/dc96134e169de5aea1ba1fc34dfb8419-Abstract-Conference.html)
- [Fairness Reprogramming.](http://papers.nips.cc/paper_files/paper/2022/hash/de08b3ee7c0043a76ee4a44fe68e90bc-Abstract-Conference.html)
- [Implicit Bias of Gradient Descent on Reparametrized Models: On Equivalence to Mirror Descent.](http://papers.nips.cc/paper_files/paper/2022/hash/dfa1106ea7065899b13f2be9da04efb4-Abstract-Conference.html)
- [Beyond Adult and COMPAS: Fair Multi-Class Prediction via Information Projection.](http://papers.nips.cc/paper_files/paper/2022/hash/fd5013ea0c3f96931dec77174eaf9d80-Abstract-Conference.html)
- [Fair and Optimal Decision Trees: A Dynamic Programming Approach.](http://papers.nips.cc/paper_files/paper/2022/hash/fe248e22b241ae5a9adf11493c8c12bc-Abstract-Conference.html)

### [SDM 2022](https://dblp.uni-trier.de/db/conf/sdm/sdm2022.html)


### [UAI 2022](https://dblp.uni-trier.de/db/conf/uai/uai2022.html)

- [Active approximately metric-fair learning.](https://proceedings.mlr.press/v180/cao22a.html)
- [Quadratic metric elicitation for fairness and beyond.](https://proceedings.mlr.press/v180/hiranandani22a.html)
- [Efficient resource allocation with fairness constraints in restless multi-armed bandits.](https://proceedings.mlr.press/v180/li22e.html)
- [How unfair is private learning?](https://proceedings.mlr.press/v180/sanyal22a.html)

### [WWW 2022](https://dblp.uni-trier.de/db/conf/www/www2022.html)

- [FairGAN: GANs-based Fairness-aware Learning for Recommendations with Implicit Feedback.](https://doi.org/10.1145/3485447.3511958)
- [EDITS: Modeling and Mitigating Data Bias for Graph Neural Networks.](https://doi.org/10.1145/3485447.3512173)
- [Fair k-Center Clustering in MapReduce and Streaming Settings.](https://doi.org/10.1145/3485447.3512188)
- [Unbiased Graph Embedding with Biased Graph Observations.](https://doi.org/10.1145/3485447.3512189)
- [Rating Distribution Calibration for Selection Bias Mitigation in Recommendations.](https://doi.org/10.1145/3485447.3512078)
- [UKD: Debiasing Conversion Rate Estimation via Uncertainty-regularized Knowledge Distillation.](https://doi.org/10.1145/3485447.3512081)
- [Unbiased Sequential Recommendation with Latent Confounders.](https://doi.org/10.1145/3485447.3512092)
- [CBR: Context Bias aware Recommendation for Debiasing User Modeling and Click Prediction✱.](https://doi.org/10.1145/3485447.3512099)
- [Cross Pairwise Ranking for Unbiased Item Recommendation.](https://doi.org/10.1145/3485447.3512010)
- [Left or Right: A Peek into the Political Biases in Email Spam Filtering Algorithms During US Election 2020.](https://doi.org/10.1145/3485447.3512121)
- [Controlled Analyses of Social Biases in Wikipedia Bios.](https://doi.org/10.1145/3485447.3512134)
- [Scheduling Virtual Conferences Fairly: Achieving Equitable Participant and Speaker Satisfaction.](https://doi.org/10.1145/3485447.3512136)
- [What Does Perception Bias on Social Networks Tell Us About Friend Count Satisfaction?](https://doi.org/10.1145/3485447.3511931)
- [Fairness Audit of Machine Learning Models with Confidential Computing.](https://doi.org/10.1145/3485447.3512244)
- [End-to-End Learning for Fair Ranking Systems.](https://doi.org/10.1145/3485447.3512247)
- [Link Recommendations for PageRank Fairness.](https://doi.org/10.1145/3485447.3512249)
- [Privacy-Preserving Fair Learning of Support Vector Machine with Homomorphic Encryption.](https://doi.org/10.1145/3485447.3512252)
- [Alexa, in you, I trust! Fairness and Interpretability Issues in E-commerce Search through Smart Speakers.](https://doi.org/10.1145/3485447.3512265)
- [Regulatory Instruments for Fair Personalized Pricing.](https://doi.org/10.1145/3485447.3512046)

### Others 2022

#### [WSDM 2022](https://dblp.uni-trier.de/db/conf/wsdm/wsdm2022.html)

- [k-Clustering with Fair Outliers.](https://doi.org/10.1145/3488560.3498485)
- [Toward Pareto Efficient Fairness-Utility Trade-off in Recommendation through Reinforcement Learning.](https://doi.org/10.1145/3488560.3498487)
- [It Is Different When Items Are Older: Debiasing Recommendations When Selection Bias and User Preferences Are Dynamic.](https://doi.org/10.1145/3488560.3498375)
- [Introducing the Expohedron for Efficient Pareto-optimal Fairness-Utility Amortizations in Repeated Rankings.](https://doi.org/10.1145/3488560.3498490)
- [Diversified Subgraph Query Generation with Group Fairness.](https://doi.org/10.1145/3488560.3498525)
- [Learning Fair Node Representations with Graph Counterfactual Fairness.](https://doi.org/10.1145/3488560.3498391)
- [Understanding and Mitigating the Effect of Outliers in Fair Ranking.](https://doi.org/10.1145/3488560.3498441)
- [Enumerating Fair Packages for Group Recommendations.](https://doi.org/10.1145/3488560.3498432)
- [Towards Unbiased and Robust Causal Ranking for Recommender Systems.](https://doi.org/10.1145/3488560.3498521)
- [Assessing Algorithmic Biases for Musical Version Identification.](https://doi.org/10.1145/3488560.3498397)
- [Towards Fair Classifiers Without Sensitive Attributes: Exploring Biases in Related Features.](https://doi.org/10.1145/3488560.3498493)
- [Fighting Mainstream Bias in Recommender Systems via Local Fine Tuning.](https://doi.org/10.1145/3488560.3498427)

## 2021

### [AAAI 2021](https://dblp.uni-trier.de/db/conf/aaai/aaai2021.html)

- [Learning Disentangled Representation for Fair Facial Attribute Classification via Fairness-aware Information Alignment.](https://ojs.aaai.org/index.php/AAAI/article/view/16341)
- [Fairness-aware News Recommendation with Decomposed Adversarial Learning.](https://ojs.aaai.org/index.php/AAAI/article/view/16573)
- [Fair and Truthful Mechanisms for Dichotomous Valuations.](https://ojs.aaai.org/index.php/AAAI/article/view/16647)
- [Maximin Fairness with Mixed Divisible and Indivisible Goods.](https://ojs.aaai.org/index.php/AAAI/article/view/16653)
- [Protecting the Protected Group: Circumventing Harmful Fairness.](https://ojs.aaai.org/index.php/AAAI/article/view/16654)
- [Fairness, Semi-Supervised Learning, and More: A General Framework for Clustering with Stochastic Pairwise Constraints.](https://ojs.aaai.org/index.php/AAAI/article/view/16842)
- [The Importance of Modeling Data Missingness in Algorithmic Fairness: A Causal Perspective.](https://ojs.aaai.org/index.php/AAAI/article/view/16926)
- [Controllable Guarantees for Fair Outcomes via Contrastive Information Estimation.](https://ojs.aaai.org/index.php/AAAI/article/view/16931)
- [Constructing a Fair Classifier with Generated Fair Data.](https://ojs.aaai.org/index.php/AAAI/article/view/16965)
- [Improving Fairness and Privacy in Selection Problems.](https://ojs.aaai.org/index.php/AAAI/article/view/16986)
- [Counterfactual Fairness with Disentangled Causal Effect Variational Autoencoder.](https://ojs.aaai.org/index.php/AAAI/article/view/16990)
- [Exacerbating Algorithmic Bias through Fairness Attacks.](https://ojs.aaai.org/index.php/AAAI/article/view/17080)
- [Minimum Robust Multi-Submodular Cover for Fairness.](https://ojs.aaai.org/index.php/AAAI/article/view/17100)
- [Robust Fairness Under Covariate Shift.](https://ojs.aaai.org/index.php/AAAI/article/view/17135)
- [Differentially Private and Fair Deep Learning: A Lagrangian Dual Approach.](https://ojs.aaai.org/index.php/AAAI/article/view/17193)
- [Fairness in Forecasting and Learning Linear Dynamical Systems.](https://ojs.aaai.org/index.php/AAAI/article/view/17328)
- [Variational Fair Clustering.](https://ojs.aaai.org/index.php/AAAI/article/view/17336)
- [Individual Fairness in Kidney Exchange Programs.](https://ojs.aaai.org/index.php/AAAI/article/view/17369)
- [Fair Representations by Compression.](https://ojs.aaai.org/index.php/AAAI/article/view/17370)
- [Fair Influence Maximization: a Welfare Optimization Approach.](https://ojs.aaai.org/index.php/AAAI/article/view/17383)
- [Group Fairness by Probabilistic Modeling with Latent Fair Decisions.](https://ojs.aaai.org/index.php/AAAI/article/view/17431)
- [How Linguistically Fair Are Multilingual Pre-Trained Language Models?](https://ojs.aaai.org/index.php/AAAI/article/view/17505)
- [Fairness in Influence Maximization through Randomization.](https://ojs.aaai.org/index.php/AAAI/article/view/17725)
- [Fair and Interpretable Algorithmic Hiring using Evolutionary Many Objective Optimization.](https://ojs.aaai.org/index.php/AAAI/article/view/17737)

### [AISTATS 2021](https://dblp.uni-trier.de/db/conf/aistats/aistats2021.html)

- [Learning Individually Fair Classifier with Path-Specific Causal-Effect Constraint.](http://proceedings.mlr.press/v130/chikahara21a.html)
- [Learning Smooth and Fair Representations.](http://proceedings.mlr.press/v130/gitiaux21a.html)
- [Learning Fair Scoring Functions: Bipartite Ranking under ROC-based Fairness Constraints.](http://proceedings.mlr.press/v130/vogel21a.html)
- [Algorithms for Fairness in Sequential Decision Making.](http://proceedings.mlr.press/v130/wen21a.html)
- [All of the Fairness for Edge Prediction with Optimal Transport.](http://proceedings.mlr.press/v130/laclau21a.html)
- [Differentiable Causal Discovery Under Unmeasured Confounding.](http://proceedings.mlr.press/v130/bhattacharya21a.html)
- [Causal Modeling with Stochastic Confounders.](http://proceedings.mlr.press/v130/vinh-vo21a.html)
- [Fair for All: Best-effort Fairness Guarantees for Classification.](http://proceedings.mlr.press/v130/krishnaswamy21a.html)

### [BIGDATA 2021](https://dblp.uni-trier.de/db/conf/bigdataconf/bigdataconf2021.html)

- [An Effective, Robust and Fairness-aware Hate Speech Detection Framework.](https://doi.org/10.1109/BigData52589.2021.9672022)
- [Fairness-aware Bandit-based Recommendation.](https://doi.org/10.1109/BigData52589.2021.9671959)
- [ExgFair: A Crowdsourcing Data Exchange Approach To Fair Human Face Datasets Augmentation.](https://doi.org/10.1109/BigData52589.2021.9671973)
- [Bayesian model for Fairness in sampling from clustered data and FP-FN error rates.](https://doi.org/10.1109/BigData52589.2021.9671353)

### [CIKM 2021](https://dblp.uni-trier.de/db/conf/cikm/cikm2021.html)

> TBD

### [FAT\* 2021](https://dblp.uni-trier.de/db/conf/fat/fat2021.html)

- [Black Feminist Musings on Algorithmic Oppression.](https://doi.org/10.1145/3442188.3445929)
- [Price Discrimination with Fairness Constraints.](https://doi.org/10.1145/3442188.3445864)
- [Fairness Violations and Mitigation under Covariate Shift.](https://doi.org/10.1145/3442188.3445865)
- [Reasons, Values, Stakeholders: A Philosophical Framework for Explainable Artificial Intelligence.](https://doi.org/10.1145/3442188.3445866)
- [Allocating Opportunities in a Dynamic Model of Intergenerational Mobility.](https://doi.org/10.1145/3442188.3445867)
- [Corporate Social Responsibility via Multi-Armed Bandits.](https://doi.org/10.1145/3442188.3445868)
- [Biases in Generative Art: A Causal Look from the Lens of Art History.](https://doi.org/10.1145/3442188.3445869)
- [Designing an Online Infrastructure for Collecting AI Data From People With Disabilities.](https://doi.org/10.1145/3442188.3445870)
- [Fifty Shades of Grey: In Praise of a Nuanced Approach Towards Trustworthy Design.](https://doi.org/10.1145/3442188.3445871)
- [Representativeness in Statistics, Politics, and Machine Learning.](https://doi.org/10.1145/3442188.3445872)
- [The Distributive Effects of Risk Prediction in Environmental Compliance: Algorithmic Design, Environmental Justice, and Public Policy.](https://doi.org/10.1145/3442188.3445873)
- [Computer Science Communities: Who is Speaking, and Who is Listening to the Women? Using an Ethics of Care to Promote Diverse Voices.](https://doi.org/10.1145/3442188.3445874)
- [Differential Tweetment: Mitigating Racial Dialect Bias in Harmful Tweet Detection.](https://doi.org/10.1145/3442188.3445875)
- [Group Fairness: Independence Revisited.](https://doi.org/10.1145/3442188.3445876)
- [Towards Fair Deep Anomaly Detection.](https://doi.org/10.1145/3442188.3445878)
- [Can You Fake It Until You Make It?: Impacts of Differentially Private Synthetic Data on Downstream Classification Fairness.](https://doi.org/10.1145/3442188.3445879)
- [Documenting Computer Vision Datasets: An Invitation to Reflexive Data Practices.](https://doi.org/10.1145/3442188.3445880)
- [Leveraging Administrative Data for Bias Audits: Assessing Disparate Coverage with Mobility Data for COVID-19 Policy.](https://doi.org/10.1145/3442188.3445881)
- [Better Together?: How Externalities of Size Complicate Notions of Solidarity and Actuarial Fairness.](https://doi.org/10.1145/3442188.3445882)
- [Removing Spurious Features can Hurt Accuracy and Affect Groups Disproportionately.](https://doi.org/10.1145/3442188.3445883)
- [Evaluating Fairness of Machine Learning Models Under Uncertain and Incomplete Information.](https://doi.org/10.1145/3442188.3445884)
- [Data Leverage: A Framework for Empowering the Public in its Relationship with Technology Companies.](https://doi.org/10.1145/3442188.3445885)
- [The Use and Misuse of Counterfactuals in Ethical Machine Learning.](https://doi.org/10.1145/3442188.3445886)
- [Mitigating Bias in Set Selection with Noisy Protected Attributes.](https://doi.org/10.1145/3442188.3445887)
- [What We Can't Measure, We Can't Understand: Challenges to Demographic Data Procurement in the Pursuit of Fairness.](https://doi.org/10.1145/3442188.3445888)
- [Standardized Tests and Affirmative Action: The Role of Bias and Variance.](https://doi.org/10.1145/3442188.3445889)
- [The Sanction of Authority: Promoting Public Trust in AI.](https://doi.org/10.1145/3442188.3445890)
- [Algorithmic Fairness in Predicting Opioid Use Disorder using Machine Learning.](https://doi.org/10.1145/3442188.3445891)
- [Avoiding Disparity Amplification under Different Worldviews.](https://doi.org/10.1145/3442188.3445892)
- [Spoken Corpora Data, Automatic Speech Recognition, and Bias Against African American Language: The case of Habitual 'Be'.](https://doi.org/10.1145/3442188.3445893)
- [Leave-one-out Unfairness.](https://doi.org/10.1145/3442188.3445894)
- [Fairness, Welfare, and Equity in Personalized Pricing.](https://doi.org/10.1145/3442188.3445895)
- [Re-imagining Algorithmic Fairness in India and Beyond.](https://doi.org/10.1145/3442188.3445896)
- [Narratives and Counternarratives on Data Sharing in Africa.](https://doi.org/10.1145/3442188.3445897)
- [This Whole Thing Smacks of Gender: Algorithmic Exclusion in Bioimpedance-based Body Composition Analysis.](https://doi.org/10.1145/3442188.3445898)
- [Algorithmic Recourse: from Counterfactual Explanations to Interventions.](https://doi.org/10.1145/3442188.3445899)
- [A Semiotics-based epistemic tool to reason about ethical issues in digital technology design and development.](https://doi.org/10.1145/3442188.3445900)
- [Measurement and Fairness.](https://doi.org/10.1145/3442188.3445901)
- [Fairness in Risk Assessment Instruments: Post-Processing to Achieve Counterfactual Equalized Odds.](https://doi.org/10.1145/3442188.3445902)
- [High Dimensional Model Explanations: An Axiomatic Approach.](https://doi.org/10.1145/3442188.3445903)
- [An Agent-based Model to Evaluate Interventions on Online Dating Platforms to Decrease Racial Homogamy.](https://doi.org/10.1145/3442188.3445904)
- [Designing Accountable Systems.](https://doi.org/10.1145/3442188.3445905)
- [Socially Fair k-Means Clustering.](https://doi.org/10.1145/3442188.3445906)
- [Towards Cross-Lingual Generalization of Translation Gender Bias.](https://doi.org/10.1145/3442188.3445907)
- [A Pilot Study in Surveying Clinical Judgments to Evaluate Radiology Report Generation.](https://doi.org/10.1145/3442188.3445909)
- [Fairness Through Robustness: Investigating Robustness Disparity in Deep Learning.](https://doi.org/10.1145/3442188.3445910)
- [Operationalizing Framing to Support Multiperspective Recommendations of Opinion Pieces.](https://doi.org/10.1145/3442188.3445911)
- [Bridging Machine Learning and Mechanism Design towards Algorithmic Fairness.](https://doi.org/10.1145/3442188.3445912)
- [Fair Clustering via Equitable Group Representations.](https://doi.org/10.1145/3442188.3445913)
- [You Can't Sit With Us: Exclusionary Pedagogy in AI Ethics Education.](https://doi.org/10.1145/3442188.3445914)
- [Fair Classification with Group-Dependent Label Noise.](https://doi.org/10.1145/3442188.3445915)
- [Censorship of Online Encyclopedias: Implications for NLP Models.](https://doi.org/10.1145/3442188.3445916)
- [Impossible Explanations?: Beyond explainable AI in the GDPR from a COVID-19 use case scenario.](https://doi.org/10.1145/3442188.3445917)
- [Towards Accountability for Machine Learning Datasets: Practices from Software Engineering and Infrastructure.](https://doi.org/10.1145/3442188.3445918)
- [Fairness, Equality, and Power in Algorithmic Decision-Making.](https://doi.org/10.1145/3442188.3445919)
- [One Label, One Billion Faces: Usage and Consistency of Racial Categories in Computer Vision.](https://doi.org/10.1145/3442188.3445920)
- [Reviewable Automated Decision-Making: A Framework for Accountable Algorithmic Systems.](https://doi.org/10.1145/3442188.3445921)
- [On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?](https://doi.org/10.1145/3442188.3445922)
- [Formalizing Trust in Artificial Intelligence: Prerequisites, Causes and Goals of Human Trust in AI.](https://doi.org/10.1145/3442188.3445923)
- [TILT: A GDPR-Aligned Transparency Information Language and Toolkit for Practical Privacy Engineering.](https://doi.org/10.1145/3442188.3445925)
- [From Papers to Programs: Courts, Corporations, Clinics and the Battle over Computerized Psychological Testing.](https://doi.org/10.1145/3442188.3445926)
- [A Statistical Test for Probabilistic Fairness.](https://doi.org/10.1145/3442188.3445927)
- [Building and Auditing Fair Algorithms: A Case Study in Candidate Screening.](https://doi.org/10.1145/3442188.3445928)
- [The Effect of the Rooney Rule on Implicit Bias in the Long Term.](https://doi.org/10.1145/3442188.3445930)
- [I agree with the decision, but they didn't deserve this: Future Developers' Perception of Fairness in Algorithmic Decisions.](https://doi.org/10.1145/3442188.3445931)
- [Image Representations Learned With Unsupervised Pre-Training Contain Human-like Biases.](https://doi.org/10.1145/3442188.3445932)
- [From Optimizing Engagement to Measuring Value.](https://doi.org/10.1145/3442188.3445933)
- [Chasing Your Long Tails: Differentially Private Prediction in Health Care Settings.](https://doi.org/10.1145/3442188.3445934)
- [Algorithmic Impact Assessments and Accountability: The Co-construction of Impacts.](https://doi.org/10.1145/3442188.3445935)
- [On the Moral Justification of Statistical Parity.](https://doi.org/10.1145/3442188.3445936)
- [Outlining Traceability: A Principle for Operationalizing Accountability in Computing Systems.](https://doi.org/10.1145/3442188.3445937)
- [An Action-Oriented AI Policy Toolkit for Technology Audits by Community Advocates and Activists.](https://doi.org/10.1145/3442188.3445938)
- [The Ethics of Emotion in Artificial Intelligence Systems.](https://doi.org/10.1145/3442188.3445939)
- [Detecting discriminatory risk through data annotation based on Bayesian inferences.](https://doi.org/10.1145/3442188.3445940)
- [How can I choose an explainer?: An Application-grounded Evaluation of Post-hoc Explanations.](https://doi.org/10.1145/3442188.3445941)
- [The Algorithmic Leviathan: Arbitrariness, Fairness, and Opportunity in Algorithmic Decision Making Systems.](https://doi.org/10.1145/3442188.3445942)
- [Epistemic values in feature importance methods: Lessons from feminist epistemology.](https://doi.org/10.1145/3442188.3445943)
- [A Bayesian Model of Cash Bail Decisions.](https://doi.org/10.1145/3442188.3445908)
- [The effect of differential victim crime reporting on predictive policing systems.](https://doi.org/10.1145/3442188.3445877)
- [Value Cards: An Educational Toolkit for Teaching Social Impacts of Machine Learning through Deliberation.](https://doi.org/10.1145/3442188.3445971)
- [BOLD: Dataset and Metrics for Measuring Biases in Open-Ended Language Generation.](https://doi.org/10.1145/3442188.3445924)
- [When the Umpire is also a Player: Bias in Private Label Product Recommendations on E-commerce Marketplaces.](https://doi.org/10.1145/3442188.3445944)

### [ICDM 2021](https://dblp.uni-trier.de/db/conf/icdm/icdm2021.html)

- [Fair Decision-making Under Uncertainty.](https://doi.org/10.1109/ICDM51629.2021.00100)
- [Promoting Fairness through Hyperparameter Optimization.](https://doi.org/10.1109/ICDM51629.2021.00119)
- [Fair Graph Auto-Encoder for Unbiased Graph Representations with Wasserstein Distance.](https://doi.org/10.1109/ICDM51629.2021.00122)
- [A Multi-view Confidence-calibrated Framework for Fair and Stable Graph Representation Learning.](https://doi.org/10.1109/ICDM51629.2021.00194)
- [Unified Fairness from Data to Learning Algorithm.](https://doi.org/10.1109/ICDM51629.2021.00195)

### [ICLR 2021](https://dblp.uni-trier.de/db/conf/iclr/iclr2021.html)

- [SenSeI: Sensitive Set Invariance for Enforcing Individual Fairness.](https://openreview.net/forum?id=DktZb97_Fx)
- [Individually Fair Gradient Boosting.](https://openreview.net/forum?id=JBAa9we1AL)
- [On Statistical Bias In Active Learning: How and When to Fix It.](https://openreview.net/forum?id=JiYq3eqTKY)
- [FairFil: Contrastive Neural Debiasing Method for Pretrained Text Encoders.](https://openreview.net/forum?id=N6JECD-PI5w)
- [Fair Mixup: Fairness via Interpolation.](https://openreview.net/forum?id=DNl5s5BXeBn)
- [Individually Fair Rankings.](https://openreview.net/forum?id=71zCSP_HuBN)
- [FairBatch: Batch Selection for Model Fairness.](https://openreview.net/forum?id=YNnpaAKeCfx)
- [INT: An Inequality Benchmark for Evaluating Generalization in Theorem Proving.](https://openreview.net/forum?id=O6LPudowNQm)
- [Debiasing Concept-based Explanations with Causal Analysis.](https://openreview.net/forum?id=6puUoArESGp)
- [Unbiased Teacher for Semi-Supervised Object Detection.](https://openreview.net/forum?id=MJIve1zgR_)
- [Rethinking Soft Labels for Knowledge Distillation: A Bias-Variance Tradeoff Perspective.](https://openreview.net/forum?id=gIHd-5X324)
- [Direction Matters: On the Implicit Bias of Stochastic Gradient Descent with Moderate Learning Rate.](https://openreview.net/forum?id=3X64RLgzY6O)
- [A unifying view on implicit bias in training linear neural networks.](https://openreview.net/forum?id=ZsZM-4iMQkH)
- [What Makes Instance Discrimination Good for Transfer Learning?](https://openreview.net/forum?id=tC6iW2UUbJf)
- [Clustering-friendly Representation Learning via Instance Discrimination and Feature Decorrelation.](https://openreview.net/forum?id=e12NDM7wkEY)
- [Shape-Texture Debiased Neural Network Training.](https://openreview.net/forum?id=Db4yerZTYkz)
- [The inductive bias of ReLU networks on orthogonally separable data.](https://openreview.net/forum?id=krz7T0xU9Z_)
- [Statistical inference for individual fairness.](https://openreview.net/forum?id=z9k8BWL-_2u)
- [What they do when in doubt: a study of inductive biases in seq2seq learners.](https://openreview.net/forum?id=YmA86Zo-P_t)
- [Learning from others' mistakes: Avoiding dataset biases without modeling them.](https://openreview.net/forum?id=Hf3qXoiNkR)
- [Predicting Inductive Biases of Pre-Trained Models.](https://openreview.net/forum?id=mNtmhaDkAr)
- [Does enhanced shape bias improve neural network robustness to common corruptions?](https://openreview.net/forum?id=yUxUNaj2Sl)
- [On Dyadic Fairness: Exploring and Mitigating Bias in Graph Connections.](https://openreview.net/forum?id=xgGS6PmzNq6)
- [Why resampling outperforms reweighting for correcting sampling bias with stochastic gradients.](https://openreview.net/forum?id=iQQK02mxVIT)
- [Towards Resolving the Implicit Bias of Gradient Descent for Matrix Factorization: Greedy Low-Rank Learning.](https://openreview.net/forum?id=AHOs7Sm5H7R)

### [ICML 2021](https://dblp.uni-trier.de/db/conf/icml/icml2021.html)

- [Fair Classification with Noisy Protected Attributes: A Framework with Provable Guarantees.](http://proceedings.mlr.press/v139/celis21a.html)
- [Fairness and Bias in Online Selection.](http://proceedings.mlr.press/v139/correa21a.html)
- [Characterizing Fairness Over the Set of Good Models Under Selective Labels.](http://proceedings.mlr.press/v139/coston21a.html)
- [On the Problem of Underranking in Group-Fair Ranking.](http://proceedings.mlr.press/v139/gorantla21a.html)
- [Fairness for Image Generation with Uncertain Sensitive Attributes.](http://proceedings.mlr.press/v139/jalal21b.html)
- [Fair Selective Classification Via Sufficiency.](http://proceedings.mlr.press/v139/lee21b.html)
- [Ditto: Fair and Robust Federated Learning Through Personalization.](http://proceedings.mlr.press/v139/li21h.html)
- [Approximate Group Fairness for Clustering.](http://proceedings.mlr.press/v139/li21j.html)
- [Blind Pareto Fairness and Subgroup Robustness.](http://proceedings.mlr.press/v139/martinez21a.html)
- [Testing Group Fairness via Optimal Transport Projections.](http://proceedings.mlr.press/v139/si21a.html)
- [Collaborative Bayesian Optimization with Fair Regret.](http://proceedings.mlr.press/v139/sim21b.html)
- [Fairness of Exposure in Stochastic Bandits.](http://proceedings.mlr.press/v139/wang21b.html)
- [To be Robust or to be Fair: Towards Fairness in Adversarial Training.](http://proceedings.mlr.press/v139/xu21b.html)

### [IJCAI 2021](https://dblp.uni-trier.de/db/conf/ijcai/ijcai2021.html)

- [Bias Silhouette Analysis: Towards Assessing the Quality of Bias Metrics for Word Embedding Models.](https://doi.org/10.24963/ijcai.2021/77)
- [Decision Making with Differential Privacy under a Fairness Lens.](https://doi.org/10.24963/ijcai.2021/78)
- [An Examination of Fairness of AI Models for Deepfake Detection.](https://doi.org/10.24963/ijcai.2021/79)
- [Towards Reducing Biases in Combining Multiple Experts Online.](https://doi.org/10.24963/ijcai.2021/416)
- [Understanding the Effect of Bias in Deep Anomaly Detection.](https://doi.org/10.24963/ijcai.2021/456)
- [Graph Debiased Contrastive Learning with Joint Representation Clustering.](https://doi.org/10.24963/ijcai.2021/473)
- [Controlling Fairness and Bias in Dynamic Learning-to-Rank (Extended Abstract).](https://doi.org/10.24963/ijcai.2021/655)

### [KDD 2021](https://dblp.uni-trier.de/db/conf/kdd/kdd2021.html)

- [Towards Model-Agnostic Post-Hoc Adjustment for Balancing Ranking Fairness and Algorithm Utility.](https://doi.org/10.1145/3447548.3467251)
- [Individual Fairness for Graph Neural Networks: A Ranking based Approach.](https://doi.org/10.1145/3447548.3467266)
- [Maxmin-Fair Ranking: Individual Fairness under Group-Fairness Constraints.](https://doi.org/10.1145/3447548.3467349)
- [Federated Adversarial Debiasing for Fair and Transferable Representations.](https://doi.org/10.1145/3447548.3467281)
- [Explaining Algorithmic Fairness Through Fairness-Aware Causal Path Decomposition.](https://doi.org/10.1145/3447548.3467258)
- [Deep Clustering based Fair Outlier Detection.](https://doi.org/10.1145/3447548.3467225)
- [Deconfounded Recommendation for Alleviating Bias Amplification.](https://doi.org/10.1145/3447548.3467249)
- [Understanding and Improving Fairness-Accuracy Trade-offs in Multi-Task Learning.](https://doi.org/10.1145/3447548.3467326)
- [Fairness-Aware Online Meta-learning.](https://doi.org/10.1145/3447548.3467389)

### [NIPS 2021](https://dblp.uni-trier.de/db/conf/nips/neurips2021.html)

> TBD

### [SDM 2021](https://dblp.uni-trier.de/db/conf/sdm/sdm2021.html)

- [Fairness-aware Agnostic Federated Learning.](https://doi.org/10.1137/1.9781611976700.21)
- [Equitable Allocation of Healthcare Resources with Fair Survival Models.](https://doi.org/10.1137/1.9781611976700.22)
- [Fair Classification Under Strict Unawareness.](https://doi.org/10.1137/1.9781611976700.23)

### [UAI 2021](https://dblp.uni-trier.de/db/conf/uai/uai2021.html)

> TBD

### [WWW 2021](https://dblp.uni-trier.de/db/conf/www/www2021.html)

> TBD

### Others 2021

#### [WSDM 2021](https://dblp.uni-trier.de/db/conf/wsdm/wsdm2021.html)

- [Popularity-Opportunity Bias in Collaborative Filtering.](https://doi.org/10.1145/3437963.3441820)
- [Deconfounding with Networked Observational Data in a Dynamic Environment.](https://doi.org/10.1145/3437963.3441818)
- [Causal Transfer Random Forest: Combining Logged Data and Randomized Experiments for Robust Prediction.](https://doi.org/10.1145/3437963.3441722)
- [Split-Treatment Analysis to Rank Heterogeneous Causal Effects for Prospective Interventions.](https://doi.org/10.1145/3437963.3441821)
- [Explain and Predict, and then Predict Again.](https://doi.org/10.1145/3437963.3441758)
- [Combating Selection Biases in Recommender Systems with a Few Unbiased Ratings.](https://doi.org/10.1145/3437963.3441799)
- [Practical Compositional Fairness: Understanding Fairness in Multi-Component Recommender Systems.](https://doi.org/10.1145/3437963.3441732)
- [Towards Long-term Fairness in Recommendation.](https://doi.org/10.1145/3437963.3441824)
- [Unifying Online and Counterfactual Learning to Rank: A Novel Counterfactual Estimator that Effectively Utilizes Online Interventions.](https://doi.org/10.1145/3437963.3441794)
- [Interpretable Ranking with Generalized Additive Models.](https://doi.org/10.1145/3437963.3441796)

#### [COLT 2021](learningtheory.org/colt2021/)

- [Approximation Algorithms for Socially Fair Clustering.](http://proceedings.mlr.press/v134/makarychev21a.html)

## 2020

### [AAAI 2020](https://dblp.uni-trier.de/db/conf/aaai/aaai2020.html)

- [Faking Fairness via Stealthily Biased Sampling.](https://aaai.org/ojs/index.php/AAAI/article/view/5377)
- [Differentially Private and Fair Classification via Calibrated Functional Mechanism.](https://aaai.org/ojs/index.php/AAAI/article/view/5402)
- [Bursting the Filter Bubble: Fairness-Aware Network Link Prediction.](https://aaai.org/ojs/index.php/AAAI/article/view/5429)
- [Making Existing Clusterings Fairer: Algorithms, Complexity Results and Insights.](https://aaai.org/ojs/index.php/AAAI/article/view/5783)
- [Fairness in Network Representation by Latent Structural Heterogeneity in Observational Data.](https://aaai.org/ojs/index.php/AAAI/article/view/5792)
- [Pairwise Fairness for Ranking and Regression.](https://aaai.org/ojs/index.php/AAAI/article/view/5970)
- [Achieving Fairness in the Stochastic Multi-Armed Bandit Problem.](https://aaai.org/ojs/index.php/AAAI/article/view/5986)
- [Fairness for Robust Log Loss Classification.](https://aaai.org/ojs/index.php/AAAI/article/view/6002)
- [Learning Fair Naive Bayes Classifiers by Discovering and Eliminating Discrimination Patterns.](https://aaai.org/ojs/index.php/AAAI/article/view/6565)

### [AISTATS 2020](https://dblp.uni-trier.de/db/conf/aistats/aistats2020.html)

- [Stretching the Effectiveness of MLE from Accuracy to Bias for Pairwise Comparisons.](http://proceedings.mlr.press/v108/wang20a.html)
- [Learning Fair Representations for Kernel Models.](http://proceedings.mlr.press/v108/tan20a.html)
- [Fair Decisions Despite Imperfect Predictions.](http://proceedings.mlr.press/v108/kilbertus20a.html)
- [Identifying and Correcting Label Bias in Machine Learning.](http://proceedings.mlr.press/v108/jiang20a.html)
- [Optimized Score Transformation for Fair Classification.](http://proceedings.mlr.press/v108/wei20a.html)
- [Equalized odds postprocessing under imperfect group information.](http://proceedings.mlr.press/v108/awasthi20a.html)
- [Fairness Evaluation in Presence of Biased Noisy Labels.](http://proceedings.mlr.press/v108/fogliato20a.html)
- [Fair Correlation Clustering.](http://proceedings.mlr.press/v108/ahmadian20a.html)
- [Auditing ML Models for Individual Bias and Unfairness.](http://proceedings.mlr.press/v108/xue20a.html)

### [BIGDATA 2020](https://dblp.uni-trier.de/db/conf/bigdataconf/bigdataconf2020.html)

> TBD

### [CIKM 2020](https://dblp.uni-trier.de/db/conf/cikm/cikm2020.html)

- [Spectral Relaxations and Fair Densest Subgraphs.](https://doi.org/10.1145/3340531.3412036)
- [Fair Class Balancing: Enhancing Model Fairness without Observing Sensitive Attributes.](https://doi.org/10.1145/3340531.3411980)
- [Active Query of Private Demographic Data for Learning Fair Models.](https://doi.org/10.1145/3340531.3412074)
- [Fairness-Aware Learning with Prejudice Free Representations.](https://doi.org/10.1145/3340531.3412150)
- [Denoising Individual Bias for Fairer Binary Submatrix Detection.](https://doi.org/10.1145/3340531.3412156)
- [LiFT: A Scalable Framework for Measuring Fairness in ML Applications.](https://doi.org/10.1145/3340531.3412705)

### [FAT\* 2020](https://dblp.uni-trier.de/db/conf/fat/fat2020.html)

- [What to account for when accounting for algorithms: a systematic literature review on algorithmic accountability.](https://doi.org/10.1145/3351095.3372833)
- [Algorithmic realism: expanding the boundaries of algorithmic thought.](https://doi.org/10.1145/3351095.3372840)
- [Algorithmic accountability in public administration: the GDPR paradox.](https://doi.org/10.1145/3351095.3373153)
- [Closing the AI accountability gap: defining an end-to-end framework for internal algorithmic auditing.](https://doi.org/10.1145/3351095.3372873)
- [Toward situated interventions for algorithmic equity: lessons from the field.](https://doi.org/10.1145/3351095.3372874)
- [Explainability fact sheets: a framework for systematic assessment of explainable approaches.](https://doi.org/10.1145/3351095.3372870)
- [Multi-layered explanations from algorithmic impact assessments in the GDPR.](https://doi.org/10.1145/3351095.3372875)
- [The hidden assumptions behind counterfactual explanations and principal reasons.](https://doi.org/10.1145/3351095.3372830)
- [Why does my model fail?: contrastive local explanations for retail forecasting.](https://doi.org/10.1145/3351095.3372824)
- ["The human body is a black box": supporting clinical decision-making with deep learning.](https://doi.org/10.1145/3351095.3372827)
- [Assessing algorithmic fairness with unobserved protected class using data combination.](https://doi.org/10.1145/3351095.3373154)
- [FlipTest: fairness testing via optimal transport.](https://doi.org/10.1145/3351095.3372845)
- [Implications of AI (un-)fairness in higher education admissions: the effects of perceived AI (un-)fairness on exit, voice and organizational reputation.](https://doi.org/10.1145/3351095.3372867)
- [Auditing radicalization pathways on YouTube.](https://doi.org/10.1145/3351095.3372879)
- [Case study: predictive fairness to reduce misdemeanor recidivism through social service interventions.](https://doi.org/10.1145/3351095.3372863)
- [The concept of fairness in the GDPR: a linguistic and contextual interpretation.](https://doi.org/10.1145/3351095.3372868)
- [Studying up: reorienting the study of algorithmic fairness around issues of power.](https://doi.org/10.1145/3351095.3372859)
- [POTs: protective optimization technologies.](https://doi.org/10.1145/3351095.3372853)
- [Fair decision making using privacy-protected data.](https://doi.org/10.1145/3351095.3372872)
- [Fairness warnings and fair-MAML: learning fairly with minimal data.](https://doi.org/10.1145/3351095.3372839)
- [From ethics washing to ethics bashing: a view on tech ethics from within moral philosophy.](https://doi.org/10.1145/3351095.3372860)
- [Onward for the freedom of others: marching beyond the AI ethics.](https://doi.org/10.1145/3351095.3373152)
- [Whose side are ethics codes on?: power, responsibility and the social good.](https://doi.org/10.1145/3351095.3372844)
- [Algorithmic targeting of social policies: fairness, accuracy, and distributed governance.](https://doi.org/10.1145/3351095.3375784)
- [Roles for computing in social change.](https://doi.org/10.1145/3351095.3372871)
- [Regulating transparency?: Facebook, Twitter and the german network enforcement act.](https://doi.org/10.1145/3351095.3372856)
- [The relationship between trust in AI and trustworthy machine learning technologies.](https://doi.org/10.1145/3351095.3372834)
- [The philosophical basis of algorithmic recourse.](https://doi.org/10.1145/3351095.3372876)
- [Value-laden disciplinary shifts in machine learning.](https://doi.org/10.1145/3351095.3373157)
- [Effect of confidence and explanation on accuracy and trust calibration in AI-assisted decision making.](https://doi.org/10.1145/3351095.3372852)
- [Lessons from archives: strategies for collecting sociocultural data in machine learning.](https://doi.org/10.1145/3351095.3372829)
- [Data in New Delhi's predictive policing system.](https://doi.org/10.1145/3351095.3372865)
- [Garbage in, garbage out?: do machine learning application papers in social computing report where human-labeled training data comes from?](https://doi.org/10.1145/3351095.3372862)
- [Bidding strategies with gender nondiscrimination constraints for online ad auctions.](https://doi.org/10.1145/3351095.3375783)
- [Multi-category fairness in sponsored search auctions.](https://doi.org/10.1145/3351095.3372848)
- [Reducing sentiment polarity for demographic attributes in word embeddings using adversarial learning.](https://doi.org/10.1145/3351095.3372837)
- [Interventions for ranking in the presence of implicit bias.](https://doi.org/10.1145/3351095.3372858)
- [The disparate equilibria of algorithmic decision making when individuals invest rationally.](https://doi.org/10.1145/3351095.3372861)
- [An empirical study on the perceived fairness of realistic, imperfect machine learning models.](https://doi.org/10.1145/3351095.3372831)
- [Artificial mental phenomena: psychophysics as a framework to detect perception biases in AI models.](https://doi.org/10.1145/3351095.3375623)
- [The social lives of generative adversarial networks.](https://doi.org/10.1145/3351095.3373156)
- [Towards a more representative politics in the ethics of computer science.](https://doi.org/10.1145/3351095.3372854)
- [Integrating FATE/critical data studies into data science curricula: where are we going and how do we get there?](https://doi.org/10.1145/3351095.3372832)
- [Recommendations and user agency: the reachability of collaboratively-filtered information.](https://doi.org/10.1145/3351095.3372866)
- [Bias in word embeddings.](https://doi.org/10.1145/3351095.3372843)
- [What does it mean to 'solve' the problem of discrimination in hiring?: social, technical and legal perspectives from the UK on automated hiring systems.](https://doi.org/10.1145/3351095.3372849)
- [Mitigating bias in algorithmic hiring: evaluating claims and practices.](https://doi.org/10.1145/3351095.3372828)
- [The impact of overbooking on a pre-trial risk assessment tool.](https://doi.org/10.1145/3351095.3372846)
- [Awareness in practice: tensions in access to sensitive attribute data for antidiscrimination.](https://doi.org/10.1145/3351095.3372877)
- [Towards a critical race methodology in algorithmic fairness.](https://doi.org/10.1145/3351095.3372826)
- [What's sex got to do with machine learning?](https://doi.org/10.1145/3351095.3375674)
- [On the apparent conflict between individual and group fairness.](https://doi.org/10.1145/3351095.3372864)
- [Fairness is not static: deeper understanding of long term fairness via simulation studies.](https://doi.org/10.1145/3351095.3372878)
- [Fair classification and social welfare.](https://doi.org/10.1145/3351095.3372857)
- [Preference-informed fairness.](https://doi.org/10.1145/3351095.3373155)
- [Towards fairer datasets: filtering and balancing the distribution of the people subtree in the ImageNet hierarchy.](https://doi.org/10.1145/3351095.3375709)
- [The case for voter-centered audits of search engines during political elections.](https://doi.org/10.1145/3351095.3372835)
- [Whose tweets are surveilled for the police: an audit of a social-media monitoring tool via log files.](https://doi.org/10.1145/3351095.3372841)
- [Dirichlet uncertainty wrappers for actionable algorithm accuracy accountability and auditability.](https://doi.org/10.1145/3351095.3372825)
- [Counterfactual risk assessments, evaluation, and fairness.](https://doi.org/10.1145/3351095.3372851)
- [The false promise of risk assessments: epistemic reform and the limits of fairness.](https://doi.org/10.1145/3351095.3372869)
- [Explaining machine learning classifiers through diverse counterfactual explanations.](https://doi.org/10.1145/3351095.3372850)
- [Model agnostic interpretability of rankers via intent modelling.](https://doi.org/10.1145/3351095.3375234)
- [Doctor XAI: an ontology-based approach to black-box sequential data classification explanations.](https://doi.org/10.1145/3351095.3372855)
- [Robustness in machine learning explanations: does it matter?](https://doi.org/10.1145/3351095.3372836)
- [Explainable machine learning in deployment.](https://doi.org/10.1145/3351095.3375624)
- [Fairness and utilization in allocating resources with uncertain demand.](https://doi.org/10.1145/3351095.3372847)
- [The effects of competition and regulation on error inequality in data-driven markets.](https://doi.org/10.1145/3351095.3372842)

### [ICDM 2020](https://dblp.uni-trier.de/db/conf/icdm/icdm2020.html)

> TBD

### [ICML 2020](https://dblp.uni-trier.de/db/conf/icml/icml2020.html)

- [A Pairwise Fair and Community-preserving Approach to k-Center Clustering.](http://proceedings.mlr.press/v119/brubach20a.html)
- [How to Solve Fair k-Center in Massive Data Models.](http://proceedings.mlr.press/v119/chiplunkar20a.html)
- [Fair Generative Modeling via Weak Supervision.](http://proceedings.mlr.press/v119/choi20a.html)
- [Causal Modeling for Fairness In Dynamical Systems.](http://proceedings.mlr.press/v119/creager20a.html)
- [Is There a Trade-Off Between Fairness and Accuracy? A Perspective Using Mismatched Hypothesis Testing.](http://proceedings.mlr.press/v119/dutta20a.html)
- [Fair k-Centers via Maximum Matching.](http://proceedings.mlr.press/v119/jones20a.html)
- [FACT: A Diagnostic for Group Fairness Trade-offs.](http://proceedings.mlr.press/v119/kim20a.html)
- [Too Relaxed to Be Fair.](http://proceedings.mlr.press/v119/lohaus20a.html)
- [Individual Fairness for k-Clustering.](http://proceedings.mlr.press/v119/mahabadi20a.html)
- [Minimax Pareto Fairness: A Multi Objective Perspective.](http://proceedings.mlr.press/v119/martinez20a.html)
- [Fair Learning with Private Demographic Data.](http://proceedings.mlr.press/v119/mozannar20a.html)
- [Two Simple Ways to Learn Individual Fairness Metrics from Data.](http://proceedings.mlr.press/v119/mukherjee20a.html)
- [FR-Train: A Mutual Information-Based Approach to Fair and Robust Training.](http://proceedings.mlr.press/v119/roh20a.html)
- [Bounding the fairness and accuracy of classifiers from population statistics.](http://proceedings.mlr.press/v119/sabato20a.html)
- [Measuring Non-Expert Comprehension of Machine Learning Fairness Metrics.](http://proceedings.mlr.press/v119/saha20c.html)
- [Learning Fair Policies in Multi-Objective (Deep) Reinforcement Learning with Average and Discounted Rewards.](http://proceedings.mlr.press/v119/siddique20a.html)
- [Learning De-biased Representations with Biased Representations.](http://proceedings.mlr.press/v119/bahng20a.html)
- [DeBayes: a Bayesian Method for Debiasing Network Embeddings.](http://proceedings.mlr.press/v119/buyl20a.html)
- [Data preprocessing to mitigate bias: A maximum entropy based approach.](http://proceedings.mlr.press/v119/celis20a.html)

### [IJCAI 2020](https://dblp.uni-trier.de/db/conf/ijcai/ijcai2020.html)

- [WEFE: The Word Embeddings Fairness Evaluation Framework.](https://doi.org/10.24963/ijcai.2020/60)
- [Individual Fairness Revisited: Transferring Techniques from Adversarial Robustness.](https://doi.org/10.24963/ijcai.2020/61)
- [Achieving Outcome Fairness in Machine Learning Models for Social Decision Problems.](https://doi.org/10.24963/ijcai.2020/62)
- [Relation-Based Counterfactual Explanations for Bayesian Network Classifiers.](https://doi.org/10.24963/ijcai.2020/63)
- [Metamorphic Testing and Certified Mitigation of Fairness Violations in NLP Models.](https://doi.org/10.24963/ijcai.2020/64)
- [Fairness-Aware Neural Rényi Minimization for Continuous Features.](https://doi.org/10.24963/ijcai.2020/313)
- [FNNC: Achieving Fairness through Neural Networks.](https://doi.org/10.24963/ijcai.2020/315)
- [Adversarial Graph Embeddings for Fair Influence Maximization over Social Networks.](https://doi.org/10.24963/ijcai.2020/594)

### [KDD 2020](https://dblp.uni-trier.de/db/conf/kdd/kdd2020.html)

- [InFoRM: Individual Fairness on Graph Mining.](https://dl.acm.org/doi/10.1145/3394486.3403080)
- [Towards Fair Truth Discovery from Biased Crowdsourced Answers.](https://dl.acm.org/doi/10.1145/3394486.3403102)
- [Evaluating Fairness Using Permutation Tests.](https://dl.acm.org/doi/10.1145/3394486.3403199)
- [A Causal Look at Statistical Definitions of Discrimination.](https://dl.acm.org/doi/10.1145/3394486.3403130)
- [List-wise Fairness Criterion for Point Processes.](https://dl.acm.org/doi/10.1145/3394486.3403246)
- [Algorithmic Decision Making with Conditional Fairness.](https://dl.acm.org/doi/10.1145/3394486.3403263)

### [NIPS 2020](https://dblp.uni-trier.de/db/conf/nips/neurips2020.html)

- [Achieving Equalized Odds by Resampling Sensitive Attributes.](https://proceedings.neurips.cc/paper/2020/hash/03593ce517feac573fdaafa6dcedef61-Abstract.html)
- [Fairness without Demographics through Adversarially Reweighted Learning.](https://proceedings.neurips.cc/paper/2020/hash/07fc15c9d169ee48573edd749d25945d-Abstract.html)
- [Fairness with Overlapping Groups; a Probabilistic Perspective.](https://proceedings.neurips.cc/paper/2020/hash/29c0605a3bab4229e46723f89cf59d83-Abstract.html)
- [Robust Optimization for Fairness with Noisy Protected Groups.](https://proceedings.neurips.cc/paper/2020/hash/37d097caf1299d9aa79c2c2b843d2d78-Abstract.html)
- [Fair regression with Wasserstein barycenters.](https://proceedings.neurips.cc/paper/2020/hash/51cdbd2611e844ece5d80878eb770436-Abstract.html)
- [Learning Certified Individually Fair Representations.](https://proceedings.neurips.cc/paper/2020/hash/55d491cf951b1b920900684d71419282-Abstract.html)
- [Metric-Free Individual Fairness in Online Learning.](https://proceedings.neurips.cc/paper/2020/hash/80b618ebcac7aa97a6dac2ba65cb7e36-Abstract.html)
- [Fairness constraints can help exact inference in structured prediction.](https://proceedings.neurips.cc/paper/2020/hash/8248a99e81e752cb9b41da3fc43fbe7f-Abstract.html)
- [Investigating Gender Bias in Language Models Using Causal Mediation Analysis.](https://proceedings.neurips.cc/paper/2020/hash/92650b2e92217715fe312e6fa7b90d82-Abstract.html)
- [Probabilistic Fair Clustering.](https://proceedings.neurips.cc/paper/2020/hash/95f2b84de5660ddf45c8a34933a2e66f-Abstract.html)
- [KFC: A Scalable Approximation Algorithm for $k$-center Fair Clustering.](https://proceedings.neurips.cc/paper/2020/hash/a6d259bfbfa2062843ef543e21d7ec8e-Abstract.html)
- [A Fair Classifier Using Kernel Density Estimation.](https://proceedings.neurips.cc/paper/2020/hash/ac3870fcad1cfc367825cda0101eee62-Abstract.html)
- [Exploiting MMD and Sinkhorn Divergences for Fair and Transferable Representation Learning.](https://proceedings.neurips.cc/paper/2020/hash/af9c0e0c1dee63e5acad8b7ed1a5be96-Abstract.html)
- [Fair Multiple Decision Making Through Soft Interventions.](https://proceedings.neurips.cc/paper/2020/hash/d0921d442ee91b896ad95059d13df618-Abstract.html)
- [Ensuring Fairness Beyond the Training Data.](https://proceedings.neurips.cc/paper/2020/hash/d6539d3b57159babf6a72e106beb45bd-Abstract.html)
- [How do fair decisions fare in long-term qualification?](https://proceedings.neurips.cc/paper/2020/hash/d6d231705f96d5a35aeb3a76402e49a3-Abstract.html)
- [Can I Trust My Fairness Metric? Assessing Fairness with Unlabeled Data and Bayesian Inference.](https://proceedings.neurips.cc/paper/2020/hash/d83de59e10227072a9c034ce10029c39-Abstract.html)
- [Fair regression via plug-in estimator and recalibration with statistical guarantees.](https://proceedings.neurips.cc/paper/2020/hash/ddd808772c035aed516d42ad3559be5f-Abstract.html)
- [Learning from Failure: De-biasing Classifier from Biased Classifier.](https://proceedings.neurips.cc/paper/2020/hash/eddc3427c5d77843c2253f1e799fe933-Abstract.html)
- [Fair Hierarchical Clustering.](https://proceedings.neurips.cc/paper/2020/hash/f10f2da9a238b746d2bac55759915f0d-Abstract.html)

### [SDM 2020](https://dblp.uni-trier.de/db/conf/sdm/sdm2020.html)

- [Bayesian Modeling of Intersectional Fairness: The Variance of Bias.](https://doi.org/10.1137/1.9781611976236.48)
- [On the Information Unfairness of Social Networks.](https://doi.org/10.1137/1.9781611976236.69)

### [UAI 2020](https://dblp.uni-trier.de/db/conf/uai/uai2020.html)

- [Fair Contextual Multi-Armed Bandits: Theory and Experiments.](http://www.auai.org/uai2020/proceedings/99_main_paper.pdf)
- [Towards Threshold Invariant Fair Classification.](http://www.auai.org/uai2020/proceedings/237_main_paper.pdf)
- [Verifying Individual Fairness in Machine Learning Models.](http://www.auai.org/uai2020/proceedings/327_main_paper.pdf)

### [WWW 2020](https://dblp.uni-trier.de/db/conf/www/www2020.html)

- [FairRec: Two-Sided Fairness for Personalized Recommendations in Two-Sided Platforms.](https://doi.org/10.1145/3366423.3380196)
- [Designing Fairly Fair Classifiers Via Economic Fairness Notions.](https://doi.org/10.1145/3366423.3380228)
- [Learning Model-Agnostic Counterfactual Explanations for Tabular Data.](https://doi.org/10.1145/3366423.3380087)

### Others 2020

#### [ASONAM 2020](https://dblp.uni-trier.de/db/conf/asunam/asonam2020.html)

- [Bias in Knowledge Graph Embeddings.](https://doi.org/10.1109/ASONAM49781.2020.9381459)
- [Debiasing Graph Representations via Metadata-Orthogonal Training.](https://doi.org/10.1109/ASONAM49781.2020.9381348)

## 2019

### [AAAI 2019](https://dblp.uni-trier.de/db/conf/aaai/aaai2019.html)

- [Learning Optimal and Fair Decision Trees for Non-Discriminative Decision-Making](https://aaai.org/ojs/index.php/AAAI/article/view/3943)
- [Learning to Address Health Inequality in the United States with a Bayesian Decision Network](https://aaai.org/ojs/index.php/AAAI/article/view/3849)
- [Convex Formulations for Fair Principal Component Analysis](https://aaai.org/ojs/index.php/AAAI/article/view/3843)
- [Bayesian Fairness](https://aaai.org/ojs/index.php/AAAI/article/view/3824)
- [One-Network Adversarial Fairness](https://aaai.org/ojs/index.php/AAAI/article/view/4085)
- [Eliminating Latent Discrimination: Train Then Mask](https://aaai.org/ojs/index.php/AAAI/article/view/4251)
- [Path-Specific Counterfactual Fairness](https://aaai.org/ojs/index.php/AAAI/article/view/4777)

### [AISTATS 2019](https://dblp.uni-trier.de/db/conf/aistats/aistats2019.html)

- [Learning Controllable Fair Representations](http://proceedings.mlr.press/v89/song19a)

### [BIGDATA 2019](https://dblp.uni-trier.de/db/conf/bigdataconf/bigdataconf2019.html)

- [FAE: A Fairness-Aware Ensemble Framework](https://ieeexplore.ieee.org/document/9006487/)
- [Privacy Bargaining with Fairness: Privacy–Price Negotiation System for Applying Differential Privacy in Data Market Environments](https://ieeexplore.ieee.org/document/9006101/)
- [FairGAN+: Achieving Fair Data Generation and Classification through Generative Adversarial Nets](https://ieeexplore.ieee.org/document/9006322/)

### [CIKM 2019](https://dblp.uni-trier.de/db/conf/cikm/cikm2019.html)

- [AdaFair: Cumulative Fairness Adaptive Boosting](https://doi.org/10.1145/3357384.3357974)

### [FAT\* 2019](https://dblp.uni-trier.de/db/conf/fat/fat2019.html)

- [Explaining Explanations in AI](https://dl.acm.org/authorize?N675479)
- [Deep Weighted Averaging Classifiers](https://dl.acm.org/authorize?N675488)
- [Fairness and Abstraction in Sociotechnical Systems](https://dl.acm.org/authorize?N675344)
- [50 Years of Test (Un)fairness: Lessons for Machine Learning](https://dl.acm.org/authorize?N675343)
- [A comparative study of fairness-enhancing interventions in machine learning](https://dl.acm.org/authorize?N675474)
- [Beyond Open vs. Closed: Balancing Individual Privacy and Public Accountability in Data Sharing](https://dl.acm.org/authorize?N675460)
- [Analyzing Biases in Perception of Truth in News Stories and their Implications for Fact Checking](https://dl.acm.org/authorize?N675453)
- [Disparate Interactions: An Algorithm-in-the-Loop Analysis of Fairness in Risk Assessments](https://dl.acm.org/authorize?N675458)
- [Problem Formulation and Fairness](https://dl.acm.org/authorize?N675342)
- [Fairness under unawareness: assessing disparity when protected class is unobserved](https://dl.acm.org/authorize?N675485)
- [On Human Predictions with Explanations and Predictions of Machine Learning Models: A Case Study on Deception Detection](https://dl.acm.org/authorize?N675341)
- [Actionable Recourse in Linear Classification](https://dl.acm.org/authorize?N675349)
- [A Taxonomy of Ethical Tensions in Inferring Mental Health States from Social Media](https://dl.acm.org/authorize?N675456)
- [The Disparate Effects of Strategic Manipulation](https://dl.acm.org/authorize?N675477)
- [An Algorithmic Framework to Control Polarization in Personalization](https://dl.acm.org/authorize?N675466)
- [Racial categories in machine learning](https://dl.acm.org/authorize?N675470)
- [Downstream Effects of Affirmative Action](https://dl.acm.org/authorize?N675475)
- [Fairness through Causal Awareness: Learning Causal Latent-Variable Models for Biased Data](https://dl.acm.org/authorize?N675486)
- [Model Reconstruction from Model Explanations](https://dl.acm.org/authorize?N675348)
- [Fair Allocation through Competitive Equilibrium from Generic Incomes](https://dl.acm.org/authorize?N675468)
- [An Empirical Study of Rich Subgroup Fairness for Machine Learning](https://dl.acm.org/authorize?N675459)
- [From Soft Classifiers to Hard Decisions: How fair can we be?](https://dl.acm.org/authorize?N675472)
- [Efficient Search for Diverse Coherent Explanations](https://dl.acm.org/authorize?N675340)
- [Robot Eyes Wide Shut: Understanding Dishonest Anthropomorphism](https://dl.acm.org/authorize?N675471)
- [A Moral Framework for Understanding Fair ML through Economic Models of Equality of Opportunity](https://dl.acm.org/authorize?N675469)
- [Classification with Fairness Constraints: A Meta-Algorithm with Provable Guarantees](https://dl.acm.org/authorize?N675473)
- [Access to Population-Level Signaling as a Source of Inequality](https://dl.acm.org/authorize?N675476)
- [Measuring the Biases that Matter: The Ethical and Casual Foundations for Measures of Fairness in Algorithms](https://dl.acm.org/authorize?N675478)
- [Fairness-Aware Programming](https://dl.acm.org/authorize?N675462)
- [The Profiling Potential of Computer Vision and the Challenge of Computational Empiricism](https://dl.acm.org/authorize?N675450)
- [Clear Sanctions, Vague Rewards: How China's Social Credit System Defines "Good" and "Bad" Behavior](https://dl.acm.org/authorize?N675455)
- [Bias in Bios: A Case Study of Semantic Representation Bias in a High-Stakes Setting](https://dl.acm.org/authorize?N675451)
- [Who's the Guinea Pig? Investigating Online A/B/n Tests In-The-Wild](https://dl.acm.org/authorize?N675461)
- [Fair Algorithms for Learning in Allocation Problems](https://dl.acm.org/authorize?N675467)
- [On Microtargeting Socially Divisive Ads: A Case Study of Russia-Linked Ad Campaigns on Facebook](https://dl.acm.org/authorize?N675454)
- [Model Cards for Model Reporting](https://dl.acm.org/authorize?N675463)
- [Dissecting Racial Bias in an Algorithm that Guides Health Decisions for 70 million people](https://dl.acm.org/authorize?N675457)
- [The Social Cost of Strategic Classification](https://dl.acm.org/authorize?N675464)
- [SIREN: A Simulation Framework for Understanding the Effects of Recommender Systems in Online News Environments](https://dl.acm.org/authorize?N675465)
- [Equality of Voice: Towards Fair Representation in Crowdsourced Top-K Recommendations](https://dl.acm.org/authorize?N675452)
- [From Fair Decision Making To Social Equality](https://dl.acm.org/authorize?N675487)

### [ICDM 2019](https://dblp.uni-trier.de/db/conf/icdm/icdm2019.html)

- [Fair Adversarial Gradient Tree Boosting](https://ieeexplore.ieee.org/document/8970941/)
- [Rank-Based Multi-task Learning For Fair Regression](https://ieeexplore.ieee.org/document/8970984/)
- [A Distributed Fair Machine Learning Framework with Private Demographic Data Protection](https://ieeexplore.ieee.org/document/8970908/)

### [ICML 2019](https://dblp.uni-trier.de/db/conf/icml/icml2019.html)

- [Fair Regression: Quantitative Definitions and Reduction-Based Algorithms](http://proceedings.mlr.press/v97/agarwal19d.html)
- [Fairwashing: the risk of rationalization](http://proceedings.mlr.press/v97/aivodji19a.html)
- [Scalable Fair Clustering](http://proceedings.mlr.press/v97/backurs19a.html)
- [Compositional Fairness Constraints for Graph Embeddings](http://proceedings.mlr.press/v97/bose19a.html)
- [Understanding the Origins of Bias in Word Embeddings](http://proceedings.mlr.press/v97/brunet19a.html)
- [Proportionally Fair Clustering](http://proceedings.mlr.press/v97/chen19d.html)
- [Training Well-Generalizing Classifiers for Fairness Metrics and Other Data-Dependent Constraints](http://proceedings.mlr.press/v97/cotter19b.html)
- [Flexibly Fair Representation Learning by Disentanglement](http://proceedings.mlr.press/v97/creager19a.html)
- [Obtaining Fairness using Optimal Transport Theory](http://proceedings.mlr.press/v97/gordaliza19a.html)
- [On the Long-term Impact of Algorithmic Decision Policies: Effort Unfairness and Feature Segregation through Social Learning](http://proceedings.mlr.press/v97/heidari19a.html)
- [Stable and Fair Classification](http://proceedings.mlr.press/v97/huang19e.html)
- [Differentially Private Fair Learning](http://proceedings.mlr.press/v97/jagielski19a.html)
- [Fair k-Center Clustering for Data Summarization](http://proceedings.mlr.press/v97/kleindessner19a.html)
- [Guarantees for Spectral Clustering with Fairness Constraints](http://proceedings.mlr.press/v97/kleindessner19b.html)
- [Making Decisions that Reduce Discriminatory Impacts](http://proceedings.mlr.press/v97/kusner19a.html)
- [The Implicit Fairness Criterion of Unconstrained Learning](http://proceedings.mlr.press/v97/liu19f.html)
- [Fairness-Aware Learning for Continuous Attributes and Treatments](http://proceedings.mlr.press/v97/mary19a.html)
- [Toward Controlling Discrimination in Online Ad Auctions](http://proceedings.mlr.press/v97/mehrotra19a.html)
- [Learning Optimal Fair Policies](http://proceedings.mlr.press/v97/nabi19a.html)
- [Fairness without Harm: Decoupled Classifiers with Preference Guarantees](http://proceedings.mlr.press/v97/ustun19a.html)
- [Repairing without Retraining: Avoiding Disparate Impact with Counterfactual Distributions](http://proceedings.mlr.press/v97/wang19l.html)
- [Fairness risk measures](http://proceedings.mlr.press/v97/williamson19a.html)

### [IJCAI 2019](https://dblp.uni-trier.de/db/conf/ijcai/ijcai2019.html)

- [Counterfactual Fairness: Unidentification, Bound and Algorithm](https://doi.org/10.24963/ijcai.2019/199)
- [Achieving Causal Fairness through Generative Adversarial Networks](https://doi.org/10.24963/ijcai.2019/201)
- [FAHT: An Adaptive Fairness-aware Decision Tree Classifier](https://doi.org/10.24963/ijcai.2019/205)
- [Delayed Impact of Fair Machine Learning](https://doi.org/10.24963/ijcai.2019/862)
- [The Price of Local Fairness in Multistage Selection](https://www.ijcai.org/proceedings/2019/809)

### [KDD 2019](https://dblp.uni-trier.de/db/conf/kdd/kdd2019.html)

- [Fairness in Recommendation Ranking through Pairwise Comparisons](https://doi.org/10.1145/3292500.3330745)
- [Fairness-Aware Ranking in Search & Recommendation Systems with Application to LinkedIn Talent Search](https://doi.org/10.1145/3292500.3330691)
- [Mathematical Notions vs. Human Perception of Fairness: A Descriptive Approach to Fairness for Machine Learning](https://doi.org/10.1145/3292500.3330664)

### [NIPS 2019](https://dblp.uni-trier.de/db/conf/nips/nips2019.html)

- [Noise-tolerant fair classification](http://papers.nips.cc/paper/8322-noise-tolerant-fair-classification)
- [Envy-Free Classification](http://papers.nips.cc/paper/8407-envy-free-classification)
- [Discrimination in Online Markets: Effects of Social Bias on Learning from Reviews and Policy Design](http://papers.nips.cc/paper/8487-discrimination-in-online-markets-effects-of-social-bias-on-learning-from-reviews-and-policy-design)
- [PC-Fairness: A Unified Framework for Measuring Causality-based Fairness](http://papers.nips.cc/paper/8601-pc-fairness-a-unified-framework-for-measuring-causality-based-fairness)
- [Assessing Disparate Impact of Personalized Interventions: Identifiability and Bounds](http://papers.nips.cc/paper/8603-assessing-disparate-impact-of-personalized-interventions-identifiability-and-bounds)
- [The Fairness of Risk Scores Beyond Classification: Bipartite Ranking and the XAUC Metric](http://papers.nips.cc/paper/8604-the-fairness-of-risk-scores-beyond-classification-bipartite-ranking-and-the-xauc-metric)
- [Fair Algorithms for Clustering](http://papers.nips.cc/paper/8741-fair-algorithms-for-clustering)
- [Characterizing Bias in Classifiers using Generative Models](http://papers.nips.cc/paper/8780-characterizing-bias-in-classifiers-using-generative-models)
- [Policy Learning for Fairness in Ranking](http://papers.nips.cc/paper/8782-policy-learning-for-fairness-in-ranking)
- [Average Individual Fairness: Algorithms, Generalization and Experiments](http://papers.nips.cc/paper/9034-average-individual-fairness-algorithms-generalization-and-experiments)
- [Paradoxes in Fair Machine Learning](http://papers.nips.cc/paper/9043-paradoxes-in-fair-machine-learning)
- [Unlocking Fairness: a Trade-off Revisited](http://papers.nips.cc/paper/9082-unlocking-fairness-a-trade-off-revisited)
- [Equal Opportunity in Online Classification with Partial Feedback](http://papers.nips.cc/paper/9099-equal-opportunity-in-online-classification-with-partial-feedback)
- [Learning Fairness in Multi-Agent Systems](http://papers.nips.cc/paper/9537-learning-fairness-in-multi-agent-systems)
- [On the Fairness of Disentangled Representations](http://papers.nips.cc/paper/9603-on-the-fairness-of-disentangled-representations)
- [Differential Privacy Has Disparate Impact on Model Accuracy](http://papers.nips.cc/paper/9681-differential-privacy-has-disparate-impact-on-model-accuracy)
- [Inherent Tradeoffs in Learning Fair Representations](http://papers.nips.cc/paper/9698-inherent-tradeoffs-in-learning-fair-representations)
- [Exploring Algorithmic Fairness in Robust Graph Covering Problems](http://papers.nips.cc/paper/9707-exploring-algorithmic-fairness-in-robust-graph-covering-problems)
- [Leveraging Labeled and Unlabeled Data for Consistent Fair Binary Classification](https://papers.nips.cc/paper/9437-leveraging-labeled-and-unlabeled-data-for-consistent-fair-binary-classification)
- [Assessing Social and Intersectional Biases in Contextualized Word Representations](https://papers.nips.cc/paper/9479-assessing-social-and-intersectional-biases-in-contextualized-word-representations)
- [Offline Contextual Bandits with High Probability Fairness Guarantees](https://papers.nips.cc/paper/9630-offline-contextual-bandits-with-high-probability-fairness-guarantees)
- [Multi-Criteria Dimensionality Reduction with Applications to Fairness](https://papers.nips.cc/paper/9652-multi-criteria-dimensionality-reduction-with-applications-to-fairness)
- [Group Retention when Using Machine Learning in Sequential Decision Making: the Interplay between User Dynamics and Fairness](https://papers.nips.cc/paper/9662-group-retention-when-using-machine-learning-in-sequential-decision-making-the-interplay-between-user-dynamics-and-fairness)

### [SDM 2019](https://dblp.uni-trier.de/db/conf/sdm/sdm2019.html)

- [Fairness in representation: quantifying stereotyping as a representational harm](https://doi.org/10.1137/1.9781611975673.90)

### [UAI 2019](https://dblp.uni-trier.de/db/conf/uai/uai2019.html)

- [The Sensitivity of Counterfactual Fairness to Unmeasured Confounding](http://auai.org/uai2019/proceedings/papers/213.pdf)
- [Wasserstein Fair Classification](http://auai.org/uai2019/proceedings/papers/315.pdf)

### [WWW 2019](https://dblp.uni-trier.de/db/conf/www/www2019.html)

- [Fairness in Algorithmic Decision Making: An Excursion Through the Lens of Causality](https://doi.org/10.1145/3308558.3313559)
- [FARE: Diagnostics for Fair Ranking using Pairwise Error Metrics](https://doi.org/10.1145/3308558.3313443)
- [On Convexity and Bounds of Fairness-aware Classification](https://doi.org/10.1145/3308558.3313723)

### Others 2019

- [Fighting Fire with Fire: Using Antidote Data to Improve Polarization and Fairness of Recommender Systems](https://doi.org/10.1145/3289600.3291002), [WSDM 2019](https://dblp.uni-trier.de/db/conf/wsdm/wsdm2019.html)
- [Interventional Fairness: Causal Database Repair for Algorithmic Fairness.](https://doi.org/10.1145/3299869.3319901), [SIGMOD 2019](https://dblp.uni-trier.de/db/conf/sigmod/index.html)
- [Designing Fair Ranking Schemes.](https://doi.org/10.1145/3299869.3300079), [SIGMOD 2019](https://dblp.uni-trier.de/db/conf/sigmod/index.html)

## 2018

### [AAAI 2018](https://dblp.uni-trier.de/db/conf/aaai/aaai2018.html)

- [Non-Discriminatory Machine Learning through Convex Fairness Criteria](https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16476)
- [Knowledge, Fairness, and Social Constraints](https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/17230)
- [Fairness in Decision-Making -- The Causal Explanation Formula](https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16949)
- [Fair Inference on Outcomes](https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16683)
- [Beyond Distributive Fairness in Algorithmic Decision Making: Feature Selection for Procedurally Fair Learning](https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16523)
- [Balancing Lexicographic Fairness and a Utilitarian Objective with Application to Kidney Exchange](https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16196)

### [AISTATS 2018](https://dblp.uni-trier.de/db/conf/aistats/aistats2018.html)

- [Fast Threshold Tests for Detecting Discrimination](http://proceedings.mlr.press/v84/pierson18a)
- [Spectral Algorithms for Computing Fair Support Vector Machines](http://proceedings.mlr.press/v84/olfat18a)

### [BIGDATA 2018](https://dblp.uni-trier.de/db/conf/bigdataconf/bigdataconf2018.html)

- [FairGAN: Fairness-aware Generative Adversarial Networks](https://ieeexplore.ieee.org/document/8622525)

### [CIKM 2018](https://dblp.uni-trier.de/db/conf/cikm/cikm2018.html)

- [Fairness-Aware Tensor-Based Recommendation](https://dl.acm.org/citation.cfm?doid=3269206.3271795)
- [Towards a Fair Marketplace: Counterfactual Evaluation of the trade-off between Relevance, Fairness & Satisfaction in Recommendation Systems](https://dl.acm.org/citation.cfm?doid=3269206.3272027)

### [FAT\* 2018](https://dblp.uni-trier.de/db/conf/fat/fat2018.html)

- [Potential for Discrimination in Online Targeted Advertising](http://proceedings.mlr.press/v81/speicher18a.html)
- [Discrimination in Online Personalization: A Multidisciplinary Inquiry](http://proceedings.mlr.press/v81/datta18a.html)
- [Privacy for All: Ensuring Fair and Equitable Privacy Protections](http://proceedings.mlr.press/v81/ekstrand18a.html)
- ["Meaningful Information" and the Right to Explanation](http://proceedings.mlr.press/v81/selbst18a.html)
- [Interpretable Active Learning](http://proceedings.mlr.press/v81/phillips18a.html)
- [Interventions over Predictions: Reframing the Ethical Debate for Actuarial Risk Assessment](http://proceedings.mlr.press/v81/barabas18a.html)
- [Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification](http://proceedings.mlr.press/v81/buolamwini18a.html)
- [Analyze, Detect and Remove Gender Stereotyping from Bollywood Movies](http://proceedings.mlr.press/v81/madaan18a.html)
- [Mixed Messages? The Limits of Automated Social Media Content Analysis](http://proceedings.mlr.press/v81/duarte18a.html)
- [The cost of fairness in binary classification](http://proceedings.mlr.press/v81/menon18a.html)
- [Decoupled Classifiers for Group-Fair and Efficient Machine Learning](http://proceedings.mlr.press/v81/dwork18a.html)
- [A case study of algorithm-assisted decision making in child maltreatment hotline screening decisions](http://proceedings.mlr.press/v81/chouldechova18a.html)
- [Fairness in Machine Learning: Lessons from Political Philosophy](http://proceedings.mlr.press/v81/binns18a.html)
- [Runaway Feedback Loops in Predictive Policing](http://proceedings.mlr.press/v81/ensign18a.html)
- [All The Cool Kids, How Do They Fit In?: Popularity and Demographic Biases in Recommender Evaluation and Effectiveness](http://proceedings.mlr.press/v81/ekstrand18b.html)
- [Recommendation Independence](http://proceedings.mlr.press/v81/kamishima18a.html)
- [Balanced Neighborhoods for Multi-sided Fairness in Recommendation](http://proceedings.mlr.press/v81/burke18a.html)

### [ICDM 2018](https://dblp.uni-trier.de/db/conf/icdm/icdm2018.html)

- [Using Balancing Terms to Avoid Discrimination in Classification](https://ieeexplore.ieee.org/document/8594925)

### [ICML 2018](https://dblp.uni-trier.de/db/conf/icml/icml2018.html)

- [Blind Justice: Fairness with Encrypted Sensitive Attributes](http://proceedings.mlr.press/v80/kilbertus18a.html)
- [Scalable Deletion-Robust Submodular Maximization: Data Summarization with Privacy and Fairness Constraints](http://proceedings.mlr.press/v80/kazemi18a.html)
- [Nonconvex Optimization for Fair Regression](http://proceedings.mlr.press/v80/komiyama18a.html)
- [Fair and Diverse DPP-based Data Summarization](http://proceedings.mlr.press/v80/celis18a.html)
- [Preventing Fairness Gerrymandering: Auditing and Learning for Subgroup Fairness](http://proceedings.mlr.press/v80/kearns18a.html)
- [Residual Unfairness in Fair Machine Learning from Prejudiced Data](http://proceedings.mlr.press/v80/kallus18a.html)
- [A Reductions Approach to Fair Classification](http://proceedings.mlr.press/v80/agarwal18a.html)
- [Probably Approximately Metric-Fair Learning](http://proceedings.mlr.press/v80/yona18a.html)
- [Learning Adversarially Fair and Transferable Representations](http://proceedings.mlr.press/v80/madras18a.html)
- [Delayed Impact of Fair Machine Learning](http://proceedings.mlr.press/v80/liu18c.html), *Best Paper Awards*
- [Fairness Without Demographics in Repeated Loss Minimization](http://proceedings.mlr.press/v80/hashimoto18a.html), *Best Paper Runner Up Awards*

### [IJCAI 2018](https://dblp.uni-trier.de/db/conf/ijcai/ijcai2018.html)

- [Achieving Non-Discrimination in Prediction](https://www.ijcai.org/proceedings/2018/430)
- [Preventing Disparate Treatment in Sequential Decision Making](https://www.ijcai.org/proceedings/2018/311)

### [KDD 2018](https://dblp.uni-trier.de/db/conf/kdd/kdd2018.html)

- [Fairness of Exposure in Rankings](https://dl.acm.org/citation.cfm?doid=3219819.3220088)
- [On Discrimination Discovery and Removal in Ranked Data using Causal Graph](https://dl.acm.org/citation.cfm?doid=3219819.3220087)
- [A Unified Approach to Quantifying Algorithmic Unfairness: Measuring Individual & Group Unfairness via Inequality Indices](https://dl.acm.org/citation.cfm?doid=3219819.3220046)

### [NIPS 2018](https://dblp.uni-trier.de/db/conf/nips/nips2018.html)

- [Fairness Behind a Veil of Ignorance: a Welfare Analysis for Automated Decision Making](http://papers.nips.cc/paper/7402-fairness-behind-a-veil-of-ignorance-a-welfare-analysis-for-automated-decision-making)
- [Enhancing the Accuracy and Fairness of Human Decision Making](http://papers.nips.cc/paper/7448-enhancing-the-accuracy-and-fairness-of-human-decision-making)
- [Online Learning with an Unknown Fairness Metric](http://papers.nips.cc/paper/7526-online-learning-with-an-unknown-fairness-metric)
- [Empirical Risk Minimization under Fairness Constraints](http://papers.nips.cc/paper/7544-empirical-risk-minimization-under-fairness-constraints)
- [Why Is My Classifier Discriminatory](http://papers.nips.cc/paper/7613-why-is-my-classifier-discriminatory)
- [Hunting for Discriminatory Proxies in Linear Regression Models](http://papers.nips.cc/paper/7708-hunting-for-discriminatory-proxies-in-linear-regression-models)
- [Fairness Through Computationally Bounded Awareness](http://papers.nips.cc/paper/7733-fairness-through-computationally-bounded-awareness)
- [Predict Responsibly Improving Fairness and Accuracy by Learning to Defer](http://papers.nips.cc/paper/7853-predict-responsibly-improving-fairness-and-accuracy-by-learning-to-defer)
- [On Preserving Non Discrimination When Combining Expert Advice](http://papers.nips.cc/paper/8058-on-preserving-non-discrimination-when-combining-expert-advice)
- [The Price of Fair PCA: One Extra Dimension](http://papers.nips.cc/paper/8294-the-price-of-fair-pca-one-extra-dimension)
- [Equality of Opportunity in Classification: A Causal Approach](http://papers.nips.cc/paper/7625-equality-of-opportunity-in-classification-a-causal-approach)
- [Invariant Representations without Adversarial Training](https://papers.nips.cc/paper/8122-invariant-representations-without-adversarial-training)
- [Learning to Pivot with Adversarial Networks](http://papers.nips.cc/paper/6699-learning-to-pivot-with-adversarial-networks)

### [SDM 2018](https://dblp.uni-trier.de/db/conf/sdm/sdm2018.html)

> *null*

### [UAI 2018](https://dblp.uni-trier.de/db/conf/uai/uai2018.html)

> *null*

### [WWW 2018](https://dblp.uni-trier.de/db/conf/www/www2018.html)

- [Adaptive Sensitive Reweighting to Mitigate Bias in Fairness-aware Classification](https://dl.acm.org/citation.cfm?id=3186133)
- [Human Perceptions of Fairness in Algorithmic Decision Making: A Case Study of Criminal Risk Prediction](https://dl.acm.org/citation.cfm?id=3186138)

### Others 2018

- [Biases in the Facebook News Feed: a Case Study on the Italian Elections](https://ieeexplore.ieee.org/document/8508659), [ASONAM 2018](https://dblp.uni-trier.de/db/conf/asunam/asonam2018.html)
- [Unleashing Linear Optimizers for Group-Fair Learning and Optimization](http://proceedings.mlr.press/v75/alabi18a.html), [COLT 2018](https://dblp.uni-trier.de/db/conf/colt/colt2018.html)

## 2017

### [AAAI 2017](https://dblp.uni-trier.de/db/conf/aaai/aaai2017.html)

> *null*

### [AISTATS 2017](https://dblp.uni-trier.de/db/conf/aistats/aistats2017.html)

- [Fairness Constraints: Mechanisms for Fair Classification](http://proceedings.mlr.press/v54/zafar17a/zafar17a.pdf), [supplement](http://proceedings.mlr.press/v54/zafar17a/zafar17a-supp.pdf)

### [BIGDATA 2017](https://dblp.uni-trier.de/db/conf/bigdataconf/bigdataconf2017.html)

- [Discrimination detection by causal effect estimation](https://ieeexplore.ieee.org/document/8258033)

### [CIKM 2017](https://dblp.uni-trier.de/db/conf/cikm/cikm2017.html)

- [FA\*IR: A Fair Top-k Ranking Algorithm](http://doi.acm.org/10.1145/3132847.3132938)
- [Algorithmic Bias: Do Good Systems Make Relevant Documents More Retrievable?](http://doi.acm.org/10.1145/3132847.3133135)

### [FAT\* 2017](https://dblp.uni-trier.de/db/conf/fat/fat2017.html)

> *null*

### [ICDM 2017](https://dblp.uni-trier.de/db/conf/icdm/icdm2017.html)

> *null*

### [ICML 2017](https://dblp.uni-trier.de/db/conf/icml/icml2017.html)

- [Fairness in Reinforcement Learning](http://proceedings.mlr.press/v70/jabbari17a.html)
- [Meritocratic Fairness for Cross-Population Selection](http://proceedings.mlr.press/v70/kearns17a.html)

### [IJCAI 2017](https://dblp.uni-trier.de/db/conf/ijcai/ijcai2017.html)

- [A Causal Framework for Discovering and Removing Direct and Indirect Discrimination](https://www.ijcai.org/proceedings/2017/549)

### [KDD 2017](https://dblp.uni-trier.de/db/conf/kdd/kdd2017.html)

- [Algorithmic decision making and the cost of fairness](http://www.kdd.org/kdd2017/papers/view/algorithmic-decision-making-and-the-cost-of-fairness)
- [Achieving Non-Discrimination in Data Release](http://www.kdd.org/kdd2017/papers/view/achieving-non-discrimination-in-data-release)

### [NIPS 2017](https://dblp.uni-trier.de/db/conf/nips/nips2017.html)

- [From Parity to Preference-based Notions of Fairness in Classification](https://papers.nips.cc/paper/6627-from-parity-to-preference-based-notions-of-fairness-in-classification)
- [Controllable Invariance through Adversarial Feature Learning](https://papers.nips.cc/paper/6661-controllable-invariance-through-adversarial-feature-learning)
- [Avoiding Discrimination through Causal Reasoning](https://papers.nips.cc/paper/6668-avoiding-discrimination-through-causal-reasoning)
- [Recycling Privileged Learning and Distribution Matching for Fairness](https://papers.nips.cc/paper/6670-recycling-privileged-learning-and-distribution-matching-for-fairness)
- [Beyond Parity: Fairness Objectives for Collaborative Filtering](http://papers.nips.cc/paper/6885-beyond-parity-fairness-objectives-for-collaborative-filtering)
- [Optimized Pre-Processing for Discrimination Prevention](https://papers.nips.cc/paper/6988-optimized-pre-processing-for-discrimination-prevention)
- [Counterfactual Fairness](https://papers.nips.cc/paper/6995-counterfactual-fairness)
- [Fair Clustering Through Fairlets](http://papers.nips.cc/paper/7088-fair-clustering-through-fairlets)
- [On Fairness and Calibration](https://papers.nips.cc/paper/7151-on-fairness-and-calibration)
- [When Worlds Collide: Integrating Different Counterfactual Assumptions in Fairness](https://papers.nips.cc/paper/7220-when-worlds-collide-integrating-different-counterfactual-assumptions-in-fairness)

### [SDM 2017](https://dblp.uni-trier.de/db/conf/sdm/sdm2017.html)

> *null*

### [UAI 2017](https://dblp.uni-trier.de/db/conf/uai/uai2017.html)

- [Fair Optimal Stopping Policy for Matching with Mediator](http://auai.org/uai2017/proceedings/papers/207.pdf), [supplement](http://auai.org/uai2017/proceedings/supplements/207.pdf)
- [Importance Sampling for Fair Policy Selection](http://auai.org/uai2017/proceedings/papers/225.pdf), [supplement](http://auai.org/uai2017/proceedings/supplements/225.pdf)

### [WWW 2017](https://dblp.uni-trier.de/db/conf/www/www2017.html)

- [Fairness in Package-to-Group Recommendations](https://dl.acm.org/citation.cfm?doid=3038912.3052612)
- [Fairness Beyond Disparate Treatment & Disparate Impact: Learning Classification without Disparate Mistreatment](https://dl.acm.org/citation.cfm?doid=3038912.3052660)

### Others 2017

- [Learning Non-Discriminatory Predictors](http://proceedings.mlr.press/v65/woodworth17a/woodworth17a.pdf), [COLT 2017](https://dblp.uni-trier.de/db/conf/colt/colt2017.html)
- [Inherent Trade-Offs in the Fair Determination of Risk Scores](http://drops.dagstuhl.de/opus/volltexte/2017/8156/), [ITCS 2017](https://dblp.uni-trier.de/db/conf/innovations/innovations2017.html)

## 2016

### [AAAI 2016](https://dblp.uni-trier.de/db/conf/aaai/aaai2016.html)

> *null*

### [AISTATS 2016](https://dblp.uni-trier.de/db/conf/aistats/aistats2016.html)

> *null*

### [BIGDATA 2016](https://dblp.uni-trier.de/db/conf/bigdataconf/bigdataconf2016.html)

> *null*

### [CIKM 2016](https://dblp.uni-trier.de/db/conf/cikm/cikm2016.html)

> *null*

### [FAT\* 2016](https://dblp.uni-trier.de/db/conf/fat/fat2016.html)

> *null*

### [ICDM 2016](https://dblp.uni-trier.de/db/conf/icdm/icdm2016.html)

- [Auditing Black-Box Models for Indirect Influence](https://ieeexplore.ieee.org/document/7837824)

### [ICML 2016](https://dblp.uni-trier.de/db/conf/icml/icml2016.html)

> *null*

### [IJCAI 2016](https://dblp.uni-trier.de/db/conf/ijcai/ijcai2016.html)

- [Situation Testing-Based Discrimination Discovery: A Causal Inference Approach](https://www.ijcai.org/Abstract/16/386)

### [KDD 2016](https://dblp.uni-trier.de/db/conf/kdd/kdd2016.html)

> *null*

### [NIPS 2016](https://dblp.uni-trier.de/db/conf/nips/nips2016.html)

- [Fairness in Learning: Classic and Contextual Bandits](https://papers.nips.cc/paper/6355-fairness-in-learning-classic-and-contextual-bandits)
- [Equality of Opportunity in Supervised Learning](https://papers.nips.cc/paper/6374-equality-of-opportunity-in-supervised-learning)
- [Satisfying Real-world Goals with Dataset Constraints](http://papers.nips.cc/paper/6316-satisfying-real-world-goals-with-dataset-constraints)
- [Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings](https://papers.nips.cc/paper/6228-man-is-to-computer-programmer-as-woman-is-to-homemaker-debiasing-word-embeddings)

### [SDM 2016](https://dblp.uni-trier.de/db/conf/sdm/sdm2016.html)

- [A Confidence-Based Approach for Balancing Fairness and Accuracy](http://epubs.siam.org/doi/abs/10.1137/1.9781611974348.17)

### [UAI 2016](https://dblp.uni-trier.de/db/conf/uai/uai2016.html)

> *null*

### [WWW 2016](https://dblp.uni-trier.de/db/conf/www/www2016.html)

> *null*

### Others 2016

- [A KDD Process for Discrimination Discovery](https://link.springer.com/chapter/10.1007%2F978-3-319-46131-1_28), ECML/PKDD 2016

## 2015

### [AAAI 2015](https://dblp.uni-trier.de/db/conf/aaai/aaai2015.html)

> *null*

### [AISTATS 2015](https://dblp.uni-trier.de/db/conf/aistats/aistats2015.html)

> *null*

### [BIGDATA 2015](https://dblp.uni-trier.de/db/conf/bigdataconf/bigdataconf2015.html)

> *null*

### [CIKM 2015](https://dblp.uni-trier.de/db/conf/cikm/cikm2015.html)

> *null*

### [FAT\* 2015](https://dblp.uni-trier.de/db/conf/fat/fat2015.html)

> *null*

### [ICDM 2015](https://dblp.uni-trier.de/db/conf/icdm/icdm2015.html)

> *null*

### [ICML 2015](https://dblp.uni-trier.de/db/conf/icml/icml2015.html)

> *null*

### [IJCAI 2015](https://dblp.uni-trier.de/db/conf/ijcai/ijcai2015.html)

> *null*

### [KDD 2015](https://dblp.uni-trier.de/db/conf/kdd/kdd2015.html)

- [Certifying and Removing Disparate Impact](https://dl.acm.org/citation.cfm?doid=2783258.2783311)

### [NIPS 2015](https://dblp.uni-trier.de/db/conf/nips/nips2015.html)

> *null*

### [SDM 2015](https://dblp.uni-trier.de/db/conf/sdm/sdm2015.html)

> *null*

### [UAI 2015](https://dblp.uni-trier.de/db/conf/uai/uai2015.html)

> *null*

### [WWW 2015](https://dblp.uni-trier.de/db/conf/www/www2015.html)

> *null*

## 2014

- [Fair pattern discovery](https://dl.acm.org/citation.cfm?doid=2554850.2555043), SAC 2014
- [Anti-discrimination Analysis Using Privacy Attack Strategies](https://link.springer.com/chapter/10.1007%2F978-3-662-44851-9_44), ECML/PKDD 2014

## 2013

- [Learning Fair Representations](http://proceedings.mlr.press/v28/zemel13.html), ICML 2013
- [Discrimination aware classification for imbalanced datasets](https://dl.acm.org/citation.cfm?doid=2505515.2507836), CIKM 2013

## 2012

- [Fairness-Aware Classifier with Prejudice Remover Regularizer](https://link.springer.com/chapter/10.1007%2F978-3-642-33486-3_3), ECML/PKDD 2012
- [Fairness through awareness](https://dl.acm.org/citation.cfm?doid=2090236.2090255), ITCS 2012
- [Decision theory for discrimination-aware classification](https://ieeexplore.ieee.org/document/6413831), ICDM 2012
- [A study of top-k measures for discrimination discovery](https://dl.acm.org/citation.cfm?doid=2245276.2245303), SAC 2012

## 2011

- [k-NN as an implementation of situation testing for discrimination discovery and prevention](https://dl.acm.org/citation.cfm?doid=2020408.2020488), KDD 2011
- [Handling Conditional Discrimination](https://ieeexplore.ieee.org/document/6137304), ICDM 2011
- [Discrimination prevention in data mining for intrusion and crime detection](https://ieeexplore.ieee.org/document/5949405), CICS 2011

## 2010

- [Discrimination Aware Decision Tree Learning](https://ieeexplore.ieee.org/document/5694053), ICDM 2010
- [Classification with no discrimination by preferential sampling](https://dtai.cs.kuleuven.be/events/Benelearn2010/submissions/benelearn2010_submission_18.pdf), 19th Machine Learning Conf. Belgium and The Netherlands 2010

## 2009

- [Measuring Discrimination in Socially-Sensitive Decision Records](https://doi.org/10.1137/1.9781611972795.50), SDM 2009
- [Classifying without discriminating](https://ieeexplore.ieee.org/document/4909197), IC4 2009

## 2008

- [Discrimination-aware data mining](https://doi.org/10.1145/1401890.1401959), KDD 2008
