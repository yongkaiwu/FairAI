# Conference Papers

## 2021

### [AAAI 2021](https://dblp.uni-trier.de/db/conf/aaai/aaai2021.html)

> TBD

### [AISTATS 2021](https://dblp.uni-trier.de/db/conf/aistats/aistats2021.html)

- [Learning Individually Fair Classifier with Path-Specific Causal-Effect Constraint.](http://proceedings.mlr.press/v130/chikahara21a.html)
- [Learning Smooth and Fair Representations.](http://proceedings.mlr.press/v130/gitiaux21a.html)
- [Learning Fair Scoring Functions: Bipartite Ranking under ROC-based Fairness Constraints.](http://proceedings.mlr.press/v130/vogel21a.html)
- [Algorithms for Fairness in Sequential Decision Making.](http://proceedings.mlr.press/v130/wen21a.html)
- [All of the Fairness for Edge Prediction with Optimal Transport.](http://proceedings.mlr.press/v130/laclau21a.html)
- [Differentiable Causal Discovery Under Unmeasured Confounding.](http://proceedings.mlr.press/v130/bhattacharya21a.html)
- [Causal Modeling with Stochastic Confounders.](http://proceedings.mlr.press/v130/vinh-vo21a.html)
- [Fair for All: Best-effort Fairness Guarantees for Classification.](http://proceedings.mlr.press/v130/krishnaswamy21a.html)

### [BIGDATA 2021](https://dblp.uni-trier.de/db/conf/bigdataconf/bigdataconf2021.html)

> TBD

### [CIKM 2021](https://dblp.uni-trier.de/db/conf/cikm/cikm2021.html)

> TBD

### [FAT\* 2021](https://dblp.uni-trier.de/db/conf/fat/fat2021.html)

- [Black Feminist Musings on Algorithmic Oppression.](https://doi.org/10.1145/3442188.3445929)
- [Price Discrimination with Fairness Constraints.](https://doi.org/10.1145/3442188.3445864)
- [Fairness Violations and Mitigation under Covariate Shift.](https://doi.org/10.1145/3442188.3445865)
- [Reasons, Values, Stakeholders: A Philosophical Framework for Explainable Artificial Intelligence.](https://doi.org/10.1145/3442188.3445866)
- [Allocating Opportunities in a Dynamic Model of Intergenerational Mobility.](https://doi.org/10.1145/3442188.3445867)
- [Corporate Social Responsibility via Multi-Armed Bandits.](https://doi.org/10.1145/3442188.3445868)
- [Biases in Generative Art: A Causal Look from the Lens of Art History.](https://doi.org/10.1145/3442188.3445869)
- [Designing an Online Infrastructure for Collecting AI Data From People With Disabilities.](https://doi.org/10.1145/3442188.3445870)
- [Fifty Shades of Grey: In Praise of a Nuanced Approach Towards Trustworthy Design.](https://doi.org/10.1145/3442188.3445871)
- [Representativeness in Statistics, Politics, and Machine Learning.](https://doi.org/10.1145/3442188.3445872)
- [The Distributive Effects of Risk Prediction in Environmental Compliance: Algorithmic Design, Environmental Justice, and Public Policy.](https://doi.org/10.1145/3442188.3445873)
- [Computer Science Communities: Who is Speaking, and Who is Listening to the Women? Using an Ethics of Care to Promote Diverse Voices.](https://doi.org/10.1145/3442188.3445874)
- [Differential Tweetment: Mitigating Racial Dialect Bias in Harmful Tweet Detection.](https://doi.org/10.1145/3442188.3445875)
- [Group Fairness: Independence Revisited.](https://doi.org/10.1145/3442188.3445876)
- [Towards Fair Deep Anomaly Detection.](https://doi.org/10.1145/3442188.3445878)
- [Can You Fake It Until You Make It?: Impacts of Differentially Private Synthetic Data on Downstream Classification Fairness.](https://doi.org/10.1145/3442188.3445879)
- [Documenting Computer Vision Datasets: An Invitation to Reflexive Data Practices.](https://doi.org/10.1145/3442188.3445880)
- [Leveraging Administrative Data for Bias Audits: Assessing Disparate Coverage with Mobility Data for COVID-19 Policy.](https://doi.org/10.1145/3442188.3445881)
- [Better Together?: How Externalities of Size Complicate Notions of Solidarity and Actuarial Fairness.](https://doi.org/10.1145/3442188.3445882)
- [Removing Spurious Features can Hurt Accuracy and Affect Groups Disproportionately.](https://doi.org/10.1145/3442188.3445883)
- [Evaluating Fairness of Machine Learning Models Under Uncertain and Incomplete Information.](https://doi.org/10.1145/3442188.3445884)
- [Data Leverage: A Framework for Empowering the Public in its Relationship with Technology Companies.](https://doi.org/10.1145/3442188.3445885)
- [The Use and Misuse of Counterfactuals in Ethical Machine Learning.](https://doi.org/10.1145/3442188.3445886)
- [Mitigating Bias in Set Selection with Noisy Protected Attributes.](https://doi.org/10.1145/3442188.3445887)
- [What We Can't Measure, We Can't Understand: Challenges to Demographic Data Procurement in the Pursuit of Fairness.](https://doi.org/10.1145/3442188.3445888)
- [Standardized Tests and Affirmative Action: The Role of Bias and Variance.](https://doi.org/10.1145/3442188.3445889)
- [The Sanction of Authority: Promoting Public Trust in AI.](https://doi.org/10.1145/3442188.3445890)
- [Algorithmic Fairness in Predicting Opioid Use Disorder using Machine Learning.](https://doi.org/10.1145/3442188.3445891)
- [Avoiding Disparity Amplification under Different Worldviews.](https://doi.org/10.1145/3442188.3445892)
- [Spoken Corpora Data, Automatic Speech Recognition, and Bias Against African American Language: The case of Habitual 'Be'.](https://doi.org/10.1145/3442188.3445893)
- [Leave-one-out Unfairness.](https://doi.org/10.1145/3442188.3445894)
- [Fairness, Welfare, and Equity in Personalized Pricing.](https://doi.org/10.1145/3442188.3445895)
- [Re-imagining Algorithmic Fairness in India and Beyond.](https://doi.org/10.1145/3442188.3445896)
- [Narratives and Counternarratives on Data Sharing in Africa.](https://doi.org/10.1145/3442188.3445897)
- [This Whole Thing Smacks of Gender: Algorithmic Exclusion in Bioimpedance-based Body Composition Analysis.](https://doi.org/10.1145/3442188.3445898)
- [Algorithmic Recourse: from Counterfactual Explanations to Interventions.](https://doi.org/10.1145/3442188.3445899)
- [A Semiotics-based epistemic tool to reason about ethical issues in digital technology design and development.](https://doi.org/10.1145/3442188.3445900)
- [Measurement and Fairness.](https://doi.org/10.1145/3442188.3445901)
- [Fairness in Risk Assessment Instruments: Post-Processing to Achieve Counterfactual Equalized Odds.](https://doi.org/10.1145/3442188.3445902)
- [High Dimensional Model Explanations: An Axiomatic Approach.](https://doi.org/10.1145/3442188.3445903)
- [An Agent-based Model to Evaluate Interventions on Online Dating Platforms to Decrease Racial Homogamy.](https://doi.org/10.1145/3442188.3445904)
- [Designing Accountable Systems.](https://doi.org/10.1145/3442188.3445905)
- [Socially Fair k-Means Clustering.](https://doi.org/10.1145/3442188.3445906)
- [Towards Cross-Lingual Generalization of Translation Gender Bias.](https://doi.org/10.1145/3442188.3445907)
- [A Pilot Study in Surveying Clinical Judgments to Evaluate Radiology Report Generation.](https://doi.org/10.1145/3442188.3445909)
- [Fairness Through Robustness: Investigating Robustness Disparity in Deep Learning.](https://doi.org/10.1145/3442188.3445910)
- [Operationalizing Framing to Support Multiperspective Recommendations of Opinion Pieces.](https://doi.org/10.1145/3442188.3445911)
- [Bridging Machine Learning and Mechanism Design towards Algorithmic Fairness.](https://doi.org/10.1145/3442188.3445912)
- [Fair Clustering via Equitable Group Representations.](https://doi.org/10.1145/3442188.3445913)
- [You Can't Sit With Us: Exclusionary Pedagogy in AI Ethics Education.](https://doi.org/10.1145/3442188.3445914)
- [Fair Classification with Group-Dependent Label Noise.](https://doi.org/10.1145/3442188.3445915)
- [Censorship of Online Encyclopedias: Implications for NLP Models.](https://doi.org/10.1145/3442188.3445916)
- [Impossible Explanations?: Beyond explainable AI in the GDPR from a COVID-19 use case scenario.](https://doi.org/10.1145/3442188.3445917)
- [Towards Accountability for Machine Learning Datasets: Practices from Software Engineering and Infrastructure.](https://doi.org/10.1145/3442188.3445918)
- [Fairness, Equality, and Power in Algorithmic Decision-Making.](https://doi.org/10.1145/3442188.3445919)
- [One Label, One Billion Faces: Usage and Consistency of Racial Categories in Computer Vision.](https://doi.org/10.1145/3442188.3445920)
- [Reviewable Automated Decision-Making: A Framework for Accountable Algorithmic Systems.](https://doi.org/10.1145/3442188.3445921)
- [On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?](https://doi.org/10.1145/3442188.3445922)
- [Formalizing Trust in Artificial Intelligence: Prerequisites, Causes and Goals of Human Trust in AI.](https://doi.org/10.1145/3442188.3445923)
- [TILT: A GDPR-Aligned Transparency Information Language and Toolkit for Practical Privacy Engineering.](https://doi.org/10.1145/3442188.3445925)
- [From Papers to Programs: Courts, Corporations, Clinics and the Battle over Computerized Psychological Testing.](https://doi.org/10.1145/3442188.3445926)
- [A Statistical Test for Probabilistic Fairness.](https://doi.org/10.1145/3442188.3445927)
- [Building and Auditing Fair Algorithms: A Case Study in Candidate Screening.](https://doi.org/10.1145/3442188.3445928)
- [The Effect of the Rooney Rule on Implicit Bias in the Long Term.](https://doi.org/10.1145/3442188.3445930)
- [I agree with the decision, but they didn't deserve this: Future Developers' Perception of Fairness in Algorithmic Decisions.](https://doi.org/10.1145/3442188.3445931)
- [Image Representations Learned With Unsupervised Pre-Training Contain Human-like Biases.](https://doi.org/10.1145/3442188.3445932)
- [From Optimizing Engagement to Measuring Value.](https://doi.org/10.1145/3442188.3445933)
- [Chasing Your Long Tails: Differentially Private Prediction in Health Care Settings.](https://doi.org/10.1145/3442188.3445934)
- [Algorithmic Impact Assessments and Accountability: The Co-construction of Impacts.](https://doi.org/10.1145/3442188.3445935)
- [On the Moral Justification of Statistical Parity.](https://doi.org/10.1145/3442188.3445936)
- [Outlining Traceability: A Principle for Operationalizing Accountability in Computing Systems.](https://doi.org/10.1145/3442188.3445937)
- [An Action-Oriented AI Policy Toolkit for Technology Audits by Community Advocates and Activists.](https://doi.org/10.1145/3442188.3445938)
- [The Ethics of Emotion in Artificial Intelligence Systems.](https://doi.org/10.1145/3442188.3445939)
- [Detecting discriminatory risk through data annotation based on Bayesian inferences.](https://doi.org/10.1145/3442188.3445940)
- [How can I choose an explainer?: An Application-grounded Evaluation of Post-hoc Explanations.](https://doi.org/10.1145/3442188.3445941)
- [The Algorithmic Leviathan: Arbitrariness, Fairness, and Opportunity in Algorithmic Decision Making Systems.](https://doi.org/10.1145/3442188.3445942)
- [Epistemic values in feature importance methods: Lessons from feminist epistemology.](https://doi.org/10.1145/3442188.3445943)
- [A Bayesian Model of Cash Bail Decisions.](https://doi.org/10.1145/3442188.3445908)
- [The effect of differential victim crime reporting on predictive policing systems.](https://doi.org/10.1145/3442188.3445877)
- [Value Cards: An Educational Toolkit for Teaching Social Impacts of Machine Learning through Deliberation.](https://doi.org/10.1145/3442188.3445971)
- [BOLD: Dataset and Metrics for Measuring Biases in Open-Ended Language Generation.](https://doi.org/10.1145/3442188.3445924)
- [When the Umpire is also a Player: Bias in Private Label Product Recommendations on E-commerce Marketplaces.](https://doi.org/10.1145/3442188.3445944)

### [ICDM 2021](https://dblp.uni-trier.de/db/conf/icdm/icdm2021.html)

> TBD

### [ICML 2021](https://dblp.uni-trier.de/db/conf/icml/icml2021.html)

> TBD

### [IJCAI 2021](https://dblp.uni-trier.de/db/conf/ijcai/ijcai2021.html)

> TBD

### [KDD 2021](https://dblp.uni-trier.de/db/conf/kdd/kdd2021.html)

> TBD

### [NIPS 2021](https://dblp.uni-trier.de/db/conf/nips/neurips2021.html)

> TBD

### [SDM 2021](https://dblp.uni-trier.de/db/conf/sdm/sdm2021.html)

> TBD

### [UAI 2021](https://dblp.uni-trier.de/db/conf/uai/uai2021.html)

> TBD

### [WWW 2021](https://dblp.uni-trier.de/db/conf/www/www2021.html)

> TBD

### Others 2021

#### [WSDM 2021](https://dblp.uni-trier.de/db/conf/wsdm/wsdm2021.html)

- [Popularity-Opportunity Bias in Collaborative Filtering.](https://doi.org/10.1145/3437963.3441820)
- [Deconfounding with Networked Observational Data in a Dynamic Environment.](https://doi.org/10.1145/3437963.3441818)
- [Causal Transfer Random Forest: Combining Logged Data and Randomized Experiments for Robust Prediction.](https://doi.org/10.1145/3437963.3441722)
- [Split-Treatment Analysis to Rank Heterogeneous Causal Effects for Prospective Interventions.](https://doi.org/10.1145/3437963.3441821)
- [Explain and Predict, and then Predict Again.](https://doi.org/10.1145/3437963.3441758)
- [Combating Selection Biases in Recommender Systems with a Few Unbiased Ratings.](https://doi.org/10.1145/3437963.3441799)
- [Practical Compositional Fairness: Understanding Fairness in Multi-Component Recommender Systems.](https://doi.org/10.1145/3437963.3441732)
- [Towards Long-term Fairness in Recommendation.](https://doi.org/10.1145/3437963.3441824)
- [Unifying Online and Counterfactual Learning to Rank: A Novel Counterfactual Estimator that Effectively Utilizes Online Interventions.](https://doi.org/10.1145/3437963.3441794)
- [Interpretable Ranking with Generalized Additive Models.](https://doi.org/10.1145/3437963.3441796)

## 2020

### [AAAI 2020](https://dblp.uni-trier.de/db/conf/aaai/aaai2020.html)

- [Faking Fairness via Stealthily Biased Sampling.](https://aaai.org/ojs/index.php/AAAI/article/view/5377)
- [Differentially Private and Fair Classification via Calibrated Functional Mechanism.](https://aaai.org/ojs/index.php/AAAI/article/view/5402)
- [Bursting the Filter Bubble: Fairness-Aware Network Link Prediction.](https://aaai.org/ojs/index.php/AAAI/article/view/5429)
- [Making Existing Clusterings Fairer: Algorithms, Complexity Results and Insights.](https://aaai.org/ojs/index.php/AAAI/article/view/5783)
- [Fairness in Network Representation by Latent Structural Heterogeneity in Observational Data.](https://aaai.org/ojs/index.php/AAAI/article/view/5792)
- [Pairwise Fairness for Ranking and Regression.](https://aaai.org/ojs/index.php/AAAI/article/view/5970)
- [Achieving Fairness in the Stochastic Multi-Armed Bandit Problem.](https://aaai.org/ojs/index.php/AAAI/article/view/5986)
- [Fairness for Robust Log Loss Classification.](https://aaai.org/ojs/index.php/AAAI/article/view/6002)
- [Learning Fair Naive Bayes Classifiers by Discovering and Eliminating Discrimination Patterns.](https://aaai.org/ojs/index.php/AAAI/article/view/6565)

### [AISTATS 2020](https://dblp.uni-trier.de/db/conf/aistats/aistats2020.html)

- [Stretching the Effectiveness of MLE from Accuracy to Bias for Pairwise Comparisons.](http://proceedings.mlr.press/v108/wang20a.html)
- [Learning Fair Representations for Kernel Models.](http://proceedings.mlr.press/v108/tan20a.html)
- [Fair Decisions Despite Imperfect Predictions.](http://proceedings.mlr.press/v108/kilbertus20a.html)
- [Identifying and Correcting Label Bias in Machine Learning.](http://proceedings.mlr.press/v108/jiang20a.html)
- [Optimized Score Transformation for Fair Classification.](http://proceedings.mlr.press/v108/wei20a.html)
- [Equalized odds postprocessing under imperfect group information.](http://proceedings.mlr.press/v108/awasthi20a.html)
- [Fairness Evaluation in Presence of Biased Noisy Labels.](http://proceedings.mlr.press/v108/fogliato20a.html)
- [Fair Correlation Clustering.](http://proceedings.mlr.press/v108/ahmadian20a.html)
- [Auditing ML Models for Individual Bias and Unfairness.](http://proceedings.mlr.press/v108/xue20a.html)

### [BIGDATA 2020](https://dblp.uni-trier.de/db/conf/bigdataconf/bigdataconf2020.html)

> TBD

### [CIKM 2020](https://dblp.uni-trier.de/db/conf/cikm/cikm2020.html)

- [Spectral Relaxations and Fair Densest Subgraphs.](https://doi.org/10.1145/3340531.3412036)
- [Fair Class Balancing: Enhancing Model Fairness without Observing Sensitive Attributes.](https://doi.org/10.1145/3340531.3411980)
- [Active Query of Private Demographic Data for Learning Fair Models.](https://doi.org/10.1145/3340531.3412074)
- [Fairness-Aware Learning with Prejudice Free Representations.](https://doi.org/10.1145/3340531.3412150)
- [Denoising Individual Bias for Fairer Binary Submatrix Detection.](https://doi.org/10.1145/3340531.3412156)
- [LiFT: A Scalable Framework for Measuring Fairness in ML Applications.](https://doi.org/10.1145/3340531.3412705)

### [FAT\* 2020](https://dblp.uni-trier.de/db/conf/fat/fat2020.html)

- [What to account for when accounting for algorithms: a systematic literature review on algorithmic accountability.](https://doi.org/10.1145/3351095.3372833)
- [Algorithmic realism: expanding the boundaries of algorithmic thought.](https://doi.org/10.1145/3351095.3372840)
- [Algorithmic accountability in public administration: the GDPR paradox.](https://doi.org/10.1145/3351095.3373153)
- [Closing the AI accountability gap: defining an end-to-end framework for internal algorithmic auditing.](https://doi.org/10.1145/3351095.3372873)
- [Toward situated interventions for algorithmic equity: lessons from the field.](https://doi.org/10.1145/3351095.3372874)
- [Explainability fact sheets: a framework for systematic assessment of explainable approaches.](https://doi.org/10.1145/3351095.3372870)
- [Multi-layered explanations from algorithmic impact assessments in the GDPR.](https://doi.org/10.1145/3351095.3372875)
- [The hidden assumptions behind counterfactual explanations and principal reasons.](https://doi.org/10.1145/3351095.3372830)
- [Why does my model fail?: contrastive local explanations for retail forecasting.](https://doi.org/10.1145/3351095.3372824)
- ["The human body is a black box": supporting clinical decision-making with deep learning.](https://doi.org/10.1145/3351095.3372827)
- [Assessing algorithmic fairness with unobserved protected class using data combination.](https://doi.org/10.1145/3351095.3373154)
- [FlipTest: fairness testing via optimal transport.](https://doi.org/10.1145/3351095.3372845)
- [Implications of AI (un-)fairness in higher education admissions: the effects of perceived AI (un-)fairness on exit, voice and organizational reputation.](https://doi.org/10.1145/3351095.3372867)
- [Auditing radicalization pathways on YouTube.](https://doi.org/10.1145/3351095.3372879)
- [Case study: predictive fairness to reduce misdemeanor recidivism through social service interventions.](https://doi.org/10.1145/3351095.3372863)
- [The concept of fairness in the GDPR: a linguistic and contextual interpretation.](https://doi.org/10.1145/3351095.3372868)
- [Studying up: reorienting the study of algorithmic fairness around issues of power.](https://doi.org/10.1145/3351095.3372859)
- [POTs: protective optimization technologies.](https://doi.org/10.1145/3351095.3372853)
- [Fair decision making using privacy-protected data.](https://doi.org/10.1145/3351095.3372872)
- [Fairness warnings and fair-MAML: learning fairly with minimal data.](https://doi.org/10.1145/3351095.3372839)
- [From ethics washing to ethics bashing: a view on tech ethics from within moral philosophy.](https://doi.org/10.1145/3351095.3372860)
- [Onward for the freedom of others: marching beyond the AI ethics.](https://doi.org/10.1145/3351095.3373152)
- [Whose side are ethics codes on?: power, responsibility and the social good.](https://doi.org/10.1145/3351095.3372844)
- [Algorithmic targeting of social policies: fairness, accuracy, and distributed governance.](https://doi.org/10.1145/3351095.3375784)
- [Roles for computing in social change.](https://doi.org/10.1145/3351095.3372871)
- [Regulating transparency?: Facebook, Twitter and the german network enforcement act.](https://doi.org/10.1145/3351095.3372856)
- [The relationship between trust in AI and trustworthy machine learning technologies.](https://doi.org/10.1145/3351095.3372834)
- [The philosophical basis of algorithmic recourse.](https://doi.org/10.1145/3351095.3372876)
- [Value-laden disciplinary shifts in machine learning.](https://doi.org/10.1145/3351095.3373157)
- [Effect of confidence and explanation on accuracy and trust calibration in AI-assisted decision making.](https://doi.org/10.1145/3351095.3372852)
- [Lessons from archives: strategies for collecting sociocultural data in machine learning.](https://doi.org/10.1145/3351095.3372829)
- [Data in New Delhi's predictive policing system.](https://doi.org/10.1145/3351095.3372865)
- [Garbage in, garbage out?: do machine learning application papers in social computing report where human-labeled training data comes from?](https://doi.org/10.1145/3351095.3372862)
- [Bidding strategies with gender nondiscrimination constraints for online ad auctions.](https://doi.org/10.1145/3351095.3375783)
- [Multi-category fairness in sponsored search auctions.](https://doi.org/10.1145/3351095.3372848)
- [Reducing sentiment polarity for demographic attributes in word embeddings using adversarial learning.](https://doi.org/10.1145/3351095.3372837)
- [Interventions for ranking in the presence of implicit bias.](https://doi.org/10.1145/3351095.3372858)
- [The disparate equilibria of algorithmic decision making when individuals invest rationally.](https://doi.org/10.1145/3351095.3372861)
- [An empirical study on the perceived fairness of realistic, imperfect machine learning models.](https://doi.org/10.1145/3351095.3372831)
- [Artificial mental phenomena: psychophysics as a framework to detect perception biases in AI models.](https://doi.org/10.1145/3351095.3375623)
- [The social lives of generative adversarial networks.](https://doi.org/10.1145/3351095.3373156)
- [Towards a more representative politics in the ethics of computer science.](https://doi.org/10.1145/3351095.3372854)
- [Integrating FATE/critical data studies into data science curricula: where are we going and how do we get there?](https://doi.org/10.1145/3351095.3372832)
- [Recommendations and user agency: the reachability of collaboratively-filtered information.](https://doi.org/10.1145/3351095.3372866)
- [Bias in word embeddings.](https://doi.org/10.1145/3351095.3372843)
- [What does it mean to 'solve' the problem of discrimination in hiring?: social, technical and legal perspectives from the UK on automated hiring systems.](https://doi.org/10.1145/3351095.3372849)
- [Mitigating bias in algorithmic hiring: evaluating claims and practices.](https://doi.org/10.1145/3351095.3372828)
- [The impact of overbooking on a pre-trial risk assessment tool.](https://doi.org/10.1145/3351095.3372846)
- [Awareness in practice: tensions in access to sensitive attribute data for antidiscrimination.](https://doi.org/10.1145/3351095.3372877)
- [Towards a critical race methodology in algorithmic fairness.](https://doi.org/10.1145/3351095.3372826)
- [What's sex got to do with machine learning?](https://doi.org/10.1145/3351095.3375674)
- [On the apparent conflict between individual and group fairness.](https://doi.org/10.1145/3351095.3372864)
- [Fairness is not static: deeper understanding of long term fairness via simulation studies.](https://doi.org/10.1145/3351095.3372878)
- [Fair classification and social welfare.](https://doi.org/10.1145/3351095.3372857)
- [Preference-informed fairness.](https://doi.org/10.1145/3351095.3373155)
- [Towards fairer datasets: filtering and balancing the distribution of the people subtree in the ImageNet hierarchy.](https://doi.org/10.1145/3351095.3375709)
- [The case for voter-centered audits of search engines during political elections.](https://doi.org/10.1145/3351095.3372835)
- [Whose tweets are surveilled for the police: an audit of a social-media monitoring tool via log files.](https://doi.org/10.1145/3351095.3372841)
- [Dirichlet uncertainty wrappers for actionable algorithm accuracy accountability and auditability.](https://doi.org/10.1145/3351095.3372825)
- [Counterfactual risk assessments, evaluation, and fairness.](https://doi.org/10.1145/3351095.3372851)
- [The false promise of risk assessments: epistemic reform and the limits of fairness.](https://doi.org/10.1145/3351095.3372869)
- [Explaining machine learning classifiers through diverse counterfactual explanations.](https://doi.org/10.1145/3351095.3372850)
- [Model agnostic interpretability of rankers via intent modelling.](https://doi.org/10.1145/3351095.3375234)
- [Doctor XAI: an ontology-based approach to black-box sequential data classification explanations.](https://doi.org/10.1145/3351095.3372855)
- [Robustness in machine learning explanations: does it matter?](https://doi.org/10.1145/3351095.3372836)
- [Explainable machine learning in deployment.](https://doi.org/10.1145/3351095.3375624)
- [Fairness and utilization in allocating resources with uncertain demand.](https://doi.org/10.1145/3351095.3372847)
- [The effects of competition and regulation on error inequality in data-driven markets.](https://doi.org/10.1145/3351095.3372842)

### [ICDM 2020](https://dblp.uni-trier.de/db/conf/icdm/icdm2020.html)

> TBD

### [ICML 2020](https://dblp.uni-trier.de/db/conf/icml/icml2020.html)

- [A Pairwise Fair and Community-preserving Approach to k-Center Clustering.](http://proceedings.mlr.press/v119/brubach20a.html)
- [How to Solve Fair k-Center in Massive Data Models.](http://proceedings.mlr.press/v119/chiplunkar20a.html)
- [Fair Generative Modeling via Weak Supervision.](http://proceedings.mlr.press/v119/choi20a.html)
- [Causal Modeling for Fairness In Dynamical Systems.](http://proceedings.mlr.press/v119/creager20a.html)
- [Is There a Trade-Off Between Fairness and Accuracy? A Perspective Using Mismatched Hypothesis Testing.](http://proceedings.mlr.press/v119/dutta20a.html)
- [Fair k-Centers via Maximum Matching.](http://proceedings.mlr.press/v119/jones20a.html)
- [FACT: A Diagnostic for Group Fairness Trade-offs.](http://proceedings.mlr.press/v119/kim20a.html)
- [Too Relaxed to Be Fair.](http://proceedings.mlr.press/v119/lohaus20a.html)
- [Individual Fairness for k-Clustering.](http://proceedings.mlr.press/v119/mahabadi20a.html)
- [Minimax Pareto Fairness: A Multi Objective Perspective.](http://proceedings.mlr.press/v119/martinez20a.html)
- [Fair Learning with Private Demographic Data.](http://proceedings.mlr.press/v119/mozannar20a.html)
- [Two Simple Ways to Learn Individual Fairness Metrics from Data.](http://proceedings.mlr.press/v119/mukherjee20a.html)
- [FR-Train: A Mutual Information-Based Approach to Fair and Robust Training.](http://proceedings.mlr.press/v119/roh20a.html)
- [Bounding the fairness and accuracy of classifiers from population statistics.](http://proceedings.mlr.press/v119/sabato20a.html)
- [Measuring Non-Expert Comprehension of Machine Learning Fairness Metrics.](http://proceedings.mlr.press/v119/saha20c.html)
- [Learning Fair Policies in Multi-Objective (Deep) Reinforcement Learning with Average and Discounted Rewards.](http://proceedings.mlr.press/v119/siddique20a.html)
- [Learning De-biased Representations with Biased Representations.](http://proceedings.mlr.press/v119/bahng20a.html)
- [DeBayes: a Bayesian Method for Debiasing Network Embeddings.](http://proceedings.mlr.press/v119/buyl20a.html)
- [Data preprocessing to mitigate bias: A maximum entropy based approach.](http://proceedings.mlr.press/v119/celis20a.html)

### [IJCAI 2020](https://dblp.uni-trier.de/db/conf/ijcai/ijcai2020.html)

- [WEFE: The Word Embeddings Fairness Evaluation Framework.](https://doi.org/10.24963/ijcai.2020/60)
- [Individual Fairness Revisited: Transferring Techniques from Adversarial Robustness.](https://doi.org/10.24963/ijcai.2020/61)
- [Achieving Outcome Fairness in Machine Learning Models for Social Decision Problems.](https://doi.org/10.24963/ijcai.2020/62)
- [Relation-Based Counterfactual Explanations for Bayesian Network Classifiers.](https://doi.org/10.24963/ijcai.2020/63)
- [Metamorphic Testing and Certified Mitigation of Fairness Violations in NLP Models.](https://doi.org/10.24963/ijcai.2020/64)
- [Fairness-Aware Neural Rényi Minimization for Continuous Features.](https://doi.org/10.24963/ijcai.2020/313)
- [FNNC: Achieving Fairness through Neural Networks.](https://doi.org/10.24963/ijcai.2020/315)
- [Adversarial Graph Embeddings for Fair Influence Maximization over Social Networks.](https://doi.org/10.24963/ijcai.2020/594)

### [KDD 2020](https://dblp.uni-trier.de/db/conf/kdd/kdd2020.html)

- [InFoRM: Individual Fairness on Graph Mining.](https://dl.acm.org/doi/10.1145/3394486.3403080)
- [Towards Fair Truth Discovery from Biased Crowdsourced Answers.](https://dl.acm.org/doi/10.1145/3394486.3403102)
- [Evaluating Fairness Using Permutation Tests.](https://dl.acm.org/doi/10.1145/3394486.3403199)
- [A Causal Look at Statistical Definitions of Discrimination.](https://dl.acm.org/doi/10.1145/3394486.3403130)
- [List-wise Fairness Criterion for Point Processes.](https://dl.acm.org/doi/10.1145/3394486.3403246)
- [Algorithmic Decision Making with Conditional Fairness.](https://dl.acm.org/doi/10.1145/3394486.3403263)

### [NIPS 2020](https://dblp.uni-trier.de/db/conf/nips/neurips2020.html)

- [Achieving Equalized Odds by Resampling Sensitive Attributes.](https://proceedings.neurips.cc/paper/2020/hash/03593ce517feac573fdaafa6dcedef61-Abstract.html)
- [Fairness without Demographics through Adversarially Reweighted Learning.](https://proceedings.neurips.cc/paper/2020/hash/07fc15c9d169ee48573edd749d25945d-Abstract.html)
- [Fairness with Overlapping Groups; a Probabilistic Perspective.](https://proceedings.neurips.cc/paper/2020/hash/29c0605a3bab4229e46723f89cf59d83-Abstract.html)
- [Robust Optimization for Fairness with Noisy Protected Groups.](https://proceedings.neurips.cc/paper/2020/hash/37d097caf1299d9aa79c2c2b843d2d78-Abstract.html)
- [Fair regression with Wasserstein barycenters.](https://proceedings.neurips.cc/paper/2020/hash/51cdbd2611e844ece5d80878eb770436-Abstract.html)
- [Learning Certified Individually Fair Representations.](https://proceedings.neurips.cc/paper/2020/hash/55d491cf951b1b920900684d71419282-Abstract.html)
- [Metric-Free Individual Fairness in Online Learning.](https://proceedings.neurips.cc/paper/2020/hash/80b618ebcac7aa97a6dac2ba65cb7e36-Abstract.html)
- [Fairness constraints can help exact inference in structured prediction.](https://proceedings.neurips.cc/paper/2020/hash/8248a99e81e752cb9b41da3fc43fbe7f-Abstract.html)
- [Investigating Gender Bias in Language Models Using Causal Mediation Analysis.](https://proceedings.neurips.cc/paper/2020/hash/92650b2e92217715fe312e6fa7b90d82-Abstract.html)
- [Probabilistic Fair Clustering.](https://proceedings.neurips.cc/paper/2020/hash/95f2b84de5660ddf45c8a34933a2e66f-Abstract.html)
- [KFC: A Scalable Approximation Algorithm for $k$-center Fair Clustering.](https://proceedings.neurips.cc/paper/2020/hash/a6d259bfbfa2062843ef543e21d7ec8e-Abstract.html)
- [A Fair Classifier Using Kernel Density Estimation.](https://proceedings.neurips.cc/paper/2020/hash/ac3870fcad1cfc367825cda0101eee62-Abstract.html)
- [Exploiting MMD and Sinkhorn Divergences for Fair and Transferable Representation Learning.](https://proceedings.neurips.cc/paper/2020/hash/af9c0e0c1dee63e5acad8b7ed1a5be96-Abstract.html)
- [Fair Multiple Decision Making Through Soft Interventions.](https://proceedings.neurips.cc/paper/2020/hash/d0921d442ee91b896ad95059d13df618-Abstract.html)
- [Ensuring Fairness Beyond the Training Data.](https://proceedings.neurips.cc/paper/2020/hash/d6539d3b57159babf6a72e106beb45bd-Abstract.html)
- [How do fair decisions fare in long-term qualification?](https://proceedings.neurips.cc/paper/2020/hash/d6d231705f96d5a35aeb3a76402e49a3-Abstract.html)
- [Can I Trust My Fairness Metric? Assessing Fairness with Unlabeled Data and Bayesian Inference.](https://proceedings.neurips.cc/paper/2020/hash/d83de59e10227072a9c034ce10029c39-Abstract.html)
- [Fair regression via plug-in estimator and recalibration with statistical guarantees.](https://proceedings.neurips.cc/paper/2020/hash/ddd808772c035aed516d42ad3559be5f-Abstract.html)
- [Learning from Failure: De-biasing Classifier from Biased Classifier.](https://proceedings.neurips.cc/paper/2020/hash/eddc3427c5d77843c2253f1e799fe933-Abstract.html)
- [Fair Hierarchical Clustering.](https://proceedings.neurips.cc/paper/2020/hash/f10f2da9a238b746d2bac55759915f0d-Abstract.html)

### [SDM 2020](https://dblp.uni-trier.de/db/conf/sdm/sdm2020.html)

- [Bayesian Modeling of Intersectional Fairness: The Variance of Bias.](https://doi.org/10.1137/1.9781611976236.48)
- [On the Information Unfairness of Social Networks.](https://doi.org/10.1137/1.9781611976236.69)

### [UAI 2020](https://dblp.uni-trier.de/db/conf/uai/uai2020.html)

- [Fair Contextual Multi-Armed Bandits: Theory and Experiments.](http://www.auai.org/uai2020/proceedings/99_main_paper.pdf)
- [Towards Threshold Invariant Fair Classification.](http://www.auai.org/uai2020/proceedings/237_main_paper.pdf)
- [Verifying Individual Fairness in Machine Learning Models.](http://www.auai.org/uai2020/proceedings/327_main_paper.pdf)

### [WWW 2020](https://dblp.uni-trier.de/db/conf/www/www2020.html)

- [FairRec: Two-Sided Fairness for Personalized Recommendations in Two-Sided Platforms.](https://doi.org/10.1145/3366423.3380196)
- [Designing Fairly Fair Classifiers Via Economic Fairness Notions.](https://doi.org/10.1145/3366423.3380228)
- [Learning Model-Agnostic Counterfactual Explanations for Tabular Data.](https://doi.org/10.1145/3366423.3380087)

### Others 2020

#### [ASONAM 2020](https://dblp.uni-trier.de/db/conf/asunam/asonam2020.html)

- [Bias in Knowledge Graph Embeddings.](https://doi.org/10.1109/ASONAM49781.2020.9381459)
- [Debiasing Graph Representations via Metadata-Orthogonal Training.](https://doi.org/10.1109/ASONAM49781.2020.9381348)

## 2019

### [AAAI 2019](https://dblp.uni-trier.de/db/conf/aaai/aaai2019.html)

- [Learning Optimal and Fair Decision Trees for Non-Discriminative Decision-Making](https://aaai.org/ojs/index.php/AAAI/article/view/3943)
- [Learning to Address Health Inequality in the United States with a Bayesian Decision Network](https://aaai.org/ojs/index.php/AAAI/article/view/3849)
- [Convex Formulations for Fair Principal Component Analysis](https://aaai.org/ojs/index.php/AAAI/article/view/3843)
- [Bayesian Fairness](https://aaai.org/ojs/index.php/AAAI/article/view/3824)
- [One-Network Adversarial Fairness](https://aaai.org/ojs/index.php/AAAI/article/view/4085)
- [Eliminating Latent Discrimination: Train Then Mask](https://aaai.org/ojs/index.php/AAAI/article/view/4251)
- [Path-Specific Counterfactual Fairness](https://aaai.org/ojs/index.php/AAAI/article/view/4777)

### [AISTATS 2019](https://dblp.uni-trier.de/db/conf/aistats/aistats2019.html)

- [Learning Controllable Fair Representations](http://proceedings.mlr.press/v89/song19a)

### [BIGDATA 2019](https://dblp.uni-trier.de/db/conf/bigdataconf/bigdataconf2019.html)

- [FAE: A Fairness-Aware Ensemble Framework](https://ieeexplore.ieee.org/document/9006487/)
- [Privacy Bargaining with Fairness: Privacy–Price Negotiation System for Applying Differential Privacy in Data Market Environments](https://ieeexplore.ieee.org/document/9006101/)
- [FairGAN+: Achieving Fair Data Generation and Classification through Generative Adversarial Nets](https://ieeexplore.ieee.org/document/9006322/)

### [CIKM 2019](https://dblp.uni-trier.de/db/conf/cikm/cikm2019.html)

- [AdaFair: Cumulative Fairness Adaptive Boosting](https://doi.org/10.1145/3357384.3357974)

### [FAT\* 2019](https://dblp.uni-trier.de/db/conf/fat/fat2019.html)

- [Explaining Explanations in AI](https://dl.acm.org/authorize?N675479)
- [Deep Weighted Averaging Classifiers](https://dl.acm.org/authorize?N675488)
- [Fairness and Abstraction in Sociotechnical Systems](https://dl.acm.org/authorize?N675344)
- [50 Years of Test (Un)fairness: Lessons for Machine Learning](https://dl.acm.org/authorize?N675343)
- [A comparative study of fairness-enhancing interventions in machine learning](https://dl.acm.org/authorize?N675474)
- [Beyond Open vs. Closed: Balancing Individual Privacy and Public Accountability in Data Sharing](https://dl.acm.org/authorize?N675460)
- [Analyzing Biases in Perception of Truth in News Stories and their Implications for Fact Checking](https://dl.acm.org/authorize?N675453)
- [Disparate Interactions: An Algorithm-in-the-Loop Analysis of Fairness in Risk Assessments](https://dl.acm.org/authorize?N675458)
- [Problem Formulation and Fairness](https://dl.acm.org/authorize?N675342)
- [Fairness under unawareness: assessing disparity when protected class is unobserved](https://dl.acm.org/authorize?N675485)
- [On Human Predictions with Explanations and Predictions of Machine Learning Models: A Case Study on Deception Detection](https://dl.acm.org/authorize?N675341)
- [Actionable Recourse in Linear Classification](https://dl.acm.org/authorize?N675349)
- [A Taxonomy of Ethical Tensions in Inferring Mental Health States from Social Media](https://dl.acm.org/authorize?N675456)
- [The Disparate Effects of Strategic Manipulation](https://dl.acm.org/authorize?N675477)
- [An Algorithmic Framework to Control Polarization in Personalization](https://dl.acm.org/authorize?N675466)
- [Racial categories in machine learning](https://dl.acm.org/authorize?N675470)
- [Downstream Effects of Affirmative Action](https://dl.acm.org/authorize?N675475)
- [Fairness through Causal Awareness: Learning Causal Latent-Variable Models for Biased Data](https://dl.acm.org/authorize?N675486)
- [Model Reconstruction from Model Explanations](https://dl.acm.org/authorize?N675348)
- [Fair Allocation through Competitive Equilibrium from Generic Incomes](https://dl.acm.org/authorize?N675468)
- [An Empirical Study of Rich Subgroup Fairness for Machine Learning](https://dl.acm.org/authorize?N675459)
- [From Soft Classifiers to Hard Decisions: How fair can we be?](https://dl.acm.org/authorize?N675472)
- [Efficient Search for Diverse Coherent Explanations](https://dl.acm.org/authorize?N675340)
- [Robot Eyes Wide Shut: Understanding Dishonest Anthropomorphism](https://dl.acm.org/authorize?N675471)
- [A Moral Framework for Understanding Fair ML through Economic Models of Equality of Opportunity](https://dl.acm.org/authorize?N675469)
- [Classification with Fairness Constraints: A Meta-Algorithm with Provable Guarantees](https://dl.acm.org/authorize?N675473)
- [Access to Population-Level Signaling as a Source of Inequality](https://dl.acm.org/authorize?N675476)
- [Measuring the Biases that Matter: The Ethical and Casual Foundations for Measures of Fairness in Algorithms](https://dl.acm.org/authorize?N675478)
- [Fairness-Aware Programming](https://dl.acm.org/authorize?N675462)
- [The Profiling Potential of Computer Vision and the Challenge of Computational Empiricism](https://dl.acm.org/authorize?N675450)
- [Clear Sanctions, Vague Rewards: How China's Social Credit System Defines "Good" and "Bad" Behavior](https://dl.acm.org/authorize?N675455)
- [Bias in Bios: A Case Study of Semantic Representation Bias in a High-Stakes Setting](https://dl.acm.org/authorize?N675451)
- [Who's the Guinea Pig? Investigating Online A/B/n Tests In-The-Wild](https://dl.acm.org/authorize?N675461)
- [Fair Algorithms for Learning in Allocation Problems](https://dl.acm.org/authorize?N675467)
- [On Microtargeting Socially Divisive Ads: A Case Study of Russia-Linked Ad Campaigns on Facebook](https://dl.acm.org/authorize?N675454)
- [Model Cards for Model Reporting](https://dl.acm.org/authorize?N675463)
- [Dissecting Racial Bias in an Algorithm that Guides Health Decisions for 70 million people](https://dl.acm.org/authorize?N675457)
- [The Social Cost of Strategic Classification](https://dl.acm.org/authorize?N675464)
- [SIREN: A Simulation Framework for Understanding the Effects of Recommender Systems in Online News Environments](https://dl.acm.org/authorize?N675465)
- [Equality of Voice: Towards Fair Representation in Crowdsourced Top-K Recommendations](https://dl.acm.org/authorize?N675452)
- [From Fair Decision Making To Social Equality](https://dl.acm.org/authorize?N675487)

### [ICDM 2019](https://dblp.uni-trier.de/db/conf/icdm/icdm2019.html)

- [Fair Adversarial Gradient Tree Boosting](https://ieeexplore.ieee.org/document/8970941/)
- [Rank-Based Multi-task Learning For Fair Regression](https://ieeexplore.ieee.org/document/8970984/)
- [A Distributed Fair Machine Learning Framework with Private Demographic Data Protection](https://ieeexplore.ieee.org/document/8970908/)

### [ICML 2019](https://dblp.uni-trier.de/db/conf/icml/icml2019.html)

- [Fair Regression: Quantitative Definitions and Reduction-Based Algorithms](http://proceedings.mlr.press/v97/agarwal19d.html)
- [Fairwashing: the risk of rationalization](http://proceedings.mlr.press/v97/aivodji19a.html)
- [Scalable Fair Clustering](http://proceedings.mlr.press/v97/backurs19a.html)
- [Compositional Fairness Constraints for Graph Embeddings](http://proceedings.mlr.press/v97/bose19a.html)
- [Understanding the Origins of Bias in Word Embeddings](http://proceedings.mlr.press/v97/brunet19a.html)
- [Proportionally Fair Clustering](http://proceedings.mlr.press/v97/chen19d.html)
- [Training Well-Generalizing Classifiers for Fairness Metrics and Other Data-Dependent Constraints](http://proceedings.mlr.press/v97/cotter19b.html)
- [Flexibly Fair Representation Learning by Disentanglement](http://proceedings.mlr.press/v97/creager19a.html)
- [Obtaining Fairness using Optimal Transport Theory](http://proceedings.mlr.press/v97/gordaliza19a.html)
- [On the Long-term Impact of Algorithmic Decision Policies: Effort Unfairness and Feature Segregation through Social Learning](http://proceedings.mlr.press/v97/heidari19a.html)
- [Stable and Fair Classification](http://proceedings.mlr.press/v97/huang19e.html)
- [Differentially Private Fair Learning](http://proceedings.mlr.press/v97/jagielski19a.html)
- [Fair k-Center Clustering for Data Summarization](http://proceedings.mlr.press/v97/kleindessner19a.html)
- [Guarantees for Spectral Clustering with Fairness Constraints](http://proceedings.mlr.press/v97/kleindessner19b.html)
- [Making Decisions that Reduce Discriminatory Impacts](http://proceedings.mlr.press/v97/kusner19a.html)
- [The Implicit Fairness Criterion of Unconstrained Learning](http://proceedings.mlr.press/v97/liu19f.html)
- [Fairness-Aware Learning for Continuous Attributes and Treatments](http://proceedings.mlr.press/v97/mary19a.html)
- [Toward Controlling Discrimination in Online Ad Auctions](http://proceedings.mlr.press/v97/mehrotra19a.html)
- [Learning Optimal Fair Policies](http://proceedings.mlr.press/v97/nabi19a.html)
- [Fairness without Harm: Decoupled Classifiers with Preference Guarantees](http://proceedings.mlr.press/v97/ustun19a.html)
- [Repairing without Retraining: Avoiding Disparate Impact with Counterfactual Distributions](http://proceedings.mlr.press/v97/wang19l.html)
- [Fairness risk measures](http://proceedings.mlr.press/v97/williamson19a.html)

### [IJCAI 2019](https://dblp.uni-trier.de/db/conf/ijcai/ijcai2019.html)

- [Counterfactual Fairness: Unidentification, Bound and Algorithm](https://doi.org/10.24963/ijcai.2019/199)
- [Achieving Causal Fairness through Generative Adversarial Networks](https://doi.org/10.24963/ijcai.2019/201)
- [FAHT: An Adaptive Fairness-aware Decision Tree Classifier](https://doi.org/10.24963/ijcai.2019/205)
- [Delayed Impact of Fair Machine Learning](https://doi.org/10.24963/ijcai.2019/862)
- [The Price of Local Fairness in Multistage Selection](https://www.ijcai.org/proceedings/2019/809)

### [KDD 2019](https://dblp.uni-trier.de/db/conf/kdd/kdd2019.html)

- [Fairness in Recommendation Ranking through Pairwise Comparisons](https://doi.org/10.1145/3292500.3330745)
- [Fairness-Aware Ranking in Search & Recommendation Systems with Application to LinkedIn Talent Search](https://doi.org/10.1145/3292500.3330691)
- [Mathematical Notions vs. Human Perception of Fairness: A Descriptive Approach to Fairness for Machine Learning](https://doi.org/10.1145/3292500.3330664)

### [NIPS 2019](https://dblp.uni-trier.de/db/conf/nips/nips2019.html)

- [Noise-tolerant fair classification](http://papers.nips.cc/paper/8322-noise-tolerant-fair-classification)
- [Envy-Free Classification](http://papers.nips.cc/paper/8407-envy-free-classification)
- [Discrimination in Online Markets: Effects of Social Bias on Learning from Reviews and Policy Design](http://papers.nips.cc/paper/8487-discrimination-in-online-markets-effects-of-social-bias-on-learning-from-reviews-and-policy-design)
- [PC-Fairness: A Unified Framework for Measuring Causality-based Fairness](http://papers.nips.cc/paper/8601-pc-fairness-a-unified-framework-for-measuring-causality-based-fairness)
- [Assessing Disparate Impact of Personalized Interventions: Identifiability and Bounds](http://papers.nips.cc/paper/8603-assessing-disparate-impact-of-personalized-interventions-identifiability-and-bounds)
- [The Fairness of Risk Scores Beyond Classification: Bipartite Ranking and the XAUC Metric](http://papers.nips.cc/paper/8604-the-fairness-of-risk-scores-beyond-classification-bipartite-ranking-and-the-xauc-metric)
- [Fair Algorithms for Clustering](http://papers.nips.cc/paper/8741-fair-algorithms-for-clustering)
- [Characterizing Bias in Classifiers using Generative Models](http://papers.nips.cc/paper/8780-characterizing-bias-in-classifiers-using-generative-models)
- [Policy Learning for Fairness in Ranking](http://papers.nips.cc/paper/8782-policy-learning-for-fairness-in-ranking)
- [Average Individual Fairness: Algorithms, Generalization and Experiments](http://papers.nips.cc/paper/9034-average-individual-fairness-algorithms-generalization-and-experiments)
- [Paradoxes in Fair Machine Learning](http://papers.nips.cc/paper/9043-paradoxes-in-fair-machine-learning)
- [Unlocking Fairness: a Trade-off Revisited](http://papers.nips.cc/paper/9082-unlocking-fairness-a-trade-off-revisited)
- [Equal Opportunity in Online Classification with Partial Feedback](http://papers.nips.cc/paper/9099-equal-opportunity-in-online-classification-with-partial-feedback)
- [Learning Fairness in Multi-Agent Systems](http://papers.nips.cc/paper/9537-learning-fairness-in-multi-agent-systems)
- [On the Fairness of Disentangled Representations](http://papers.nips.cc/paper/9603-on-the-fairness-of-disentangled-representations)
- [Differential Privacy Has Disparate Impact on Model Accuracy](http://papers.nips.cc/paper/9681-differential-privacy-has-disparate-impact-on-model-accuracy)
- [Inherent Tradeoffs in Learning Fair Representations](http://papers.nips.cc/paper/9698-inherent-tradeoffs-in-learning-fair-representations)
- [Exploring Algorithmic Fairness in Robust Graph Covering Problems](http://papers.nips.cc/paper/9707-exploring-algorithmic-fairness-in-robust-graph-covering-problems)
- [Leveraging Labeled and Unlabeled Data for Consistent Fair Binary Classification](https://papers.nips.cc/paper/9437-leveraging-labeled-and-unlabeled-data-for-consistent-fair-binary-classification)
- [Assessing Social and Intersectional Biases in Contextualized Word Representations](https://papers.nips.cc/paper/9479-assessing-social-and-intersectional-biases-in-contextualized-word-representations)
- [Offline Contextual Bandits with High Probability Fairness Guarantees](https://papers.nips.cc/paper/9630-offline-contextual-bandits-with-high-probability-fairness-guarantees)
- [Multi-Criteria Dimensionality Reduction with Applications to Fairness](https://papers.nips.cc/paper/9652-multi-criteria-dimensionality-reduction-with-applications-to-fairness)
- [Group Retention when Using Machine Learning in Sequential Decision Making: the Interplay between User Dynamics and Fairness](https://papers.nips.cc/paper/9662-group-retention-when-using-machine-learning-in-sequential-decision-making-the-interplay-between-user-dynamics-and-fairness)

### [SDM 2019](https://dblp.uni-trier.de/db/conf/sdm/sdm2019.html)

- [Fairness in representation: quantifying stereotyping as a representational harm](https://doi.org/10.1137/1.9781611975673.90)

### [UAI 2019](https://dblp.uni-trier.de/db/conf/uai/uai2019.html)

- [The Sensitivity of Counterfactual Fairness to Unmeasured Confounding](http://auai.org/uai2019/proceedings/papers/213.pdf)
- [Wasserstein Fair Classification](http://auai.org/uai2019/proceedings/papers/315.pdf)

### [WWW 2019](https://dblp.uni-trier.de/db/conf/www/www2019.html)

- [Fairness in Algorithmic Decision Making: An Excursion Through the Lens of Causality](https://doi.org/10.1145/3308558.3313559)
- [FARE: Diagnostics for Fair Ranking using Pairwise Error Metrics](https://doi.org/10.1145/3308558.3313443)
- [On Convexity and Bounds of Fairness-aware Classification](https://doi.org/10.1145/3308558.3313723)

### Others 2019

- [Fighting Fire with Fire: Using Antidote Data to Improve Polarization and Fairness of Recommender Systems](https://doi.org/10.1145/3289600.3291002), [WSDM 2019](https://dblp.uni-trier.de/db/conf/wsdm/wsdm2019.html)
- [Interventional Fairness: Causal Database Repair for Algorithmic Fairness.](https://doi.org/10.1145/3299869.3319901), [SIGMOD 2019](https://dblp.uni-trier.de/db/conf/sigmod/index.html)
- [Designing Fair Ranking Schemes.](https://doi.org/10.1145/3299869.3300079), [SIGMOD 2019](https://dblp.uni-trier.de/db/conf/sigmod/index.html)

## 2018

### [AAAI 2018](https://dblp.uni-trier.de/db/conf/aaai/aaai2018.html)

- [Non-Discriminatory Machine Learning through Convex Fairness Criteria](https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16476)
- [Knowledge, Fairness, and Social Constraints](https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/17230)
- [Fairness in Decision-Making -- The Causal Explanation Formula](https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16949)
- [Fair Inference on Outcomes](https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16683)
- [Beyond Distributive Fairness in Algorithmic Decision Making: Feature Selection for Procedurally Fair Learning](https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16523)
- [Balancing Lexicographic Fairness and a Utilitarian Objective with Application to Kidney Exchange](https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16196)

### [AISTATS 2018](https://dblp.uni-trier.de/db/conf/aistats/aistats2018.html)

- [Fast Threshold Tests for Detecting Discrimination](http://proceedings.mlr.press/v84/pierson18a)
- [Spectral Algorithms for Computing Fair Support Vector Machines](http://proceedings.mlr.press/v84/olfat18a)

### [BIGDATA 2018](https://dblp.uni-trier.de/db/conf/bigdataconf/bigdataconf2018.html)

- [FairGAN: Fairness-aware Generative Adversarial Networks](https://ieeexplore.ieee.org/document/8622525)

### [CIKM 2018](https://dblp.uni-trier.de/db/conf/cikm/cikm2018.html)

- [Fairness-Aware Tensor-Based Recommendation](https://dl.acm.org/citation.cfm?doid=3269206.3271795)
- [Towards a Fair Marketplace: Counterfactual Evaluation of the trade-off between Relevance, Fairness & Satisfaction in Recommendation Systems](https://dl.acm.org/citation.cfm?doid=3269206.3272027)

### [FAT\* 2018](https://dblp.uni-trier.de/db/conf/fat/fat2018.html)

- [Potential for Discrimination in Online Targeted Advertising](http://proceedings.mlr.press/v81/speicher18a.html)
- [Discrimination in Online Personalization: A Multidisciplinary Inquiry](http://proceedings.mlr.press/v81/datta18a.html)
- [Privacy for All: Ensuring Fair and Equitable Privacy Protections](http://proceedings.mlr.press/v81/ekstrand18a.html)
- ["Meaningful Information" and the Right to Explanation](http://proceedings.mlr.press/v81/selbst18a.html)
- [Interpretable Active Learning](http://proceedings.mlr.press/v81/phillips18a.html)
- [Interventions over Predictions: Reframing the Ethical Debate for Actuarial Risk Assessment](http://proceedings.mlr.press/v81/barabas18a.html)
- [Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification](http://proceedings.mlr.press/v81/buolamwini18a.html)
- [Analyze, Detect and Remove Gender Stereotyping from Bollywood Movies](http://proceedings.mlr.press/v81/madaan18a.html)
- [Mixed Messages? The Limits of Automated Social Media Content Analysis](http://proceedings.mlr.press/v81/duarte18a.html)
- [The cost of fairness in binary classification](http://proceedings.mlr.press/v81/menon18a.html)
- [Decoupled Classifiers for Group-Fair and Efficient Machine Learning](http://proceedings.mlr.press/v81/dwork18a.html)
- [A case study of algorithm-assisted decision making in child maltreatment hotline screening decisions](http://proceedings.mlr.press/v81/chouldechova18a.html)
- [Fairness in Machine Learning: Lessons from Political Philosophy](http://proceedings.mlr.press/v81/binns18a.html)
- [Runaway Feedback Loops in Predictive Policing](http://proceedings.mlr.press/v81/ensign18a.html)
- [All The Cool Kids, How Do They Fit In?: Popularity and Demographic Biases in Recommender Evaluation and Effectiveness](http://proceedings.mlr.press/v81/ekstrand18b.html)
- [Recommendation Independence](http://proceedings.mlr.press/v81/kamishima18a.html)
- [Balanced Neighborhoods for Multi-sided Fairness in Recommendation](http://proceedings.mlr.press/v81/burke18a.html)

### [ICDM 2018](https://dblp.uni-trier.de/db/conf/icdm/icdm2018.html)

- [Using Balancing Terms to Avoid Discrimination in Classification](https://ieeexplore.ieee.org/document/8594925)

### [ICML 2018](https://dblp.uni-trier.de/db/conf/icml/icml2018.html)

- [Blind Justice: Fairness with Encrypted Sensitive Attributes](http://proceedings.mlr.press/v80/kilbertus18a.html)
- [Scalable Deletion-Robust Submodular Maximization: Data Summarization with Privacy and Fairness Constraints](http://proceedings.mlr.press/v80/kazemi18a.html)
- [Nonconvex Optimization for Fair Regression](http://proceedings.mlr.press/v80/komiyama18a.html)
- [Fair and Diverse DPP-based Data Summarization](http://proceedings.mlr.press/v80/celis18a.html)
- [Preventing Fairness Gerrymandering: Auditing and Learning for Subgroup Fairness](http://proceedings.mlr.press/v80/kearns18a.html)
- [Residual Unfairness in Fair Machine Learning from Prejudiced Data](http://proceedings.mlr.press/v80/kallus18a.html)
- [A Reductions Approach to Fair Classification](http://proceedings.mlr.press/v80/agarwal18a.html)
- [Probably Approximately Metric-Fair Learning](http://proceedings.mlr.press/v80/yona18a.html)
- [Learning Adversarially Fair and Transferable Representations](http://proceedings.mlr.press/v80/madras18a.html)
- [Delayed Impact of Fair Machine Learning](http://proceedings.mlr.press/v80/liu18c.html), *Best Paper Awards*
- [Fairness Without Demographics in Repeated Loss Minimization](http://proceedings.mlr.press/v80/hashimoto18a.html), *Best Paper Runner Up Awards*

### [IJCAI 2018](https://dblp.uni-trier.de/db/conf/ijcai/ijcai2018.html)

- [Achieving Non-Discrimination in Prediction](https://www.ijcai.org/proceedings/2018/430)
- [Preventing Disparate Treatment in Sequential Decision Making](https://www.ijcai.org/proceedings/2018/311)

### [KDD 2018](https://dblp.uni-trier.de/db/conf/kdd/kdd2018.html)

- [Fairness of Exposure in Rankings](https://dl.acm.org/citation.cfm?doid=3219819.3220088)
- [On Discrimination Discovery and Removal in Ranked Data using Causal Graph](https://dl.acm.org/citation.cfm?doid=3219819.3220087)
- [A Unified Approach to Quantifying Algorithmic Unfairness: Measuring Individual & Group Unfairness via Inequality Indices](https://dl.acm.org/citation.cfm?doid=3219819.3220046)

### [NIPS 2018](https://dblp.uni-trier.de/db/conf/nips/nips2018.html)

- [Fairness Behind a Veil of Ignorance: a Welfare Analysis for Automated Decision Making](http://papers.nips.cc/paper/7402-fairness-behind-a-veil-of-ignorance-a-welfare-analysis-for-automated-decision-making)
- [Enhancing the Accuracy and Fairness of Human Decision Making](http://papers.nips.cc/paper/7448-enhancing-the-accuracy-and-fairness-of-human-decision-making)
- [Online Learning with an Unknown Fairness Metric](http://papers.nips.cc/paper/7526-online-learning-with-an-unknown-fairness-metric)
- [Empirical Risk Minimization under Fairness Constraints](http://papers.nips.cc/paper/7544-empirical-risk-minimization-under-fairness-constraints)
- [Why Is My Classifier Discriminatory](http://papers.nips.cc/paper/7613-why-is-my-classifier-discriminatory)
- [Hunting for Discriminatory Proxies in Linear Regression Models](http://papers.nips.cc/paper/7708-hunting-for-discriminatory-proxies-in-linear-regression-models)
- [Fairness Through Computationally Bounded Awareness](http://papers.nips.cc/paper/7733-fairness-through-computationally-bounded-awareness)
- [Predict Responsibly Improving Fairness and Accuracy by Learning to Defer](http://papers.nips.cc/paper/7853-predict-responsibly-improving-fairness-and-accuracy-by-learning-to-defer)
- [On Preserving Non Discrimination When Combining Expert Advice](http://papers.nips.cc/paper/8058-on-preserving-non-discrimination-when-combining-expert-advice)
- [The Price of Fair PCA: One Extra Dimension](http://papers.nips.cc/paper/8294-the-price-of-fair-pca-one-extra-dimension)
- [Equality of Opportunity in Classification: A Causal Approach](http://papers.nips.cc/paper/7625-equality-of-opportunity-in-classification-a-causal-approach)
- [Invariant Representations without Adversarial Training](https://papers.nips.cc/paper/8122-invariant-representations-without-adversarial-training)
- [Learning to Pivot with Adversarial Networks](http://papers.nips.cc/paper/6699-learning-to-pivot-with-adversarial-networks)

### [SDM 2018](https://dblp.uni-trier.de/db/conf/sdm/sdm2018.html)

> *null*

### [UAI 2018](https://dblp.uni-trier.de/db/conf/uai/uai2018.html)

> *null*

### [WWW 2018](https://dblp.uni-trier.de/db/conf/www/www2018.html)

- [Adaptive Sensitive Reweighting to Mitigate Bias in Fairness-aware Classification](https://dl.acm.org/citation.cfm?id=3186133)
- [Human Perceptions of Fairness in Algorithmic Decision Making: A Case Study of Criminal Risk Prediction](https://dl.acm.org/citation.cfm?id=3186138)

### Others 2018

- [Biases in the Facebook News Feed: a Case Study on the Italian Elections](https://ieeexplore.ieee.org/document/8508659), [ASONAM 2018](https://dblp.uni-trier.de/db/conf/asunam/asonam2018.html)
- [Unleashing Linear Optimizers for Group-Fair Learning and Optimization](http://proceedings.mlr.press/v75/alabi18a.html), [COLT 2018](https://dblp.uni-trier.de/db/conf/colt/colt2018.html)

## 2017

### [AAAI 2017](https://dblp.uni-trier.de/db/conf/aaai/aaai2017.html)

> *null*

### [AISTATS 2017](https://dblp.uni-trier.de/db/conf/aistats/aistats2017.html)

- [Fairness Constraints: Mechanisms for Fair Classification](http://proceedings.mlr.press/v54/zafar17a/zafar17a.pdf), [supplement](http://proceedings.mlr.press/v54/zafar17a/zafar17a-supp.pdf)

### [BIGDATA 2017](https://dblp.uni-trier.de/db/conf/bigdataconf/bigdataconf2017.html)

- [Discrimination detection by causal effect estimation](https://ieeexplore.ieee.org/document/8258033)

### [CIKM 2017](https://dblp.uni-trier.de/db/conf/cikm/cikm2017.html)

- [FA\*IR: A Fair Top-k Ranking Algorithm](http://doi.acm.org/10.1145/3132847.3132938)
- [Algorithmic Bias: Do Good Systems Make Relevant Documents More Retrievable?](http://doi.acm.org/10.1145/3132847.3133135)

### [FAT\* 2017](https://dblp.uni-trier.de/db/conf/fat/fat2017.html)

> *null*

### [ICDM 2017](https://dblp.uni-trier.de/db/conf/icdm/icdm2017.html)

> *null*

### [ICML 2017](https://dblp.uni-trier.de/db/conf/icml/icml2017.html)

- [Fairness in Reinforcement Learning](http://proceedings.mlr.press/v70/jabbari17a.html)
- [Meritocratic Fairness for Cross-Population Selection](http://proceedings.mlr.press/v70/kearns17a.html)

### [IJCAI 2017](https://dblp.uni-trier.de/db/conf/ijcai/ijcai2017.html)

- [A Causal Framework for Discovering and Removing Direct and Indirect Discrimination](https://www.ijcai.org/proceedings/2017/549)

### [KDD 2017](https://dblp.uni-trier.de/db/conf/kdd/kdd2017.html)

- [Algorithmic decision making and the cost of fairness](http://www.kdd.org/kdd2017/papers/view/algorithmic-decision-making-and-the-cost-of-fairness)
- [Achieving Non-Discrimination in Data Release](http://www.kdd.org/kdd2017/papers/view/achieving-non-discrimination-in-data-release)

### [NIPS 2017](https://dblp.uni-trier.de/db/conf/nips/nips2017.html)

- [From Parity to Preference-based Notions of Fairness in Classification](https://papers.nips.cc/paper/6627-from-parity-to-preference-based-notions-of-fairness-in-classification)
- [Controllable Invariance through Adversarial Feature Learning](https://papers.nips.cc/paper/6661-controllable-invariance-through-adversarial-feature-learning)
- [Avoiding Discrimination through Causal Reasoning](https://papers.nips.cc/paper/6668-avoiding-discrimination-through-causal-reasoning)
- [Recycling Privileged Learning and Distribution Matching for Fairness](https://papers.nips.cc/paper/6670-recycling-privileged-learning-and-distribution-matching-for-fairness)
- [Beyond Parity: Fairness Objectives for Collaborative Filtering](http://papers.nips.cc/paper/6885-beyond-parity-fairness-objectives-for-collaborative-filtering)
- [Optimized Pre-Processing for Discrimination Prevention](https://papers.nips.cc/paper/6988-optimized-pre-processing-for-discrimination-prevention)
- [Counterfactual Fairness](https://papers.nips.cc/paper/6995-counterfactual-fairness)
- [Fair Clustering Through Fairlets](http://papers.nips.cc/paper/7088-fair-clustering-through-fairlets)
- [On Fairness and Calibration](https://papers.nips.cc/paper/7151-on-fairness-and-calibration)
- [When Worlds Collide: Integrating Different Counterfactual Assumptions in Fairness](https://papers.nips.cc/paper/7220-when-worlds-collide-integrating-different-counterfactual-assumptions-in-fairness)

### [SDM 2017](https://dblp.uni-trier.de/db/conf/sdm/sdm2017.html)

> *null*

### [UAI 2017](https://dblp.uni-trier.de/db/conf/uai/uai2017.html)

- [Fair Optimal Stopping Policy for Matching with Mediator](http://auai.org/uai2017/proceedings/papers/207.pdf), [supplement](http://auai.org/uai2017/proceedings/supplements/207.pdf)
- [Importance Sampling for Fair Policy Selection](http://auai.org/uai2017/proceedings/papers/225.pdf), [supplement](http://auai.org/uai2017/proceedings/supplements/225.pdf)

### [WWW 2017](https://dblp.uni-trier.de/db/conf/www/www2017.html)

- [Fairness in Package-to-Group Recommendations](https://dl.acm.org/citation.cfm?doid=3038912.3052612)
- [Fairness Beyond Disparate Treatment & Disparate Impact: Learning Classification without Disparate Mistreatment](https://dl.acm.org/citation.cfm?doid=3038912.3052660)

### Others 2017

- [Learning Non-Discriminatory Predictors](http://proceedings.mlr.press/v65/woodworth17a/woodworth17a.pdf), [COLT 2017](https://dblp.uni-trier.de/db/conf/colt/colt2017.html)
- [Inherent Trade-Offs in the Fair Determination of Risk Scores](http://drops.dagstuhl.de/opus/volltexte/2017/8156/), [ITCS 2017](https://dblp.uni-trier.de/db/conf/innovations/innovations2017.html)

## 2016

### [AAAI 2016](https://dblp.uni-trier.de/db/conf/aaai/aaai2016.html)

> *null*

### [AISTATS 2016](https://dblp.uni-trier.de/db/conf/aistats/aistats2016.html)

> *null*

### [BIGDATA 2016](https://dblp.uni-trier.de/db/conf/bigdataconf/bigdataconf2016.html)

> *null*

### [CIKM 2016](https://dblp.uni-trier.de/db/conf/cikm/cikm2016.html)

> *null*

### [FAT\* 2016](https://dblp.uni-trier.de/db/conf/fat/fat2016.html)

> *null*

### [ICDM 2016](https://dblp.uni-trier.de/db/conf/icdm/icdm2016.html)

- [Auditing Black-Box Models for Indirect Influence](https://ieeexplore.ieee.org/document/7837824)

### [ICML 2016](https://dblp.uni-trier.de/db/conf/icml/icml2016.html)

> *null*

### [IJCAI 2016](https://dblp.uni-trier.de/db/conf/ijcai/ijcai2016.html)

- [Situation Testing-Based Discrimination Discovery: A Causal Inference Approach](https://www.ijcai.org/Abstract/16/386)

### [KDD 2016](https://dblp.uni-trier.de/db/conf/kdd/kdd2016.html)

> *null*

### [NIPS 2016](https://dblp.uni-trier.de/db/conf/nips/nips2016.html)

- [Fairness in Learning: Classic and Contextual Bandits](https://papers.nips.cc/paper/6355-fairness-in-learning-classic-and-contextual-bandits)
- [Equality of Opportunity in Supervised Learning](https://papers.nips.cc/paper/6374-equality-of-opportunity-in-supervised-learning)
- [Satisfying Real-world Goals with Dataset Constraints](http://papers.nips.cc/paper/6316-satisfying-real-world-goals-with-dataset-constraints)
- [Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings](https://papers.nips.cc/paper/6228-man-is-to-computer-programmer-as-woman-is-to-homemaker-debiasing-word-embeddings)

### [SDM 2016](https://dblp.uni-trier.de/db/conf/sdm/sdm2016.html)

- [A Confidence-Based Approach for Balancing Fairness and Accuracy](http://epubs.siam.org/doi/abs/10.1137/1.9781611974348.17)

### [UAI 2016](https://dblp.uni-trier.de/db/conf/uai/uai2016.html)

> *null*

### [WWW 2016](https://dblp.uni-trier.de/db/conf/www/www2016.html)

> *null*

### Others 2016

- [A KDD Process for Discrimination Discovery](https://link.springer.com/chapter/10.1007%2F978-3-319-46131-1_28), ECML/PKDD 2016

## 2015

### [AAAI 2015](https://dblp.uni-trier.de/db/conf/aaai/aaai2015.html)

> *null*

### [AISTATS 2015](https://dblp.uni-trier.de/db/conf/aistats/aistats2015.html)

> *null*

### [BIGDATA 2015](https://dblp.uni-trier.de/db/conf/bigdataconf/bigdataconf2015.html)

> *null*

### [CIKM 2015](https://dblp.uni-trier.de/db/conf/cikm/cikm2015.html)

> *null*

### [FAT\* 2015](https://dblp.uni-trier.de/db/conf/fat/fat2015.html)

> *null*

### [ICDM 2015](https://dblp.uni-trier.de/db/conf/icdm/icdm2015.html)

> *null*

### [ICML 2015](https://dblp.uni-trier.de/db/conf/icml/icml2015.html)

> *null*

### [IJCAI 2015](https://dblp.uni-trier.de/db/conf/ijcai/ijcai2015.html)

> *null*

### [KDD 2015](https://dblp.uni-trier.de/db/conf/kdd/kdd2015.html)

- [Certifying and Removing Disparate Impact](https://dl.acm.org/citation.cfm?doid=2783258.2783311)

### [NIPS 2015](https://dblp.uni-trier.de/db/conf/nips/nips2015.html)

> *null*

### [SDM 2015](https://dblp.uni-trier.de/db/conf/sdm/sdm2015.html)

> *null*

### [UAI 2015](https://dblp.uni-trier.de/db/conf/uai/uai2015.html)

> *null*

### [WWW 2015](https://dblp.uni-trier.de/db/conf/www/www2015.html)

> *null*

## 2014

- [Fair pattern discovery](https://dl.acm.org/citation.cfm?doid=2554850.2555043), SAC 2014
- [Anti-discrimination Analysis Using Privacy Attack Strategies](https://link.springer.com/chapter/10.1007%2F978-3-662-44851-9_44), ECML/PKDD 2014

## 2013

- [Learning Fair Representations](http://proceedings.mlr.press/v28/zemel13.html), ICML 2013
- [Discrimination aware classification for imbalanced datasets](https://dl.acm.org/citation.cfm?doid=2505515.2507836), CIKM 2013

## 2012

- [Fairness-Aware Classifier with Prejudice Remover Regularizer](https://link.springer.com/chapter/10.1007%2F978-3-642-33486-3_3), ECML/PKDD 2012
- [Fairness through awareness](https://dl.acm.org/citation.cfm?doid=2090236.2090255), ITCS 2012
- [Decision theory for discrimination-aware classification](https://ieeexplore.ieee.org/document/6413831), ICDM 2012
- [A study of top-k measures for discrimination discovery](https://dl.acm.org/citation.cfm?doid=2245276.2245303), SAC 2012

## 2011

- [k-NN as an implementation of situation testing for discrimination discovery and prevention](https://dl.acm.org/citation.cfm?doid=2020408.2020488), KDD 2011
- [Handling Conditional Discrimination](https://ieeexplore.ieee.org/document/6137304), ICDM 2011
- [Discrimination prevention in data mining for intrusion and crime detection](https://ieeexplore.ieee.org/document/5949405), CICS 2011

## 2010

- [Discrimination Aware Decision Tree Learning](https://ieeexplore.ieee.org/document/5694053), ICDM 2010
- [Classification with no discrimination by preferential sampling](https://dtai.cs.kuleuven.be/events/Benelearn2010/submissions/benelearn2010_submission_18.pdf), 19th Machine Learning Conf. Belgium and The Netherlands 2010

## 2009

- [Measuring Discrimination in Socially-Sensitive Decision Records](https://doi.org/10.1137/1.9781611972795.50), SDM 2009
- [Classifying without discriminating](https://ieeexplore.ieee.org/document/4909197), IC4 2009

## 2008

- [Discrimination-aware data mining](https://doi.org/10.1145/1401890.1401959), KDD 2008
