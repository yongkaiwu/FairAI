## 2023

### [AAAI 2023](https://dblp.uni-trier.de/db/conf/aaai/aaai2023.html)

### [AIES 2023](https://www.aies-conference.com/2023/)

### [CIKM 2023](https://dblp.uni-trier.de/db/conf/cikm/cikm2023.html)

### [FAT\* 2023](https://dblp.uni-trier.de/db/conf/fat/fat2023.html)

- [Machine Explanations and Human Understanding.](https://doi.org/10.1145/3593013.3593970)
- [Broadening AI Ethics Narratives: An Indic Art View.](https://doi.org/10.1145/3593013.3593971)
- [How to Explain and Justify Almost Any Decision: Potential Pitfalls for Accountability in AI Decision-Making.](https://doi.org/10.1145/3593013.3593972)
- ['We are adults and deserve control of our phones': Examining the risks and opportunities of a right to repair for mobile apps.](https://doi.org/10.1145/3593013.3593973)
- [Fairness in machine learning from the perspective of sociology of statistics: How machine learning is becoming scientific by turning its back on metrological realism.](https://doi.org/10.1145/3593013.3593974)
- [Two Reasons for Subjecting Medical AI Systems to Lower Standards than Humans.](https://doi.org/10.1145/3593013.3593975)
- [Optimization's Neglected Normative Commitments.](https://doi.org/10.1145/3593013.3593976)
- [Welfarist Moral Grounding for Transparent AI.](https://doi.org/10.1145/3593013.3593977)
- [Humans, AI, and Context: Understanding End-Users' Trust in a Real-World Computer Vision Application.](https://doi.org/10.1145/3593013.3593978)
- [Multi-dimensional Discrimination in Law and Machine Learning - A Comparative Overview.](https://doi.org/10.1145/3593013.3593979)
- [Reconciling Individual Probability Forecastsâœ±.](https://doi.org/10.1145/3593013.3593980)
- [The Gradient of Generative AI Release: Methods and Considerations.](https://doi.org/10.1145/3593013.3593981)
- [In the Name of Fairness: Assessing the Bias in Clinical Record De-identification.](https://doi.org/10.1145/3593013.3593982)
- ["How Biased are Your Features?": Computing Fairness Influence Functions with Global Sensitivity Analysis.](https://doi.org/10.1145/3593013.3593983)
- [Preventing Discriminatory Decision-making in Evolving Data Streams.](https://doi.org/10.1145/3593013.3593984)
- [WEIRD FAccTs: How Western, Educated, Industrialized, Rich, and Democratic is FAccT?](https://doi.org/10.1145/3593013.3593985)
- [Trustworthy AI and the Logics of Intersectional Resistance.](https://doi.org/10.1145/3593013.3593986)
- [In her Shoes: Gendered Labelling in Crowdsourced Safety Perceptions Data from India.](https://doi.org/10.1145/3593013.3593987)
- [The Dataset Multiplicity Problem: How Unreliable Data Impacts Predictions.](https://doi.org/10.1145/3593013.3593988)
- ["I wouldn't say offensive but...": Disability-Centered Perspectives on Large Language Models.](https://doi.org/10.1145/3593013.3593989)
- [Walking the Walk of AI Ethics: Organizational Challenges and the Individualization of Risk among Ethics Entrepreneurs.](https://doi.org/10.1145/3593013.3593990)
- [Algorithmic Transparency from the South: Examining the state of algorithmic transparency in Chile's public administration algorithms.](https://doi.org/10.1145/3593013.3593991)
- [Who Should Pay When Machines Cause Harm? Laypeople's Expectations of Legal Damages for Machine-Caused Harm.](https://doi.org/10.1145/3593013.3593992)
- [Diagnosing AI Explanation Methods with Folk Concepts of Behavior.](https://doi.org/10.1145/3593013.3593993)
- [Certification Labels for Trustworthy AI: Insights From an Empirical Mixed-Method Study.](https://doi.org/10.1145/3593013.3593994)
- [The ethical ambiguity of AI data enrichment: Measuring gaps in research ethics norms and practices.](https://doi.org/10.1145/3593013.3593995)
- [Making Intelligence: Ethical Values in IQ and ML Benchmarks.](https://doi.org/10.1145/3593013.3593996)
- [Saliency Cards: A Framework to Characterize and Compare Saliency Methods.](https://doi.org/10.1145/3593013.3593997)
- [Multi-Target Multiplicity: Flexibility and Fairness in Target Specification under Resource Constraints.](https://doi.org/10.1145/3593013.3593998)
- [Ghosting the Machine: Judicial Resistance to a Recidivism Risk Assessment Instrument.](https://doi.org/10.1145/3593013.3593999)
- ['Affordances' for Machine Learning.](https://doi.org/10.1145/3593013.3594000)
- [Explainable AI is Dead, Long Live Explainable AI!: Hypothesis-driven Decision Support using Evaluative AI.](https://doi.org/10.1145/3593013.3594001)
- [Stronger Together: on the Articulation of Ethical Charters, Legal Tools, and Technical Documentation in ML.](https://doi.org/10.1145/3593013.3594002)
- [Simplicity Bias Leads to Amplified Performance Disparities.](https://doi.org/10.1145/3593013.3594003)
- [On the Independence of Association Bias and Empirical Fairness in Language Models.](https://doi.org/10.1145/3593013.3594004)
- [Envisioning Equitable Speech Technologies for Black Older Adults.](https://doi.org/10.1145/3593013.3594005)
- [Group-Fair Classification with Strategic Agents.](https://doi.org/10.1145/3593013.3594006)
- [The Possibility of Fairness: Revisiting the Impossibility Theorem in Practice.](https://doi.org/10.1145/3593013.3594007)
- [Domain Adaptive Decision Trees: Implications for Accuracy and Fairness.](https://doi.org/10.1145/3593013.3594008)
- [Algorithmic Transparency and Accountability through Crowdsourcing: A Study of the NYC School Admission Lottery.](https://doi.org/10.1145/3593013.3594009)
- [Rethinking Transparency as a Communicative Constellation.](https://doi.org/10.1145/3593013.3594010)
- [On the Praxes and Politics of AI Speech Emotion Recognition.](https://doi.org/10.1145/3593013.3594011)
- [It's about power: What ethical concerns do software engineers have, and what do they (feel they can) do about them?](https://doi.org/10.1145/3593013.3594012)
- [Does AI-Assisted Fact-Checking Disproportionately Benefit Majority Groups Online?](https://doi.org/10.1145/3593013.3594013)
- [Algorithms as Social-Ecological-Technological Systems: an Environmental Justice Lens on Algorithmic Audits.](https://doi.org/10.1145/3593013.3594014)
- [The Privacy-Bias Tradeoff: Data Minimization and Racial Disparity Assessments in U.S. Government.](https://doi.org/10.1145/3593013.3594015)
- [AI's Regimes of Representation: A Community-centered Study of Text-to-Image Models in South Asia.](https://doi.org/10.1145/3593013.3594016)
- [A Theory of Auditability for Allocation and Social Choice Mechanisms.](https://doi.org/10.1145/3593013.3594017)
- [Representation in AI Evaluations.](https://doi.org/10.1145/3593013.3594019)
- [Detecting disparities in police deployments using dashcam data.](https://doi.org/10.1145/3593013.3594020)
- [Delayed and Indirect Impacts of Link Recommendations.](https://doi.org/10.1145/3593013.3594021)
- [Striving for Affirmative Algorithmic Futures: How the Social Sciences can Promote more Equitable and Just Algorithmic System Design.](https://doi.org/10.1145/3593013.3594022)
- [Can Workers Meaningfully Consent to Workplace Wellbeing Technologies?](https://doi.org/10.1145/3593013.3594023)
- [Invigorating Ubuntu Ethics in AI for healthcare: Enabling equitable care.](https://doi.org/10.1145/3593013.3594024)
- [Honor Ethics: The Challenge of Globalizing Value Alignment in AI.](https://doi.org/10.1145/3593013.3594026)
- [Power and Resistance in the Twitter Bias Discourse.](https://doi.org/10.1145/3593013.3594027)
- [Runtime Monitoring of Dynamic Fairness Properties.](https://doi.org/10.1145/3593013.3594028)
- [Data Collaboratives with the Use of Decentralised Learning.](https://doi.org/10.1145/3593013.3594029)
- [Against Predictive Optimization: On the Legitimacy of Decision-Making Algorithms that Optimize Predictive Accuracy.](https://doi.org/10.1145/3593013.3594030)
- [Care and Coordination in Algorithmic Systems: An Economies of Worth Approach.](https://doi.org/10.1145/3593013.3594031)
- [You Sound Depressed: A Case Study on Sonde Health's Diagnostic Use of Voice Analysis AI.](https://doi.org/10.1145/3593013.3594032)
- [Harms from Increasingly Agentic Algorithmic Systems.](https://doi.org/10.1145/3593013.3594033)
- [How Redundant are Redundant Encodings? Blindness in the Wild and Racial Disparity when Race is Unobserved.](https://doi.org/10.1145/3593013.3594034)
- [On the Site of Predictive Justice.](https://doi.org/10.1145/3593013.3594035)
- [Ground(less) Truth: A Causal Framework for Proxy Labels in Human-Algorithm Decision-Making.](https://doi.org/10.1145/3593013.3594036)
- [Investigating Practices and Opportunities for Cross-functional Collaboration around AI Fairness in Industry Practice.](https://doi.org/10.1145/3593013.3594037)
- [Your Browsing History May Cost You: A Framework for Discovering Differential Pricing in Non-Transparent Markets.](https://doi.org/10.1145/3593013.3594038)
- [Add-Remove-or-Relabel: Practitioner-Friendly Bias Mitigation via Influential Fairness.](https://doi.org/10.1145/3593013.3594039)
- [FairAssign: Stochastically Fair Driver Assignment in Gig Delivery Platforms.](https://doi.org/10.1145/3593013.3594040)
- [Algorithmic Decisions, Desire for Control, and the Preference for Human Review over Algorithmic Review.](https://doi.org/10.1145/3593013.3594041)
- [Gender Animus Can Still Exist Under Favorable Disparate Impact: a Cautionary Tale from Online P2P Lending.](https://doi.org/10.1145/3593013.3594042)
- ["I Think You Might Like This": Exploring Effects of Confidence Signal Patterns on Trust in and Reliance on Conversational Recommender Systems.](https://doi.org/10.1145/3593013.3594043)
- [Algorithmic Unfairness through the Lens of EU Non-Discrimination Law: Or Why the Law is not a Decision Tree.](https://doi.org/10.1145/3593013.3594044)
- [On (assessing) the fairness of risk score models.](https://doi.org/10.1145/3593013.3594045)
- [UNFair: Search Engine Manipulation, Undetectable by Amortized Inequity.](https://doi.org/10.1145/3593013.3594046)
- [Datafication Genealogies beyond Algorithmic Fairness: Making Up Racialised Subjects.](https://doi.org/10.1145/3593013.3594047)
- [Maximal fairness.](https://doi.org/10.1145/3593013.3594048)
- [Augmented Datasheets for Speech Datasets and Ethical Decision-Making.](https://doi.org/10.1145/3593013.3594049)
- [To Be High-Risk, or Not To Be - Semantic Specifications and Implications of the AI Act's High-Risk AI Applications and Harmonised Standards.](https://doi.org/10.1145/3593013.3594050)
- [Implementing Fairness Constraints in Markets Using Taxes and Subsidies.](https://doi.org/10.1145/3593013.3594051)
- [AI in the Public Eye: Investigating Public AI Literacy Through AI Art.](https://doi.org/10.1145/3593013.3594052)
- [Questioning the ability of feature-based explanations to empower non-experts in robo-advised financial decision-making.](https://doi.org/10.1145/3593013.3594053)
- [On the Impact of Explanations on Understanding of Algorithmic Decision-Making.](https://doi.org/10.1145/3593013.3594054)
- [Addressing contingency in algorithmic (mis)information classification: Toward a responsible machine learning agenda.](https://doi.org/10.1145/3593013.3594055)
- ["We try to empower them" - Exploring Future Technologies to Support Migrant Jobseekers.](https://doi.org/10.1145/3593013.3594056)
- [Robustness Implies Fairness in Causal Algorithmic Recourse.](https://doi.org/10.1145/3593013.3594057)
- [Bias on Demand: A Modelling Framework That Generates Synthetic Data With Bias.](https://doi.org/10.1145/3593013.3594058)
- [ACROCPoLis: A Descriptive Framework for Making Sense of Fairness.](https://doi.org/10.1145/3593013.3594059)
- [Towards Labor Transparency in Situated Computational Systems Impact Research.](https://doi.org/10.1145/3593013.3594060)
- [Measuring and mitigating voting access disparities: a study of race and polling locations in Florida and North Carolina.](https://doi.org/10.1145/3593013.3594061)
- [Which Stereotypes Are Moderated and Under-Moderated in Search Engine Autocompletion?](https://doi.org/10.1145/3593013.3594062)
- [Ethical considerations in the early detection of Alzheimer's disease using speech and AI.](https://doi.org/10.1145/3593013.3594063)
- [Co-Design Perspectives on Algorithm Transparency Reporting: Guidelines and Prototypes.](https://doi.org/10.1145/3593013.3594064)
- [More Data Types More Problems: A Temporal Analysis of Complexity, Stability, and Sensitivity in Privacy Policies.](https://doi.org/10.1145/3593013.3594065)
- [Emotions and Dynamic Assemblages: A Study of Automated Social Security Using Qualitative Longitudinal Research.](https://doi.org/10.1145/3593013.3594066)
- [Regulating ChatGPT and other Large Generative AI Models.](https://doi.org/10.1145/3593013.3594067)
- [On the Richness of Calibration.](https://doi.org/10.1145/3593013.3594068)
- [The role of explainable AI in the context of the AI Act.](https://doi.org/10.1145/3593013.3594069)
- [The Dimensions of Data Labor: A Road Map for Researchers, Activists, and Policymakers to Empower Data Producers.](https://doi.org/10.1145/3593013.3594070)
- [Going public: the role of public participation approaches in commercial AI labs.](https://doi.org/10.1145/3593013.3594071)
- [Contrastive Language-Vision AI Models Pretrained on Web-Scraped Multimodal Data Exhibit Sexual Objectification Bias.](https://doi.org/10.1145/3593013.3594072)
- [Understanding accountability in algorithmic supply chains.](https://doi.org/10.1145/3593013.3594073)
- [Explainability in AI Policies: A Critical Review of Communications, Reports, Regulations, and Standards in the EU, US, and UK.](https://doi.org/10.1145/3593013.3594074)
- [Disentangling and Operationalizing AI Fairness at LinkedIn.](https://doi.org/10.1145/3593013.3594075)
- [Enhancing AI fairness through impact assessment in the European Union: a legal and computer science perspective.](https://doi.org/10.1145/3593013.3594076)
- ["I'm fully who I am": Towards Centering Transgender and Non-Binary Voices to Measure Biases in Open Language Generation.](https://doi.org/10.1145/3593013.3594078)
- [AI Regulation Is (not) All You Need.](https://doi.org/10.1145/3593013.3594079)
- [Diverse Perspectives Can Mitigate Political Bias in Crowdsourced Content Moderation.](https://doi.org/10.1145/3593013.3594080)
- [The Devil is in the Details: Interrogating Values Embedded in the Allegheny Family Screening Tool.](https://doi.org/10.1145/3593013.3594081)
- [A Systematic Review of Ethics Disclosures in Predictive Mental Health Research.](https://doi.org/10.1145/3593013.3594082)
- [An Empirical Analysis of Racial Categories in the Algorithmic Fairness Literature.](https://doi.org/10.1145/3593013.3594083)
- [A Sociotechnical Audit: Assessing Police Use of Facial Recognition.](https://doi.org/10.1145/3593013.3594084)
- [Fairer Together: Mitigating Disparate Exposure in Kemeny Rank Aggregation.](https://doi.org/10.1145/3593013.3594085)
- [Can Querying for Bias Leak Protected Attributes? Achieving Privacy With Smooth Sensitivity.](https://doi.org/10.1145/3593013.3594086)
- [Towards a Science of Human-AI Decision Making: An Overview of Design Space in Empirical Human-Subject Studies.](https://doi.org/10.1145/3593013.3594087)
- [(Anti)-Intentional Harms: The Conceptual Pitfalls of Emotion AI in Education.](https://doi.org/10.1145/3593013.3594088)
- [Organizational Governance of Emerging Technologies: AI Adoption in Healthcare.](https://doi.org/10.1145/3593013.3594089)
- [Navigating the Audit Landscape: A Framework for Developing Transparent and Auditable XR.](https://doi.org/10.1145/3593013.3594090)
- [Group fairness without demographics using social networks.](https://doi.org/10.1145/3593013.3594091)
- [Taking Algorithms to Courts: A Relational Approach to Algorithmic Accountability.](https://doi.org/10.1145/3593013.3594092)
- [Co-Designing for Transparency: Lessons from Building a Document Organization Tool in the Criminal Justice Domain.](https://doi.org/10.1145/3593013.3594093)
- [Examining risks of racial biases in NLP tools for child protective services.](https://doi.org/10.1145/3593013.3594094)
- [Easily Accessible Text-to-Image Generation Amplifies Demographic Stereotypes at Large Scale.](https://doi.org/10.1145/3593013.3594095)
- [What's fair is... fair? Presenting JustEFAB, an ethical framework for operationalizing medical ethics and social justice in the integration of clinical machine learning: JustEFAB.](https://doi.org/10.1145/3593013.3594096)
- [Personalized Pricing with Group Fairness Constraint.](https://doi.org/10.1145/3593013.3594097)
- [Auditing Cross-Cultural Consistency of Human-Annotated Labels for Recommendation Systems.](https://doi.org/10.1145/3593013.3594098)
- [The Progression of Disparities within the Criminal Justice System: Differential Enforcement and Risk Assessment Instruments.](https://doi.org/10.1145/3593013.3594099)
- [The Misuse of AUC: What High Impact Risk Assessment Gets Wrong.](https://doi.org/10.1145/3593013.3594100)
- [Counterfactual Prediction Under Outcome Measurement Error.](https://doi.org/10.1145/3593013.3594101)
- [Improving Fairness in AI Models on Electronic Health Records: The Case for Federated Learning Methods.](https://doi.org/10.1145/3593013.3594102)
- [Arbitrary Decisions are a Hidden Cost of Differentially Private Training.](https://doi.org/10.1145/3593013.3594103)
- [Interrogating the T in FAccT.](https://doi.org/10.1145/3593013.3594104)
- [Reducing Access Disparities in Networks using Edge Augmentationâœ±.](https://doi.org/10.1145/3593013.3594105)
- [The Many Faces of Fairness: Exploring the Institutional Logics of Multistakeholder Microlending Recommendation.](https://doi.org/10.1145/3593013.3594106)
- [Cross-Institutional Transfer Learning for Educational Models: Implications for Model Performance, Fairness, and Equity.](https://doi.org/10.1145/3593013.3594107)
- [Help or Hinder? Evaluating the Impact of Fairness Metrics and Algorithms in Visualizations for Consensus Ranking.](https://doi.org/10.1145/3593013.3594108)
- [Bias Against 93 Stigmatized Groups in Masked Language Models and Downstream Sentiment Classification Tasks.](https://doi.org/10.1145/3593013.3594109)
- [Representation, Self-Determination, and Refusal: Queer People's Experiences with Targeted Advertising.](https://doi.org/10.1145/3593013.3594110)
- [Capturing Humans' Mental Models of AI: An Item Response Theory Approach.](https://doi.org/10.1145/3593013.3594111)
- [Representation Online Matters: Practical End-to-End Diversification in Search and Recommender Systems.](https://doi.org/10.1145/3593013.3594112)
- [Using Supervised Learning to Estimate Inequality in the Size and Persistence of Income Shocks.](https://doi.org/10.1145/3593013.3594113)
- [Skin Deep: Investigating Subjectivity in Skin Tone Annotations for Computer Vision Benchmark Datasets.](https://doi.org/10.1145/3593013.3594114)
- [Discrimination through Image Selection by Job Advertisers on Facebook.](https://doi.org/10.1145/3593013.3594115)
- [On The Impact of Machine Learning Randomness on Group Fairness.](https://doi.org/10.1145/3593013.3594116)
- [Detection and Mitigation of Algorithmic Bias via Predictive Parity.](https://doi.org/10.1145/3593013.3594117)
- [Fairness Auditing in Urban Decisions using LP-based Data Combination.](https://doi.org/10.1145/3593013.3594118)
- [The Slow Violence of Surveillance Capitalism: How Online Behavioral Advertising Harms People.](https://doi.org/10.1145/3593013.3594119)
- [Bias as Boundary Object: Unpacking The Politics Of An Austerity Algorithm Using Bias Frameworks.](https://doi.org/10.1145/3593013.3594120)
- [Legal Taxonomies of Machine Bias: Revisiting Direct Discrimination.](https://doi.org/10.1145/3593013.3594121)
- [Achieving Diversity in Counterfactual Explanations: a Review and Discussion.](https://doi.org/10.1145/3593013.3594122)
- [Disparities in Text-to-Image Model Concept Possession Across Languages.](https://doi.org/10.1145/3593013.3594123)
- [Reconciling Governmental Use of Online Targeting With Democracy.](https://doi.org/10.1145/3593013.3594133)
- [Queer In AI: A Case Study in Community-Led Participatory AI.](https://doi.org/10.1145/3593013.3594134)

### [ICLR 2023](https://dblp.uni-trier.de/db/conf/iclr/iclr2023.html)

### [ICML 2023](https://dblp.uni-trier.de/db/conf/icml/icml2023.html)

### [IJCAI 2023](https://dblp.uni-trier.de/db/conf/ijcai/ijcai2023.html)

### [KDD 2023](https://dblp.uni-trier.de/db/conf/kdd/kdd2023.html)

### [NIPS 2023](https://dblp.uni-trier.de/db/conf/nips/neurips2023.html)

### [SDM 2023](https://dblp.uni-trier.de/db/conf/sdm/sdm2023.html)

### [UAI 2023](https://dblp.uni-trier.de/db/conf/uai/uai2023.html)

- [Toward Fairness in Text Generation via Mutual Information Minimization based on Importance Sampling.](https://proceedings.mlr.press/v206/wang23c.html)
- [Mean Parity Fair Regression in RKHS.](https://proceedings.mlr.press/v206/wei23a.html)
- [Fair Representation Learning with Unreliable Labels.](https://proceedings.mlr.press/v206/zhang23g.html)
- [Efficient fair PCA for fair representation learning.](https://proceedings.mlr.press/v206/kleindessner23a.html)
- [Revisiting Fair-PAC Learning and the Axioms of Cardinal Welfare.](https://proceedings.mlr.press/v206/cousins23a.html)
- [Scalable Spectral Clustering with Group Fairness Constraints.](https://proceedings.mlr.press/v206/wang23h.html)
- [Fast Feature Selection with Fairness Constraints.](https://proceedings.mlr.press/v206/quinzan23a.html)
- [Improved Approximation for Fair Correlation Clustering.](https://proceedings.mlr.press/v206/ahmadian23a.html)
- [MMD-B-Fair: Learning Fair Representations with Statistical Testing.](https://proceedings.mlr.press/v206/deka23a.html)
- [Doubly Fair Dynamic Pricing.](https://proceedings.mlr.press/v206/xu23i.html)
- [Stochastic Methods for AUC Optimization subject to AUC-based Fairness Constraints.](https://proceedings.mlr.press/v206/yao23b.html)
- [Reinforcement Learning with Stepwise Fairness Constraints.](https://proceedings.mlr.press/v206/deng23a.html)
- [Uncertainty Estimates of Predictions via a General Bias-Variance Decomposition.](https://proceedings.mlr.press/v206/gruber23a.html)

### [WWW 2023](https://dblp.uni-trier.de/db/conf/www/www2023.html)

#### [WSDM 2023](https://dblp.uni-trier.de/db/conf/wsdm/wsdm2023.html)

### Others 2023
